{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8028421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyvcf2 0.30.14\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cyvcf2\n",
    "\n",
    "print(f\"cyvcf2 {cyvcf2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0449fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_maf_from_vcf(vcf_file,\n",
    "                         categorize = False,\n",
    "                         verbose = False):\n",
    "    num_singletons = 0\n",
    "    \n",
    "    maf_dict = OrderedDict()\n",
    "    \n",
    "    for variant in cyvcf2.VCF(vcf_file):\n",
    "        # Assume that there are only biallelic sites.\n",
    "        num_genotypes_00 = 0\n",
    "        num_genotypes_01 = 0 # Includes genotype 10\n",
    "        num_genotypes_11 = 0\n",
    "        num_alleles_0 = 0\n",
    "        num_alleles_1 = 0\n",
    "        num_alleles_2 = 0\n",
    "        \n",
    "        for genotype in variant.genotypes:\n",
    "            # Tally up genotypes.\n",
    "            if   genotype[0] == 0 and genotype[0] == 0:\n",
    "                num_genotypes_00 += 1\n",
    "            elif genotype[0] == 1 and genotype[1] == 1:\n",
    "                num_genotypes_11 += 1\n",
    "            else:\n",
    "                num_genotypes_01 += 1 # Or 10\n",
    "                \n",
    "            # Tally up alleles in genotype.\n",
    "            if   genotype[0] == 0:\n",
    "                num_alleles_0 += 1\n",
    "            elif genotype[0] == 1:\n",
    "                num_alleles_1 += 1\n",
    "            elif genotype[0] == 2:\n",
    "                num_alleles_2 += 1\n",
    "                if verbose:\n",
    "                    print(f\"WARNING: Multi-alleic site at {variant.start} \" +\\\n",
    "                          f\"with genotype {genotype}.\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"WARNING: Allele value in {genotype}\" +\\\n",
    "                          f\"at {variant.start} is not recognized.\")\n",
    "                \n",
    "            # Tally up alleles in genotype.\n",
    "            if   genotype[1] == 0:\n",
    "                num_alleles_0 += 1\n",
    "            elif genotype[1] == 1:\n",
    "                num_alleles_1 += 1\n",
    "            elif genotype[1] == 2:\n",
    "                num_alleles_2 += 1\n",
    "                if verbose:\n",
    "                    print(f\"WARNING:\" + \" \" +\\\n",
    "                          f\"Multi-alleic site at {variant.start}\" + \" \" +\\\n",
    "                          f\"with genotype {genotype}.\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"WARNING:\" + \" \" +\\\n",
    "                          f\"Allele value in {genotype}\" + \" \" +\\\n",
    "                          f\"at {variant.start} is not recognized.\")\n",
    "                \n",
    "        #assert min(num_alleles_0, num_alleles_1) > num_alleles_2,\\\n",
    "        #    \"Allele 2 occurs at higher frequency than alleles 0 and 1.\"\n",
    "        \n",
    "        num_alleles_total = num_alleles_0 + num_alleles_1 + num_alleles_2\n",
    "        # MAF is defined as the frequency of the SECOND most common allele.\n",
    "        minor_allele = 0 if num_alleles_0 < num_alleles_1 else 1\n",
    "        maf = float(min(num_alleles_0, num_alleles_1)) / float(num_alleles_total)\n",
    "        \n",
    "        # Key: Site position\n",
    "        # Val: (MAF or MAF category, minor allele,)\n",
    "        if categorize:\n",
    "            #if maf < 0.0000002:\n",
    "            #    maf_dict[variant.start] = ('(0.00000%, 0.00002%)', minor_allele)\n",
    "            #elif maf >= 0.0000002 and maf < 0.0000005:\n",
    "            #    maf_dict[variant.start] = ('[0.00002%, 0.00005%)', minor_allele)\n",
    "            #elif maf >= 0.0000005 and maf < 0.000001:\n",
    "            #    maf_dict[variant.start] = ('[0.00005%,  0.0001%)', minor_allele)\n",
    "            #elif maf >= 0.000001 and maf < 0.000002:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0001%,  0.0002%)', minor_allele)\n",
    "            #elif maf >= 0.000002 and maf < 0.000005:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0002%,  0.0005%)', minor_allele)\n",
    "            #elif maf >= 0.000005 and maf < 0.00001:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0005%,  0.0010%)', minor_allele)\n",
    "            #elif maf >= 0.00001 and maf < 0.00002:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0010%,  0.0020%)', minor_allele)\n",
    "            #elif maf >= 0.00002 and maf < 0.00005:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0020%,  0.0050%)', minor_allele)\n",
    "            #elif maf >= 0.00005 and maf < 0.00010:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0050%,  0.0100%)', minor_allele)\n",
    "            if maf < 0.00010:\n",
    "                maf_dict[variant.start] = ('( 0.0000%,  0.0100%)', minor_allele)\n",
    "            elif maf >= 0.00010 and maf < 0.00100:\n",
    "                maf_dict[variant.start] = ('[ 0.0100%,  0.1000%)', minor_allele)\n",
    "            elif maf >= 0.00100 and maf < 0.00200:\n",
    "                maf_dict[variant.start] = ('[ 0.1000%,  0.2000%)', minor_allele)\n",
    "            elif maf >= 0.00200 and maf < 0.00300:\n",
    "                maf_dict[variant.start] = ('[ 0.2000%,  0.3000%)', minor_allele)\n",
    "            elif maf >= 0.00300 and maf < 0.00400:\n",
    "                maf_dict[variant.start] = ('[ 0.3000%,  0.4000%)', minor_allele)\n",
    "            elif maf >= 0.00400 and maf < 0.00500:\n",
    "                maf_dict[variant.start] = ('[ 0.4000%,  0.5000%)', minor_allele)\n",
    "            elif maf >= 0.00500 and maf < 0.01000:\n",
    "                maf_dict[variant.start] = ('[ 0.5000%,  1.0000%)', minor_allele)\n",
    "            elif maf >= 0.01000 and maf < 0.02000:\n",
    "                maf_dict[variant.start] = ('[ 1.0000%,  2.0000%)', minor_allele)\n",
    "            elif maf >= 0.02000 and maf < 0.05000:\n",
    "                maf_dict[variant.start] = ('[ 2.0000%,  5.0000%)', minor_allele)\n",
    "            elif maf >= 0.05000 and maf < 0.10000:\n",
    "                maf_dict[variant.start] = ('[ 5.0000%, 10.0000%)', minor_allele)\n",
    "            elif maf >= 0.10000 and maf < 0.20000:\n",
    "                maf_dict[variant.start] = ('[10.0000%, 20.0000%)', minor_allele)\n",
    "            elif maf >= 0.20000 and maf < 0.30000:\n",
    "                maf_dict[variant.start] = ('[20.0000%, 30.0000%)', minor_allele)\n",
    "            elif maf >= 0.30000 and maf < 0.40000:\n",
    "                maf_dict[variant.start] = ('[30.0000%, 40.0000%)', minor_allele)\n",
    "            elif maf >= 0.40000 and maf <= 0.50000:\n",
    "                maf_dict[variant.start] = ('[40.0000%, 50.0000%]', minor_allele)\n",
    "            else:\n",
    "                print(f\"MAF value {maf} is out of recognized range.\")\n",
    "        else:\n",
    "            maf_dict[variant.start] = (maf, minor_allele)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"MAF is {round(maf, 4)}\"\\\n",
    "                  f\" at {variant.start}\"\\\n",
    "                  f\" with {variant.aaf}\"\\\n",
    "                  f\" in {maf_dict[variant.start]}\")\n",
    "        \n",
    "        if min(num_alleles_0, num_alleles_1) == 1:\n",
    "            num_singletons += 1\n",
    "            if verbose:\n",
    "                print(f\"Singleton at position {variant.start}\")\n",
    "                \n",
    "    if verbose:\n",
    "        print(f\"Number of singletons in vcf file {i} is {num_singletons}\")\n",
    "    \n",
    "    return(maf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff355954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vcf_file(vcf_file):\n",
    "    \"\"\"\n",
    "    If gt_types = False, then 0=HOM_REF, 1=HET, 2=UNKNOWN, the coordinates are 0-based.\n",
    "    It returns a list of dictionaries, each containing a VCF record.\n",
    "    \"\"\"\n",
    "    parsed_vcf = []\n",
    "    \n",
    "    for variant in cyvcf2.VCF(vcf_file,\n",
    "                              gts012 = False, # 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\n",
    "                              strict_gt = True):\n",
    "        record = {\n",
    "            'ref': variant.REF,\n",
    "            'alt': variant.ALT,\n",
    "            'ctg': variant.CHROM, # Contig id/name\n",
    "            'pos': int(variant.start),\n",
    "            'aa' : variant.INFO.get('AA'), # Ancestral allele\n",
    "            'gt' : variant.genotypes\n",
    "        }\n",
    "        \n",
    "        parsed_vcf.append(record)\n",
    "        \n",
    "    return(parsed_vcf)\n",
    "\n",
    "\n",
    "def compare_vcf(vcf_1, vcf_2):\n",
    "    assert len(vcf_1) == len(vcf_2),\\\n",
    "        \"vcf_1 and vcf_2 have different number of records.\"\n",
    "    \n",
    "    for i in range(len(vcf_1)):\n",
    "        is_valid_ref = vcf_1[i].get('ref') == vcf_2[i].get('ref')\n",
    "        #is_valid_alt = vcf_1[i].get('alt') == vcf_2[i].get('alt')\n",
    "        is_valid_ctg = vcf_1[i].get('ctg') == vcf_2[i].get('ctg')\n",
    "        is_valid_pos = vcf_1[i].get('pos') == vcf_2[i].get('pos')\n",
    "        #is_valid_aa  = vcf_1[i].get('aa' ) == vcf_2[i].get('aa' )\n",
    "        is_all_valid = np.all([is_valid_ref,\n",
    "                               #is_valid_alt,\n",
    "                               is_valid_ctg,\n",
    "                               is_valid_pos\n",
    "                               #is_valid_aa\n",
    "                              ])\n",
    "        \n",
    "        if not is_all_valid:\n",
    "            pos_1 = vcf_1[i].get('pos')\n",
    "            pos_2 = vcf_2[i].get('pos')\n",
    "            print(f\"{is_valid_ref} {is_valid_alt} {is_valid_ctg} {is_valid_pos}\")\n",
    "            print(f\"{vcf_1[i].get('alt')} {vcf_2[i].get('alt')}\")\n",
    "            print(f\"Incomparable records at {pos_1} and {pos_2}.\")\n",
    "            return(False)\n",
    "        \n",
    "    return(True)\n",
    "\n",
    "\n",
    "def get_common_positions_in_vcf(vcf_1, vcf_2):\n",
    "    pos_1 = []\n",
    "    pos_2 = []\n",
    "    for i, record in enumerate(vcf_1):\n",
    "        pos_1.append(record.get('pos'))\n",
    "    for i, record in enumerate(vcf_2):\n",
    "        pos_2.append(record.get('pos'))\n",
    "        \n",
    "    # All positions should be unique.\n",
    "    assert len(pos_1) == len(set(pos_1)),\\\n",
    "        \"The positions in vcf_1 are not all unique.\"\n",
    "    assert len(pos_2) == len(set(pos_2)),\\\n",
    "        \"The positions in vcf_2 are not all unique.\"\n",
    "    \n",
    "    common_pos = list(set.intersection(set(pos_1), set(pos_2)))\n",
    "    \n",
    "    return(common_pos)\n",
    "\n",
    "\n",
    "def compare_variants(true_vcf_file,\n",
    "                     miss_vcf_file,\n",
    "                     imputed_vcf_file,\n",
    "                     maf_dict,\n",
    "                     ploidy_level,\n",
    "                     verbose = False):\n",
    "    assert ploidy_level == 1 or ploidy_level == 2,\\\n",
    "        f\"ploidy_level {ploidy_level} is not recognized.\"\n",
    "    \n",
    "    if ploidy_level == 1:\n",
    "        MISSING_GENOTYPE_CONSTANT = [-1, False]\n",
    "    else:\n",
    "        MISSING_GENOTYPE_CONSTANT = [-1, -1, True]\n",
    "    \n",
    "    true_vcf    = parse_vcf_file(true_vcf_file)\n",
    "    miss_vcf    = parse_vcf_file(miss_vcf_file)\n",
    "    imputed_vcf = parse_vcf_file(imputed_vcf_file)\n",
    "    \n",
    "    new_true_vcf, new_miss_vcf, new_imputed_vcf = filter_non_biallelic_sites(true_vcf, miss_vcf, imputed_vcf)\n",
    "    \n",
    "    # Reencode genotype from 0|0, 0|1, 1|0, and 1|1 to 1, 2, 2, and 3, respectively.\n",
    "    reencode_map = {\n",
    "        (0, 0, True) : 1, # AA\n",
    "        (0, 1, True) : 2, # AB, treated as equal to BA\n",
    "        (1, 0, True) : 2, # BA\n",
    "        (1, 1, True) : 3, # BB\n",
    "        (0, False)   : 1, # A\n",
    "        (1, False)   : 2, # B\n",
    "    }\n",
    "    \n",
    "    # Key   : MAF category\n",
    "    # Value : (number of total, number of correctly imputed, percent correctly imputed)\n",
    "    maf_categories = OrderedDict()\n",
    "    #maf_categories['(0.00000%, 0.00002%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[0.00002%, 0.00005%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[0.00005%,  0.0001%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0001%,  0.0002%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0002%,  0.0005%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0005%,  0.0010%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0010%,  0.0020%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0020%,  0.0050%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0050%,  0.0100%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['( 0.0000%,  0.0100%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.0100%,  0.1000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.1000%,  0.2000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.2000%,  0.3000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.3000%,  0.4000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.4000%,  0.5000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.5000%,  1.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 1.0000%,  2.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 2.0000%,  5.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 5.0000%, 10.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[10.0000%, 20.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[20.0000%, 30.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[30.0000%, 40.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[40.0000%, 50.0000%]'] = [0.0, 0.0, 0.0]\n",
    "    \n",
    "    results = {\n",
    "        'pos' : [],\n",
    "        'maf' : [],\n",
    "        'iqs' : []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(new_imputed_vcf)):\n",
    "        position = new_imputed_vcf[i]['pos']\n",
    "        \n",
    "        if position not in maf_dict:\n",
    "            continue\n",
    "            \n",
    "        maf, minor_allele = maf_dict[position]\n",
    "        \n",
    "        missing_bool   = [x == MISSING_GENOTYPE_CONSTANT for x in new_miss_vcf[i]['gt']]\n",
    "        true_gt_oi     = [x for x, y in zip(new_true_vcf[i]['gt'],    missing_bool) if y]\n",
    "        imputed_gt_oi  = [x for x, y in zip(new_imputed_vcf[i]['gt'], missing_bool) if y]\n",
    "        \n",
    "        assert len(true_gt_oi) == len(imputed_gt_oi),\\\n",
    "            f\"true_gt_oi {len(true_gt_oi)}\" + \" and \" +\\\n",
    "            f\"imputed_gt_oi {len(imputed_gt_oi)}\" + \" \" +\\\n",
    "            f\"are not of the same length.\"\n",
    "        \n",
    "        nbr_gt_missing = len(imputed_gt_oi)\n",
    "        if nbr_gt_missing <= 1:\n",
    "            continue\n",
    "            \n",
    "        true_gt_reencoded    = [reencode_map[tuple(x)] for x in true_gt_oi]\n",
    "        imputed_gt_reencoded = [reencode_map[tuple(x)] for x in imputed_gt_oi]\n",
    "        \n",
    "        # Calculate IQS, haploid version (1 denotes the ancestral allele and 2 the derived allele).\n",
    "        # See Table 1 for the original diploid version.\n",
    "        # https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2837741/\n",
    "        n11 = np.sum([y == 1 for x, y in zip(imputed_gt_reencoded, true_gt_reencoded) if x == 1])\n",
    "        n21 = np.sum([y == 1 for x, y in zip(imputed_gt_reencoded, true_gt_reencoded) if x == 2])\n",
    "        n12 = np.sum([y == 2 for x, y in zip(imputed_gt_reencoded, true_gt_reencoded) if x == 1])\n",
    "        n22 = np.sum([y == 2 for x, y in zip(imputed_gt_reencoded, true_gt_reencoded) if x == 2])\n",
    "        \n",
    "        n1_ = n11 + n12\n",
    "        n2_ = n21 + n22\n",
    "        n_1 = n11 + n21\n",
    "        n_2 = n12 + n22\n",
    "        n__ = n11 + n21 + n12 + n22 # Total genotypes imputed\n",
    "        assert n__ == nbr_gt_missing,\\\n",
    "            f\"n__ {n__} is not equal to nbr_gt_missing {nbr_gt_missing}\"\n",
    "        \n",
    "        Po = float(n11 + n22) / float(n__) # Concordance rate; observed agreement\n",
    "        Pc = float(n1_ * n_1 + n2_ * n_2) / float(n__ * n__) # Change agreement\n",
    "        if Pc == 1:\n",
    "            #print(f\"Pc = {Pc}; n1_ = {n1_}; n_1 = {n_1}; n2_ = {n2_}; n_2 = {n_2}; n__ = {n__}\")\n",
    "            continue\n",
    "        iqs = (Po - Pc) / (1 - Pc)\n",
    "        \n",
    "        results['pos'].append(position)\n",
    "        results['maf'].append(maf)\n",
    "        results['iqs'].append(iqs)\n",
    "        \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7613aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_non_biallelic_sites(vcf_1, vcf_2, vcf_3):\n",
    "    assert compare_vcf(vcf_1, vcf_2),\\\n",
    "        \"vcf_1 and vcf_2 are not comparable.\"\n",
    "    assert compare_vcf(vcf_2, vcf_3),\\\n",
    "        \"vcf_2 and vcf_3 are not comparable.\"\n",
    "    \n",
    "    new_vcf_1 = []\n",
    "    new_vcf_2 = []\n",
    "    new_vcf_3 = []\n",
    "    \n",
    "    for i in range(len(vcf_1)):\n",
    "        is_biallelic_1 = len(set(vcf_1[i]['alt']) - {'.'}) == 1\n",
    "        is_biallelic_2 = len(set(vcf_2[i]['alt']) - {'.'}) == 1\n",
    "        is_biallelic_3 = len(set(vcf_3[i]['alt']) - {'.'}) == 1\n",
    "        \n",
    "        if is_biallelic_1 and is_biallelic_2 and is_biallelic_3:\n",
    "            new_vcf_1.append(vcf_1[i])\n",
    "            new_vcf_2.append(vcf_2[i])\n",
    "            new_vcf_3.append(vcf_3[i])\n",
    "            \n",
    "    assert  len(new_vcf_1) == len(new_vcf_2)\\\n",
    "        and len(new_vcf_1) == len(new_vcf_3),\\\n",
    "        \"The number of site positions in \" +\\\n",
    "        \"new_vcf_1, new_vcf_2, and new_vcf_3\" +\\\n",
    "        \"are different.\"\n",
    "        \n",
    "    return(new_vcf_1, new_vcf_2, new_vcf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c81a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(method, ploidy_level, number_sets):\n",
    "    imputed_dir = \"imputed\" + \"_\" + method + \"/\"\n",
    "    results = []\n",
    "    for i in np.arange(number_sets):\n",
    "        true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf.gz\"\n",
    "        miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf.gz\"\n",
    "        imputed_vcf_file = base_dir + imputed_dir + \"imputed.\" + str(i) + \".vcf.gz\"\n",
    "        stats = compare_variants(true_vcf_file,\n",
    "                                 miss_vcf_file,\n",
    "                                 imputed_vcf_file,\n",
    "                                 maf_dict = maf_dict[i],\n",
    "                                 ploidy_level = ploidy_level,\n",
    "                                 verbose = False)\n",
    "        results.append(stats)\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c844656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../data/ancient_panmictic_haploid_miss80/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe8aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/ancient_panmictic_haploid_miss80/ref/ref.0.vcf\n"
     ]
    }
   ],
   "source": [
    "maf_dict = []\n",
    "for i in np.arange(1):\n",
    "    vcf_file = base_dir + \"ref/ref.\" + str(i) + \".vcf\"\n",
    "    print(f\"{vcf_file}\")\n",
    "    maf_dict.append(compute_maf_from_vcf(vcf_file,\n",
    "                                         categorize = False,\n",
    "                                         verbose = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0a1aaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n"
     ]
    }
   ],
   "source": [
    "methods = [\"tsinfer\", \"beagle\"]\n",
    "for method in methods:\n",
    "    out_csv_file = base_dir + \"results/\" + method + \".csv\"\n",
    "    results = parse_results(method = method,\n",
    "                            ploidy_level = 1,\n",
    "                            number_sets = 1)\n",
    "    with open(out_csv_file, 'w') as out_csv:\n",
    "        out_csv.write(\",\".join(['method', 'position', 'maf', 'iqs']) + \"\\n\")\n",
    "        for i, result in enumerate(results):\n",
    "            for j, position in enumerate(results[i]['pos']):\n",
    "                out_csv.write(\",\".join([method,\n",
    "                                        str(position),\n",
    "                                        str(results[i]['maf'][j]),\n",
    "                                        str(results[i]['iqs'][j])\n",
    "                                       ]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77322176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
