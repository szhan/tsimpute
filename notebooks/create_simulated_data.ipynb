{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tskit\n",
    "import tsinfer\n",
    "import msprime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import masks\n",
    "import measures\n",
    "import util\n",
    "import simulate_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population-matched imputation\n",
    "num_ref_inds = 1_500\n",
    "num_query_inds = 500\n",
    "ts_full = simulate_ts.get_ts_ten_pop(\n",
    "    num_ref_inds=num_ref_inds,\n",
    "    num_query_inds=num_query_inds,\n",
    "    sequence_length=1e7,    # 10 Mbp\n",
    "    pop_ref='CEU',\n",
    "    pop_query='CEU',\n",
    ")\n",
    "ts_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare files for tsimpute\n",
    "prefix = \"jacobs_ceu_ceu_2k\"\n",
    "ts_full_file = prefix + \".full.trees\"\n",
    "ts_ref_file = prefix + \".ref.trees\"\n",
    "ts_query_file = prefix + \".query.trees\"\n",
    "npy_query_file = prefix + \".query.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploidy = 2\n",
    "num_ref_haps = ploidy * num_ref_inds\n",
    "num_query_haps = ploidy * num_query_inds\n",
    "idx_ref_inds = np.arange(num_ref_inds)\n",
    "idx_ref_haps = np.arange(num_ref_haps)\n",
    "idx_query_inds = np.arange(num_ref_inds, num_ref_inds + num_query_inds)\n",
    "idx_query_haps = np.arange(num_ref_haps, num_ref_haps + num_query_haps)\n",
    "assert np.all(ts_full.nodes_flags[:(num_ref_haps + num_query_haps)] == 1)\n",
    "assert np.all(ts_full.nodes_flags[(num_ref_haps + num_query_haps):] == 0)\n",
    "assert np.all(ts_full.nodes_flags[idx_ref_haps] == 1)\n",
    "assert np.all(ts_full.nodes_flags[idx_query_haps] == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify down to reference haplotypes, removing monoallelic sites.\n",
    "ts_ref = ts_full.simplify(idx_ref_haps, filter_sites=True)\n",
    "ts_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and remove sites with private mutations.\n",
    "af = np.zeros(ts_ref.num_sites, dtype=np.int32)\n",
    "i = 0\n",
    "for v in ts_ref.variants():\n",
    "    af[i] = min(v.counts().values())\n",
    "    i += 1\n",
    "sites_private_mutation = np.where(af < 2)[0]\n",
    "print(f\"Sites with private mutation: {len(sites_private_mutation)}\")\n",
    "ts_ref_filtered = ts_ref.delete_sites(site_ids=sites_private_mutation)\n",
    "ts_ref_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify sites with high MAF.\n",
    "maf = np.zeros(ts_ref_filtered.num_sites, dtype=np.float64)\n",
    "i = 0\n",
    "for v in ts_ref_filtered.variants():\n",
    "    maf[i] = min(v.frequencies().values())\n",
    "    i += 1\n",
    "sites_high_maf = np.where(maf >= 0.05)[0]\n",
    "print(f\"Sites with high MAF: {len(sites_high_maf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select genotyped markers\n",
    "reference_markers = np.arange(ts_ref_filtered.num_sites)\n",
    "num_markers = 3333 # Density of 3,333 markers per 10 Mb\n",
    "genotyped_markers = np.random.choice(sites_high_maf, size=num_markers, replace=False)\n",
    "genotyped_markers.sort()    # In-place sort\n",
    "ungenotyped_markers = np.setdiff1d(reference_markers, genotyped_markers)\n",
    "assert np.union1d(genotyped_markers,\n",
    "                  ungenotyped_markers).size == ts_ref_filtered.num_sites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotyped_site_pos = ts_ref_filtered.sites_position[genotyped_markers]\n",
    "ungenotyped_site_pos = ts_ref_filtered.sites_position[ungenotyped_markers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reference markers: {ts_ref_filtered.num_sites}\")\n",
    "print(f\"Genotyped markers: {len(genotyped_markers)}\")\n",
    "print(f\"Ungenotyped markers: {len(ungenotyped_markers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare query haplotypes\n",
    "# WARN: Extracting query haplotypes like this only works when using ACGT encoding.\n",
    "ts_query = ts_full.simplify(idx_query_haps, filter_sites=False)\n",
    "ts_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter sites in query haplotypes down to reference markers.\n",
    "remove_sites = np.where(np.isin(ts_query.sites_position, ts_ref_filtered.sites_position, invert=True))[0]\n",
    "ts_query_filtered = ts_query.delete_sites(site_ids=remove_sites)\n",
    "assert ts_query_filtered.num_sites == ts_ref_filtered.num_sites\n",
    "assert np.array_equal(ts_query_filtered.sites_position, ts_ref_filtered.sites_position)\n",
    "ts_query_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmasked query haplotypes\n",
    "ts_query_h = ts_query_filtered.genotype_matrix(alleles=tskit.ALLELES_ACGT)\n",
    "print(ts_query_h.shape)\n",
    "ts_query_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked query haplotypes\n",
    "ts_query_h_masked = np.copy(ts_query_h)\n",
    "ts_query_h_masked[ungenotyped_markers, :] = -1\n",
    "ts_query_h_masked\n",
    "assert ts_query_h.shape == ts_query_h_masked.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(npy_query_file, \"wb\") as f:\n",
    "    np.save(f, ts_query_h)\n",
    "    np.save(f, ts_query_h_masked)\n",
    "    np.save(f, genotyped_site_idx)\n",
    "    np.save(f, ungenotyped_site_idx)\n",
    "    np.save(f, genotyped_site_pos)\n",
    "    np.save(f, ungenotyped_site_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_full.dump(ts_full_file)\n",
    "ts_ref_filtered.dump(ts_ref_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare files for BEAGLE 4.1\n",
    "import gzip\n",
    "with gzip.open(prefix + \".ref.vcf.gz\", \"wt\") as f:\n",
    "    ts_ref_filtered.write_vcf(f)\n",
    "site_mask = np.zeros(ts_ref_filtered.num_sites, dtype=bool)\n",
    "site_mask[ungenotyped_markers] = True\n",
    "assert np.sum(site_mask) == len(ungenotyped_markers)\n",
    "with gzip.open(prefix + \".query.vcf.gz\", \"wt\") as f:\n",
    "    ts_query_filtered.write_vcf(f, site_mask=site_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
