{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f1c464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tskit 0.4.1\n",
      "tsinfer 0.2.3.dev9+gc8568d5\n",
      "msprime 1.1.1\n",
      "stdpopsim 0.1.2\n",
      "cyvcf2 0.30.14\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "sys.path.append(\"../modules/\")\n",
    "import mask_genotype\n",
    "import parse_vcf\n",
    "\n",
    "import tsinfer\n",
    "from tsinfer import make_ancestors_ts\n",
    "import tskit\n",
    "import msprime\n",
    "import stdpopsim\n",
    "import cyvcf2\n",
    "\n",
    "print(f\"tskit {tskit.__version__}\")\n",
    "print(f\"tsinfer {tsinfer.__version__}\")\n",
    "print(f\"msprime {msprime.__version__}\")\n",
    "print(f\"stdpopsim {stdpopsim.__version__}\")\n",
    "print(f\"cyvcf2 {cyvcf2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e64d1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_data_to_vcf(sample_data,\n",
    "                             individuals,\n",
    "                             samples,\n",
    "                             mask,\n",
    "                             out_vcf_file,\n",
    "                             contig_id,\n",
    "                             sequence_length_max = 1e12):\n",
    "    \"\"\"\n",
    "    Fields:\n",
    "    CHROM contig_id\n",
    "    POS row index in genotype_matrix\n",
    "    ID .\n",
    "    REF ancestral allele\n",
    "    ALT derived allele(s)\n",
    "    QUAL .\n",
    "    FILTER PASS\n",
    "    INFO\n",
    "    FORMAT GT\n",
    "    individual 0\n",
    "    individual 1\n",
    "    ...\n",
    "    individual n - 1; n = number of individuals\n",
    "    \"\"\"\n",
    "    CHROM = contig_id\n",
    "    ID = '.'\n",
    "    QUAL = '.'\n",
    "    FILTER = 'PASS'\n",
    "    FORMAT = 'GT'\n",
    "    \n",
    "    assert 2 * len(individuals) == len(samples),\\\n",
    "        \"Some individuals may not be diploid.\"\n",
    "    \n",
    "    # Assume that both sample and individual ids are ordered the same way.\n",
    "    individual_id_map = np.repeat(individuals, 2)\n",
    "    \n",
    "    header  = \"##fileformat=VCFv4.2\\n\"\\\n",
    "            + \"##source=tskit \" + tskit.__version__ + \"\\n\"\\\n",
    "            + \"##INFO=<ID=AA,Number=1,Type=String,Description=\\\"Ancestral Allele\\\">\\n\"\\\n",
    "            + \"##FORMAT=<ID=GT,Number=1,Type=String,Description=\\\"Genotype\\\">\\n\"\n",
    "    header += \"##contig=<ID=\" + contig_id + \",\" + \"length=\" + str(int(ts.sequence_length)) + \">\\n\"\n",
    "    header += \"\\t\".join(['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT']\\\n",
    "                        + [\"s\" + str(x) for x in individuals])\n",
    "    \n",
    "    with open(out_vcf_file, \"w\") as vcf:\n",
    "        vcf.write(header + \"\\n\")\n",
    "        for i, variant in enumerate(ts.variants()):\n",
    "            site_id = variant.site.id\n",
    "            POS = int(np.round(variant.site.position))\n",
    "            if POS > sequence_length_max:\n",
    "                break\n",
    "            # Since the tree sequence was produced using simulation,\n",
    "            #    there's no reference sequence other than the ancestral sequence.\n",
    "            REF = variant.site.ancestral_state\n",
    "            alt_alleles = list(set(variant.alleles) - {REF})\n",
    "            AA = variant.site.ancestral_state\n",
    "            ALT = \",\".join(alt_alleles) if len(alt_alleles) > 0 else \".\"\n",
    "            INFO = \"AA\" + \"=\" + AA\n",
    "            record = [str(x)\n",
    "                      for x\n",
    "                      in [CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, FORMAT]]\n",
    "            \n",
    "            for j in individuals:\n",
    "                sample_ids = [samples[x]\n",
    "                              for x\n",
    "                              in np.where(individual_id_map == j)[0].tolist()]\n",
    "                genotype = \"|\".join([str(variant.genotypes[k])\n",
    "                                     for k\n",
    "                                     in sample_ids])\n",
    "                if mask is not None\\\n",
    "                    and mask.query_position(individual = j, position = POS) == True:\n",
    "                    genotype = '.|.' # Or \"./.\"\n",
    "                record += [genotype]\n",
    "                \n",
    "            vcf.write(\"\\t\".join(record) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa396407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sourced and modified from:\n",
    "# https://tsinfer.readthedocs.io/en/latest/tutorial.html#data-example\n",
    "def add_populations(vcf,\n",
    "                    samples):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    pop_ids = [sample_name[0] for sample_name in vcf.samples]\n",
    "    pop_codes = np.unique(pop_ids)\n",
    "    pop_lookup = {}\n",
    "    for p in pop_codes:\n",
    "        pop_lookup[p] = samples.add_population(metadata = {\"name\" : p})\n",
    "    return [pop_lookup[pop_id] for pop_id in pop_ids]\n",
    "\n",
    "\n",
    "def add_diploid_individuals(vcf,\n",
    "                            samples,\n",
    "                            populations):\n",
    "    for name, population in zip(vcf.samples, populations):\n",
    "        samples.add_individual(ploidy = 2,\n",
    "                               metadata = {\"name\": name},\n",
    "                               population = population)\n",
    "\n",
    "\n",
    "def get_chromosome_length(vcf):\n",
    "    assert len(vcf.seqlens) == 1\n",
    "    return vcf.seqlens[0]\n",
    "\n",
    "\n",
    "def add_diploid_sites(vcf,\n",
    "                      samples,\n",
    "                      warn_monomorphic_sites = False):\n",
    "    \"\"\"\n",
    "    Read the sites in the VCF and add them to the samples object,\n",
    "    reordering the alleles to put the ancestral allele first,\n",
    "    if it is available.\n",
    "    \"\"\"\n",
    "    pos = 0\n",
    "    for variant in vcf:\n",
    "        # Check for duplicate site positions.\n",
    "        if pos == variant.POS:\n",
    "            raise ValueError(\"Duplicate positions for variant at position\", pos)\n",
    "        else:\n",
    "            pos = variant.POS\n",
    "        # Check that the genotypes are phased.\n",
    "        if any([not phased for _, _, phased in variant.genotypes]):\n",
    "            raise ValueError(\"Unphased genotypes for variant at position\", pos)\n",
    "        alleles = [variant.REF] + variant.ALT # Exactly as in the input VCF file.\n",
    "        if warn_monomorphic_sites:\n",
    "            if len(alleles) < 2:\n",
    "                print(f\"Monomorphic site at {pos}\")\n",
    "        ancestral = variant.INFO.get(\"AA\", variant.REF) # Dangerous action!!!\n",
    "        # Ancestral state must be first in the allele list.\n",
    "        ordered_alleles = [ancestral] + list(set(alleles) - {ancestral})\n",
    "        # Create an index mapping from the input VCF to tsinfer input.\n",
    "        allele_index = {\n",
    "            old_index: ordered_alleles.index(allele)\n",
    "            for old_index, allele in enumerate(alleles)\n",
    "        }\n",
    "        # When genotype is missing...\n",
    "        if variant.num_unknown > 0:\n",
    "            allele_index[-1] = tskit.MISSING_DATA\n",
    "            ordered_alleles += [None]\n",
    "        # Map original allele indexes to their indexes in the new alleles list.\n",
    "        genotypes = [\n",
    "            allele_index[old_index]\n",
    "            for row in variant.genotypes # cyvcf2 uses -1 to indicate missing data.\n",
    "            for old_index in row[0:2] # Each is a 3-tuple (allele 1, allele 2, is phased?).\n",
    "        ]\n",
    "        samples.add_site(pos,\n",
    "                         genotypes = genotypes,\n",
    "                         alleles = ordered_alleles)\n",
    "\n",
    "\n",
    "def create_sample_data_from_vcf_file(vcf_file):\n",
    "    vcf = cyvcf2.VCF(vcf_file,\n",
    "                     gts012 = False, # 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\n",
    "                     strict_gt = True)\n",
    "    with tsinfer.SampleData(\n",
    "        sequence_length = get_chromosome_length(vcf)\n",
    "    ) as samples:\n",
    "        populations = add_populations(vcf, samples)\n",
    "        add_diploid_individuals(vcf, samples, populations)\n",
    "        add_diploid_sites(vcf, samples)\n",
    "    return(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d0e8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vcf_file(vcf_file):\n",
    "    \"\"\"\n",
    "    If gt_types = False, then 0=HOM_REF, 1=HET, 2=UNKNOWN, the coordinates are 0-based.\n",
    "    It returns a list of dictionaries, each containing a VCF record.\n",
    "    \"\"\"\n",
    "    parsed_vcf = []\n",
    "    for variant in cyvcf2.VCF(vcf_file,\n",
    "                              gts012 = False, # 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\n",
    "                              strict_gt = True):\n",
    "        record = {\n",
    "            'ref': variant.REF,\n",
    "            'alt': variant.ALT,\n",
    "            'ctg': variant.CHROM, # Contig id/name\n",
    "            'pos': int(variant.start),\n",
    "            'aa' : variant.INFO.get('AA'), # Ancestral allele\n",
    "            'gt' : variant.genotypes\n",
    "        }\n",
    "        parsed_vcf.append(record)\n",
    "    return(parsed_vcf)\n",
    "\n",
    "\n",
    "def compare_vcf(vcf_1, vcf_2):\n",
    "    assert len(vcf_1) == len(vcf_2)\n",
    "    for i in range(len(vcf_1)):\n",
    "        is_valid_ref = vcf_1[i].get('ref') == vcf_2[i].get('ref')\n",
    "        is_valid_alt = vcf_1[i].get('alt') == vcf_2[i].get('alt')\n",
    "        is_valid_ctg = vcf_1[i].get('ctg') == vcf_2[i].get('ctg')\n",
    "        is_valid_pos = vcf_1[i].get('pos') == vcf_2[i].get('pos')\n",
    "        is_valid_aa  = vcf_1[i].get('aa' ) == vcf_2[i].get('aa' )\n",
    "        is_all_valid = np.all([is_valid_ref,\n",
    "                               is_valid_alt,\n",
    "                               is_valid_ctg,\n",
    "                               is_valid_pos,\n",
    "                               is_valid_aa])\n",
    "        if not is_all_valid:\n",
    "            return(False)\n",
    "    return(True)\n",
    "\n",
    "\n",
    "def get_common_positions_in_vcf(vcf_1, vcf_2):\n",
    "    pos_1 = []\n",
    "    pos_2 = []\n",
    "    for i, record in enumerate(vcf_1):\n",
    "        pos_1.append(record.get('pos'))\n",
    "    for i, record in enumerate(vcf_2):\n",
    "        pos_2.append(record.get('pos'))\n",
    "    # All positions should be unique.\n",
    "    assert len(pos_1) == len(set(pos_1)),\\\n",
    "        \"The positions in vcf_1 are not all unique.\"\n",
    "    assert len(pos_2) == len(set(pos_2)),\\\n",
    "        \"The positions in vcf_2 are not all unique.\"\n",
    "    common_pos = list(set.intersection(set(pos_1), set(pos_2)))\n",
    "    return(common_pos)\n",
    "\n",
    "\n",
    "def compare_variants(true_vcf_file,\n",
    "                     miss_vcf_file,\n",
    "                     imputed_vcf_file):\n",
    "    true_vcf    = parse_vcf_file(true_vcf_file)\n",
    "    miss_vcf    = parse_vcf_file(miss_vcf_file)\n",
    "    imputed_vcf = parse_vcf_file(imputed_vcf_file)    \n",
    "    assert compare_vcf(true_vcf, miss_vcf),\\\n",
    "        \"true_vcf and miss_vcf are not comparable.\"\n",
    "    # Imputed VCF file must have at most the number of positions as the true/miss VCF files.\n",
    "    common_pos = get_common_positions_in_vcf(miss_vcf, imputed_vcf)\n",
    "    # Number of genotypes imputed, correctly or not.\n",
    "    nbr_gt_total = 0\n",
    "    # Number of instances of genotypes correctly imputed.\n",
    "    nbr_gt_correct = 0\n",
    "    for i in range(len(imputed_vcf)):\n",
    "        if true_vcf[i]['pos'] not in common_pos\\\n",
    "            or miss_vcf[i]['pos'] not in common_pos\\\n",
    "            or imputed_vcf[i]['pos'] not in common_pos:\n",
    "            continue\n",
    "        imputed_bool = [x == [-1, -1, True]\n",
    "                        for x\n",
    "                        in miss_vcf[i]['gt']]\n",
    "        true_gt_oi = [x\n",
    "                      for x, y\n",
    "                      in zip(true_vcf[i]['gt'], imputed_bool) if y]\n",
    "        imputed_gt_oi = [x\n",
    "                         for x, y\n",
    "                         in zip(imputed_vcf[i]['gt'], imputed_bool) if y]\n",
    "        nbr_gt_total   += len(true_gt_oi)\n",
    "        nbr_gt_correct += np.count_nonzero([x == y\n",
    "                                            for x, y\n",
    "                                            in zip(true_gt_oi, imputed_gt_oi)])\n",
    "    concordance_rate = float(nbr_gt_correct) / float(nbr_gt_total)\n",
    "    #print(\",\".join([str(nbr_gt_total),\n",
    "    #                str(nbr_gt_correct),\n",
    "    #                str(concordance_rate)]))\n",
    "    return((nbr_gt_total,\n",
    "            nbr_gt_correct,\n",
    "            concordance_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a68edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_biallelic_sites(sample_data_1,\n",
    "                             sample_data_2):\n",
    "    variants_1 = sample_data_1.variants()\n",
    "    variants_2 = sample_data_2.variants()\n",
    "    # Keep only biallelic sites\n",
    "    sites_1 = []\n",
    "    sites_2 = []\n",
    "    for var_1, var_2 in zip(variants_1, variants_2):\n",
    "        assert var_1.site.position == var_2.site.position\n",
    "        alleles_1 = set(var_1.alleles) - {None}\n",
    "        alleles_2 = set(var_2.alleles) - {None}\n",
    "        if len(alleles_1) == 2\\\n",
    "            and len(alleles_2) == 2\\\n",
    "            and alleles_1 == alleles_2:\n",
    "            sites_1.append(var_1.site.id)\n",
    "            sites_2.append(var_2.site.id)\n",
    "    assert len(sites_1) == len(sites_2),\\\n",
    "        \"The number of site positions in sites_1 and sites_2 are different.\"\n",
    "    return(sites_1, sites_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23154dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_with_discretized_coordinates(ts):\n",
    "    ts_tables = ts.dump_tables()\n",
    "    ts_tables.sites.position = np.round(ts_tables.sites.position)\n",
    "    ts_tables.deduplicate_sites()\n",
    "    ts_tables.sort()\n",
    "    ts_tables.build_index()\n",
    "    ts_tables.compute_mutation_times()\n",
    "    ts_discretized = ts_tables.tree_sequence()\n",
    "    return(ts_discretized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8994b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_genotypes_using_tsinfer(ref_vcf_file,\n",
    "                                   miss_vcf_file,\n",
    "                                   imputed_vcf_file,\n",
    "                                   contig_id):\n",
    "    sd_ref  = create_sample_data_from_vcf_file(ref_vcf_file)\n",
    "    sd_miss = create_sample_data_from_vcf_file(miss_vcf_file)\n",
    "    ad_ref     = tsinfer.generate_ancestors(sample_data = sd_ref)\n",
    "    # This step is to infer a tree sequence from the sample data.\n",
    "    ts_anc_ref = tsinfer.match_ancestors(sample_data   = sd_ref,\n",
    "                                         ancestor_data = ad_ref)\n",
    "    ts_matched = tsinfer.match_samples(sample_data  = sd_miss,\n",
    "                                       ancestors_ts = ts_anc_ref)\n",
    "    with open(imputed_vcf_file, \"w\") as vcf:\n",
    "        ts_matched.write_vcf(vcf, contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bd1f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_genotypes_using_ts_only(ref_vcf_file,\n",
    "                                   miss_vcf_file,\n",
    "                                   imputed_vcf_file,\n",
    "                                   ts_anc_ref,\n",
    "                                   contig_id):\n",
    "    sd_ref  = create_sample_data_from_vcf_file(ref_vcf_file)\n",
    "    sd_miss = create_sample_data_from_vcf_file(miss_vcf_file)\n",
    "    ts_matched = tsinfer.match_samples(sample_data  = sd_miss,\n",
    "                                       ancestors_ts = ts_anc_ref)\n",
    "    with open(imputed_vcf_file, \"w\") as vcf:\n",
    "        ts_matched.write_vcf(vcf, contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1ea4b",
   "metadata": {},
   "source": [
    "## Create data sets via simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80ab9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ref   = 9_999\n",
    "#size_ref   = 1_000\n",
    "size_query =   100\n",
    "\n",
    "ploidy_level = 2\n",
    "eff_pop_size = 10_000\n",
    "\n",
    "num_replicates = 2\n",
    "\n",
    "num_missing_sites = 1_000\n",
    "\n",
    "#contig_id = '1'\n",
    "contig_id = 'chr20'\n",
    "\n",
    "base_dir = \"../data/modern_outofafrica_unequal_900505_p1000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f814f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate_map = msprime.RateMap.uniform(\n",
    "#    sequence_length = 1_000_000,\n",
    "#    rate = 1e-8\n",
    "#)\n",
    "# chr20:1 - chr20:849,253\n",
    "map_file = \"../hapmap/genetic_map_GRCh37_\" + contig_id + \"_reduced_v2.txt\"\n",
    "rate_map = msprime.RateMap.read_hapmap(\n",
    "    fileobj = map_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa5b6e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the reference panel is 1000\n",
      "Size of the query is 100\n",
      "Ploidy level is 2\n",
      "Population size is 10000\n",
      "Simulating 10 ts without duplicate site positions.\n",
      "Simulation of 10 ts took 0.14 seconds.\n"
     ]
    }
   ],
   "source": [
    "contig_id = '1'\n",
    "\n",
    "sample_set = [\n",
    "    msprime.SampleSet(num_samples = size_query,\n",
    "                      time = 0,\n",
    "                      #time = 100\n",
    "                      ploidy = 2),\n",
    "    msprime.SampleSet(num_samples = size_ref,\n",
    "                      time = 0,\n",
    "                      ploidy = 2)\n",
    "]\n",
    "\n",
    "print(f\"Size of the reference panel is {size_ref}\")\n",
    "print(f\"Size of the query is {size_query}\")\n",
    "print(f\"Ploidy level is {ploidy_level}\")\n",
    "print(f\"Population size is {eff_pop_size}\")\n",
    "\n",
    "src_ts = [] # List of full simulated ts.\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print(f\"Simulating {num_replicates} ts without duplicate site positions.\")\n",
    "success = 0\n",
    "while success < num_replicates:\n",
    "    sim_ts = msprime.sim_ancestry(\n",
    "        samples = sample_set,\n",
    "        population_size = eff_pop_size,\n",
    "        ploidy = ploidy_level,\n",
    "        model = \"hudson\",\n",
    "        recombination_rate = rate_map,\n",
    "        discrete_genome = True\n",
    "    )\n",
    "    \n",
    "    sim_mts = msprime.sim_mutations(\n",
    "        sim_ts,\n",
    "        rate = 1e-8, # per base per generation\n",
    "        discrete_genome = True\n",
    "    )\n",
    "    \n",
    "    #pos_discretized = np.round(sim_mts.tables.sites.position)\n",
    "    #num_pos_total   = len(pos_discretized)\n",
    "    #num_pos_unique  = len(np.unique(pos_discretized))\n",
    "    #if num_pos_total != num_pos_unique:\n",
    "    #    continue\n",
    "    #sim_mts_discretized = get_ts_with_discretized_coordinates(sim_mts)\n",
    "    #src_ts.append(sim_mts_discretized)\n",
    "    src_ts.append(sim_mts)\n",
    "    success += 1\n",
    "    \n",
    "toc = time.time()\n",
    "print(f\"Simulation of {num_replicates} ts took {round(toc - tic, 2)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4058b4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of (sampling and non-sampling) populations is 5.\n",
      "Number of sampling populations is 3.\n",
      "Populations in this model are: ['YRI', 'CEU', 'CHB', 'Neanderthal', 'ArchaicAFR'].\n",
      "Simulating 2 ts without duplicate site positions.\n",
      "Simulation of 2 ts took 6.44 seconds.\n"
     ]
    }
   ],
   "source": [
    "species = stdpopsim.get_species(\"HomSap\")\n",
    "#contig  = species.get_contig(contig_id)\n",
    "contig  = stdpopsim.Contig(mutation_rate = 1e-8,\n",
    "                           recombination_map = rate_map)\n",
    "model   = species.get_demographic_model('OutOfAfricaArchaicAdmixture_5R19')\n",
    "\n",
    "print(f\"Number of (sampling and non-sampling) populations is {model.num_populations}.\")\n",
    "print(f\"Number of sampling populations is {model.num_sampling_populations}.\")\n",
    "print(f\"Populations in this model are: {[pop.id for pop in model.populations]}.\")\n",
    "\n",
    "samples = model.get_samples(2 * (size_query + int(size_ref * 0.05)), # YRI\n",
    "                            2 * int(size_ref * 0.05),                # CHB\n",
    "                            2 * int(size_ref * 0.90))                # CEU\n",
    "\n",
    "engine = stdpopsim.get_engine('msprime')\n",
    "\n",
    "src_ts = [] # List of full simulated ts.\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print(f\"Simulating {num_replicates} ts without duplicate site positions.\")\n",
    "success = 0\n",
    "while success < num_replicates:\n",
    "    sim_ts = engine.simulate(model,\n",
    "                             contig,\n",
    "                             samples,\n",
    "                             discrete_genome = True)\n",
    "    \n",
    "    sim_mts = msprime.sim_mutations(sim_ts,\n",
    "                                    rate = 1e-8,\n",
    "                                    discrete_genome = True,\n",
    "                                    keep = False)\n",
    "    \n",
    "    #pos_discretized = np.round(sim_mts.tables.sites.position)\n",
    "    #num_pos_total   = len(pos_discretized)\n",
    "    #num_pos_unique  = len(np.unique(pos_discretized))\n",
    "    #if num_pos_total != num_pos_unique:\n",
    "    #    print(f\"{num_pos_total} {num_pos_unique}\")\n",
    "    #    continue\n",
    "    #sim_mts_discretized = get_ts_with_discretized_coordinates(sim_mts)\n",
    "    #src_ts.append(sim_mts_discretized)\n",
    "    src_ts.append(sim_mts)\n",
    "    success += 1\n",
    "    \n",
    "toc = time.time()\n",
    "print(f\"Simulation of {num_replicates} ts took {round(toc - tic, 2)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a12ae6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ref = int(size_ref * 0.05) + int(size_ref * 0.05) + int(size_ref * 0.90) # rounding errors\n",
    "\n",
    "individuals_query = np.arange(size_query)\n",
    "samples_query     = np.arange(2 * size_query)\n",
    "\n",
    "individuals_ref   = np.arange(size_query,\n",
    "                              size_query + size_ref)\n",
    "samples_ref       = np.arange(2 * size_query,\n",
    "                              2 * (size_query + size_ref))\n",
    "\n",
    "gt_mask = mask_genotype.MissingGenotypeMask(individuals = individuals_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fce9cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ts 0.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 1.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n"
     ]
    }
   ],
   "source": [
    "anc_ts = [] # List of simulated ancestor ts.\n",
    "\n",
    "for i, ts in enumerate(src_ts):\n",
    "    print(f\"Processing ts {i}.\")\n",
    "    ref_vcf_file  = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    true_vcf_file = base_dir + \"true/\" + \"true.\" + str(i) + \".vcf\"\n",
    "    miss_vcf_file = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    ts_anc_ref_file = base_dir + \"ts_anc_ref/\" + \"ts_anc_ref.\" + str(i) + \".trees\"\n",
    "    \n",
    "    sd_all = tsinfer.SampleData.from_tree_sequence(ts, use_sites_time = False)\n",
    "    \n",
    "    sd_ref   = sd_all.subset(individuals = individuals_ref)\n",
    "    sd_query = sd_all.subset(individuals = individuals_query)\n",
    "    \n",
    "    sites_to_keep     = find_biallelic_sites(sd_ref, sd_query)\n",
    "    sd_ref_filtered   =   sd_ref.subset(sites = sites_to_keep[0])\n",
    "    sd_query_filtered = sd_query.subset(sites = sites_to_keep[1])\n",
    "    \n",
    "    # TODO: Refactor.\n",
    "    # TODO: Remove some monomorphic sites?\n",
    "    print(\"Printing ancestors ts.\")\n",
    "    sim_ts_anc_ref = make_ancestors_ts(samples = samples_ref,\n",
    "                                       ts = ts,\n",
    "                                       remove_leaves = True)\n",
    "    tmp_tables = sim_ts_anc_ref.dump_tables()\n",
    "    tmp_tables.populations.metadata_schema = tskit.MetadataSchema(schema = None)\n",
    "    sim_ts_anc_ref = tmp_tables.tree_sequence()\n",
    "    anc_ts.append(sim_ts_anc_ref)\n",
    "    sim_ts_anc_ref.dump(ts_anc_ref_file)\n",
    "    \n",
    "    print(\"Printing reference panel VCF.\")\n",
    "    print_sample_data_to_vcf(sample_data = sd_ref_filtered,\n",
    "                             individuals = individuals_ref,\n",
    "                             samples = samples_ref,\n",
    "                             mask = None,\n",
    "                             out_vcf_file = ref_vcf_file,\n",
    "                             contig_id = contig_id,\n",
    "                             sequence_length_max = 1e24)\n",
    "    \n",
    "    print(\"Printing query VCF with non-missing genotypes.\")\n",
    "    print_sample_data_to_vcf(sample_data = sd_query_filtered,\n",
    "                             individuals = individuals_query,\n",
    "                             samples = samples_query,\n",
    "                             mask = None,\n",
    "                             out_vcf_file = true_vcf_file,\n",
    "                             contig_id = contig_id,\n",
    "                             sequence_length_max = 1e24)\n",
    "    \n",
    "    print(\"Printing query VCF with missing genotypes.\")\n",
    "    print_sample_data_to_vcf(sample_data = sd_query_filtered,\n",
    "                             individuals = individuals_query,\n",
    "                             samples = samples_query,\n",
    "                             mask = gt_mask,\n",
    "                             out_vcf_file = miss_vcf_file,\n",
    "                             contig_id = contig_id,\n",
    "                             sequence_length_max = 1e24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da1bc5",
   "metadata": {},
   "source": [
    "## Impute genotypes using ts with true genealogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f2d72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(anc_ts)):\n",
    "    ref_vcf_file     = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsonly/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    impute_genotypes_using_ts_only(ref_vcf_file = ref_vcf_file,\n",
    "                                   miss_vcf_file = miss_vcf_file,\n",
    "                                   imputed_vcf_file = imputed_vcf_file,\n",
    "                                   ts_anc_ref = anc_ts[i],\n",
    "                                   contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9786689d",
   "metadata": {},
   "source": [
    "## Impute genotypes using tsinfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e143b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(src_ts)):\n",
    "    ref_vcf_file     = base_dir + \"ref/\" + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsinfer/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    impute_genotypes_using_tsinfer(ref_vcf_file = ref_vcf_file,\n",
    "                                   miss_vcf_file = miss_vcf_file,\n",
    "                                   imputed_vcf_file = imputed_vcf_file,\n",
    "                                   contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38e462",
   "metadata": {},
   "source": [
    "## Impute genotypes using BEAGLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ff859033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_outofafrica_unequal_900505_p1000/ref/ref.0.vcf gt=../data/modern_outofafrica_unequal_900505_p1000/miss/miss.0.vcf out=../data/modern_outofafrica_unequal_900505_p1000/imputed_beagle/imputed.0\n",
      "\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_outofafrica_unequal_900505_p1000/ref/ref.1.vcf gt=../data/modern_outofafrica_unequal_900505_p1000/miss/miss.1.vcf out=../data/modern_outofafrica_unequal_900505_p1000/imputed_beagle/imputed.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beagle_exe = \"../analysis/beagle/beagle.28Jun21.220.jar\"\n",
    "map_file = \"../hapmap/genetic_map_GRCh37_chr20_reduced_plink_v2.txt\"\n",
    "\n",
    "for i in range(len(src_ts)):\n",
    "    ref_vcf_file     = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_beagle/\" + \"imputed.\" + str(i)\n",
    "    beagle_cmd = [\n",
    "        \"java\", \"-jar\", beagle_exe,\n",
    "        #\"map=\" + map_file,\n",
    "        \"ref=\" + ref_vcf_file,\n",
    "        \"gt=\"  + miss_vcf_file,\n",
    "        \"out=\" + imputed_vcf_file\n",
    "    ]\n",
    "    beagle_cmd = \" \".join(beagle_cmd)\n",
    "    print(beagle_cmd + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3f76d",
   "metadata": {},
   "source": [
    "## Get imputation accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c4025cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing imputation accuracy metrics for ts only.\n",
      "11999,11989,0.9991665972164347\n",
      "12206,12197,0.9992626577093233\n"
     ]
    }
   ],
   "source": [
    "# Get imputation accuracy metrics for ts with true genealogy.\n",
    "print(\"Computing imputation accuracy metrics for ts only.\")\n",
    "results = []\n",
    "for i in range(len(anc_ts)):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsonly/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    stats = compare_variants(true_vcf_file, miss_vcf_file, imputed_vcf_file)\n",
    "    results.append(stats)\n",
    "for y in results:\n",
    "    print(\",\".join([str(x) for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0caf474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing imputation accuracy metrics for tsinfer WITH inference.\n",
      "963,929,0.9646936656282451\n",
      "883,851,0.9637599093997735\n",
      "974,937,0.9620123203285421\n",
      "946,912,0.9640591966173362\n",
      "873,846,0.9690721649484536\n",
      "910,886,0.9736263736263736\n",
      "880,833,0.946590909090909\n",
      "868,845,0.9735023041474654\n",
      "916,895,0.9770742358078602\n",
      "906,879,0.9701986754966887\n"
     ]
    }
   ],
   "source": [
    "# Get imputation accuracy metrics for tsinfer.\n",
    "print(\"Computing imputation accuracy metrics for tsinfer WITH inference.\")\n",
    "results = []\n",
    "for i in range(len(src_ts)):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsinfer/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    stats = compare_variants(true_vcf_file, miss_vcf_file, imputed_vcf_file)\n",
    "    results.append(stats)\n",
    "for y in results:\n",
    "    print(\",\".join([str(x) for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "46ca517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing imputation accuracy metrics for BEAGLE.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::vcf_parse] Contig 'chr20' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr20' is not defined in the header. (Quick workaround: index the file with tabix.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11999,11931,0.994332861071756\n",
      "12206,12146,0.9950843847288219\n"
     ]
    }
   ],
   "source": [
    "# Get imputation accuracy metrics for BEAGLE.\n",
    "print(\"Computing imputation accuracy metrics for BEAGLE.\")\n",
    "results = []\n",
    "for i in range(len(src_ts)):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_beagle/\" + \"imputed.\" + str(i) + \".vcf.gz\"\n",
    "    stats = compare_variants(true_vcf_file, miss_vcf_file, imputed_vcf_file)\n",
    "    results.append(stats)\n",
    "for y in results:\n",
    "    print(\",\".join([str(x) for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af0f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
