{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1c464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tskit 0.4.1\n",
      "tsinfer 0.2.2\n",
      "msprime 1.1.1\n",
      "stdpopsim 0.1.2\n",
      "cyvcf2 0.30.14\n"
     ]
    }
   ],
   "source": [
    "import tsinfer\n",
    "from tsinfer import make_ancestors_ts\n",
    "import tskit\n",
    "import msprime\n",
    "import stdpopsim\n",
    "import cyvcf2\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "sys.path.append(\"modules/\")\n",
    "import mask_genotype\n",
    "\n",
    "print(f\"tskit {tskit.__version__}\")\n",
    "print(f\"tsinfer {tsinfer.__version__}\")\n",
    "print(f\"msprime {msprime.__version__}\")\n",
    "print(f\"stdpopsim {stdpopsim.__version__}\")\n",
    "print(f\"cyvcf2 {cyvcf2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64d1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_data_to_vcf(sample_data,\n",
    "                             individuals,\n",
    "                             samples,\n",
    "                             mask,\n",
    "                             out_vcf_file,\n",
    "                             contig_id):\n",
    "    \"\"\"\n",
    "    Fields:\n",
    "    CHROM contig_id\n",
    "    POS row index in genotype_matrix\n",
    "    ID .\n",
    "    REF ancestral allele\n",
    "    ALT derived allele(s)\n",
    "    QUAL .\n",
    "    FILTER PASS\n",
    "    INFO\n",
    "    FORMAT GT\n",
    "    individual 0\n",
    "    individual 1\n",
    "    ...\n",
    "    individual n - 1; n = number of individuals\n",
    "    \"\"\"\n",
    "    CHROM = contig_id\n",
    "    ID = '.'\n",
    "    QUAL = '.'\n",
    "    FILTER = 'PASS'\n",
    "    FORMAT = 'GT'\n",
    "    \n",
    "    assert 2 * len(individuals) == len(samples),\\\n",
    "        \"Some individuals may not be diploid.\"\n",
    "    \n",
    "    # Assume that both sample and individual ids are ordered the same way.\n",
    "    individual_id_map = np.repeat(individuals, 2)\n",
    "    \n",
    "    header  = \"##fileformat=VCFv4.2\\n\"\\\n",
    "            + \"##source=tskit \" + tskit.__version__ + \"\\n\"\\\n",
    "            + \"##INFO=<ID=AA,Number=1,Type=String,Description=\\\"Ancestral Allele\\\">\\n\"\\\n",
    "            + \"##FORMAT=<ID=GT,Number=1,Type=String,Description=\\\"Genotype\\\">\\n\"\n",
    "    header += \"##contig=<ID=\" + contig_id + \",\" + \"length=\" + str(int(ts.sequence_length)) + \">\\n\"\n",
    "    header += \"\\t\".join(['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT']\\\n",
    "                        + [\"s\" + str(x) for x in individuals])\n",
    "    \n",
    "    with open(out_vcf_file, \"w\") as vcf:\n",
    "        vcf.write(header + \"\\n\")\n",
    "        for i, variant in enumerate(ts.variants()):\n",
    "            site_id = variant.site.id\n",
    "            POS = int(np.round(variant.site.position))\n",
    "            # Since the tree sequence was produced using simulation,\n",
    "            #    there's no reference sequence other than the ancestral sequence.\n",
    "            REF = variant.site.ancestral_state\n",
    "            alt_alleles = list(set(variant.alleles) - {REF})\n",
    "            ALT = \",\".join(alt_alleles) if len(alt_alleles) > 0 else \".\"\n",
    "            INFO = \"AA\" + \"=\" + variant.site.ancestral_state\n",
    "            record = [str(x)\n",
    "                      for x\n",
    "                      in [CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, FORMAT]]\n",
    "            \n",
    "            for j in individuals:\n",
    "                sample_ids = [samples[x]\n",
    "                              for x\n",
    "                              in np.where(individual_id_map == j)[0].tolist()]\n",
    "                genotype = \"|\".join([str(variant.genotypes[k])\n",
    "                                     for k\n",
    "                                     in sample_ids])\n",
    "                if mask is not None\\\n",
    "                    and mask.query_position(individual = j, position = POS) == True:\n",
    "                    genotype = '.|.' # Or \"./.\"\n",
    "                record += [genotype]\n",
    "                \n",
    "            vcf.write(\"\\t\".join(record) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa396407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sourced and modified from:\n",
    "# https://tsinfer.readthedocs.io/en/latest/tutorial.html#data-example\n",
    "def add_populations(vcf,\n",
    "                    samples):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    pop_ids = [sample_name[0] for sample_name in vcf.samples]\n",
    "    pop_codes = np.unique(pop_ids)\n",
    "    pop_lookup = {}\n",
    "    for p in pop_codes:\n",
    "        pop_lookup[p] = samples.add_population(metadata = {\"name\" : p})\n",
    "    return [pop_lookup[pop_id] for pop_id in pop_ids]\n",
    "\n",
    "\n",
    "def add_diploid_individuals(vcf,\n",
    "                            samples,\n",
    "                            populations):\n",
    "    for name, population in zip(vcf.samples, populations):\n",
    "        samples.add_individual(ploidy = 2,\n",
    "                               metadata = {\"name\": name},\n",
    "                               population = population)\n",
    "\n",
    "\n",
    "def get_chromosome_length(vcf):\n",
    "    assert len(vcf.seqlens) == 1\n",
    "    return vcf.seqlens[0]\n",
    "\n",
    "\n",
    "def add_diploid_sites(vcf,\n",
    "                      samples,\n",
    "                      warn_monomorphic_sites = False):\n",
    "    \"\"\"\n",
    "    Read the sites in the VCF and add them to the samples object,\n",
    "    reordering the alleles to put the ancestral allele first,\n",
    "    if it is available.\n",
    "    \"\"\"\n",
    "    pos = 0\n",
    "    for variant in vcf:\n",
    "        # Check for duplicate site positions.\n",
    "        if pos == variant.POS:\n",
    "            raise ValueError(\"Duplicate positions for variant at position\", pos)\n",
    "        else:\n",
    "            pos = variant.POS\n",
    "        # Check that the genotypes are phased.\n",
    "        if any([not phased for _, _, phased in variant.genotypes]):\n",
    "            raise ValueError(\"Unphased genotypes for variant at position\", pos)\n",
    "        alleles = [variant.REF] + variant.ALT # Exactly as in the input VCF file.\n",
    "        if warn_monomorphic_sites:\n",
    "            if len(alleles) < 2:\n",
    "                print(f\"Monomorphic site at {pos}\")\n",
    "        ancestral = variant.INFO.get(\"AA\", variant.REF) # Dangerous action!!!\n",
    "        # Ancestral state must be first in the allele list.\n",
    "        ordered_alleles = [ancestral] + list(set(alleles) - {ancestral})\n",
    "        # Create an index mapping from the input VCF to tsinfer input.\n",
    "        allele_index = {\n",
    "            old_index: ordered_alleles.index(allele)\n",
    "            for old_index, allele in enumerate(alleles)\n",
    "        }\n",
    "        # When genotype is missing...\n",
    "        if variant.num_unknown > 0:\n",
    "            allele_index[-1] = tskit.MISSING_DATA\n",
    "            ordered_alleles += [None]\n",
    "        # Map original allele indexes to their indexes in the new alleles list.\n",
    "        genotypes = [\n",
    "            allele_index[old_index]\n",
    "            for row in variant.genotypes # cyvcf2 uses -1 to indicate missing data.\n",
    "            for old_index in row[0:2] # Each is a 3-tuple (allele 1, allele 2, is phased?).\n",
    "        ]\n",
    "        samples.add_site(pos,\n",
    "                         genotypes = genotypes,\n",
    "                         alleles = ordered_alleles)\n",
    "\n",
    "\n",
    "def create_sample_data_from_vcf_file(vcf_file):\n",
    "    vcf = cyvcf2.VCF(vcf_file,\n",
    "                     gts012 = False, # 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\n",
    "                     strict_gt = True)\n",
    "    with tsinfer.SampleData(\n",
    "        sequence_length = get_chromosome_length(vcf)\n",
    "    ) as samples:\n",
    "        populations = add_populations(vcf, samples)\n",
    "        add_diploid_individuals(vcf, samples, populations)\n",
    "        add_diploid_sites(vcf, samples)\n",
    "    return(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0e8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vcf_file(vcf_file):\n",
    "    \"\"\"\n",
    "    If gt_types = False, then 0=HOM_REF, 1=HET, 2=UNKNOWN, the coordinates are 0-based.\n",
    "    It returns a list of dictionaries, each containing a VCF record.\n",
    "    \"\"\"\n",
    "    parsed_vcf = []\n",
    "    for variant in cyvcf2.VCF(vcf_file,\n",
    "                              gts012 = False, # 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\n",
    "                              strict_gt = True):\n",
    "        record = {\n",
    "            'ref': variant.REF,\n",
    "            'alt': variant.ALT,\n",
    "            'ctg': variant.CHROM, # Contig id/name\n",
    "            'pos': int(variant.start),\n",
    "            'aa' : variant.INFO.get('AA'), # Ancestral allele\n",
    "            'gt' : variant.genotypes\n",
    "        }\n",
    "        parsed_vcf.append(record)\n",
    "    return(parsed_vcf)\n",
    "\n",
    "\n",
    "def compare_vcf(vcf_1, vcf_2):\n",
    "    assert len(vcf_1) == len(vcf_2)\n",
    "    for i in range(len(vcf_1)):\n",
    "        is_valid_ref = vcf_1[i].get('ref') == vcf_2[i].get('ref')\n",
    "        is_valid_alt = vcf_1[i].get('alt') == vcf_2[i].get('alt')\n",
    "        is_valid_ctg = vcf_1[i].get('ctg') == vcf_2[i].get('ctg')\n",
    "        is_valid_pos = vcf_1[i].get('pos') == vcf_2[i].get('pos')\n",
    "        is_valid_aa  = vcf_1[i].get('aa' ) == vcf_2[i].get('aa' )\n",
    "        is_all_valid = np.all([is_valid_ref,\n",
    "                               is_valid_alt,\n",
    "                               is_valid_ctg,\n",
    "                               is_valid_pos,\n",
    "                               is_valid_aa])\n",
    "        if not is_all_valid:\n",
    "            return(False)\n",
    "    return(True)\n",
    "\n",
    "\n",
    "def get_common_positions_in_vcf(vcf_1, vcf_2):\n",
    "    pos_1 = []\n",
    "    pos_2 = []\n",
    "    for i, record in enumerate(vcf_1):\n",
    "        pos_1.append(record.get('pos'))\n",
    "    for i, record in enumerate(vcf_2):\n",
    "        pos_2.append(record.get('pos'))\n",
    "    # All positions should be unique.\n",
    "    assert len(pos_1) == len(set(pos_1)),\\\n",
    "        \"The positions in vcf_1 are not all unique.\"\n",
    "    assert len(pos_2) == len(set(pos_2)),\\\n",
    "        \"The positions in vcf_2 are not all unique.\"\n",
    "    common_pos = list(set.intersection(set(pos_1), set(pos_2)))\n",
    "    return(common_pos)\n",
    "\n",
    "\n",
    "def compare_variants(true_vcf_file,\n",
    "                     miss_vcf_file,\n",
    "                     imputed_vcf_file):\n",
    "    true_vcf    = parse_vcf_file(true_vcf_file)\n",
    "    miss_vcf    = parse_vcf_file(miss_vcf_file)\n",
    "    imputed_vcf = parse_vcf_file(imputed_vcf_file)    \n",
    "    assert compare_vcf(true_vcf, miss_vcf),\\\n",
    "        \"true_vcf and miss_vcf are not comparable.\"\n",
    "    # Imputed VCF file must have at most the number of positions as the true/miss VCF files.\n",
    "    common_pos = get_common_positions_in_vcf(miss_vcf, imputed_vcf)\n",
    "    # Number of genotypes imputed, correctly or not.\n",
    "    nbr_gt_total = 0\n",
    "    # Number of instances of genotypes correctly imputed.\n",
    "    nbr_gt_correct = 0\n",
    "    for i in range(len(imputed_vcf)):\n",
    "        if true_vcf[i]['pos'] not in common_pos\\\n",
    "            or miss_vcf[i]['pos'] not in common_pos\\\n",
    "            or imputed_vcf[i]['pos'] not in common_pos:\n",
    "            continue\n",
    "        imputed_bool = [x == [-1, -1, True]\n",
    "                        for x\n",
    "                        in miss_vcf[i]['gt']]\n",
    "        true_gt_oi = [x\n",
    "                      for x, y\n",
    "                      in zip(true_vcf[i]['gt'], imputed_bool) if y]\n",
    "        imputed_gt_oi = [x\n",
    "                         for x, y\n",
    "                         in zip(imputed_vcf[i]['gt'], imputed_bool) if y]\n",
    "        nbr_gt_total   += len(true_gt_oi)\n",
    "        nbr_gt_correct += np.count_nonzero([x == y\n",
    "                                            for x, y\n",
    "                                            in zip(true_gt_oi, imputed_gt_oi)])\n",
    "    concordance_rate = float(nbr_gt_correct) / float(nbr_gt_total)\n",
    "    #print(\",\".join([str(nbr_gt_total),\n",
    "    #                str(nbr_gt_correct),\n",
    "    #                str(concordance_rate)]))\n",
    "    return((nbr_gt_total,\n",
    "            nbr_gt_correct,\n",
    "            concordance_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a68edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_monomorphic_sites(sample_data_1,\n",
    "                             sample_data_2):\n",
    "    variants_1 = sample_data_1.variants()\n",
    "    variants_2 = sample_data_2.variants()\n",
    "    # Keep only biallelic sites\n",
    "    sites_1 = []\n",
    "    sites_2 = []\n",
    "    for var_1, var_2 in zip(variants_1, variants_2):\n",
    "        assert var_1.site.position == var_2.site.position\n",
    "        alleles_1 = set(var_1.alleles) - {None}\n",
    "        alleles_2 = set(var_2.alleles) - {None}\n",
    "        if len(alleles_1) == 2\\\n",
    "            and len(alleles_2) == 2\\\n",
    "            and alleles_1 == alleles_2:\n",
    "            sites_1.append(var_1.site.id)\n",
    "            sites_2.append(var_2.site.id)\n",
    "    assert len(sites_1) == len(sites_2),\\\n",
    "        \"The number of site positions in sites_1 and sites_2 are different.\"\n",
    "    return(sites_1, sites_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23154dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_with_discretized_coordinates(ts):\n",
    "    ts_tables = ts.dump_tables()\n",
    "    ts_tables.sites.position = np.round(ts_tables.sites.position)\n",
    "    ts_tables.deduplicate_sites()\n",
    "    ts_tables.sort()\n",
    "    ts_tables.build_index()\n",
    "    ts_tables.compute_mutation_times()\n",
    "    ts_discretized = ts_tables.tree_sequence()\n",
    "    return(ts_discretized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8994b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_genotypes_using_tsinfer_with_inference(ref_vcf_file,\n",
    "                                                  miss_vcf_file,\n",
    "                                                  imputed_vcf_file,\n",
    "                                                  contig_id):\n",
    "    sd_ref  = create_sample_data_from_vcf_file(ref_vcf_file)\n",
    "    sd_miss = create_sample_data_from_vcf_file(miss_vcf_file)\n",
    "    \n",
    "    ad_ref     = tsinfer.generate_ancestors(sample_data = sd_ref)\n",
    "    ts_anc_ref = tsinfer.match_ancestors(sample_data   = sd_ref,\n",
    "                                         ancestor_data = ad_ref)\n",
    "    ts_matched = tsinfer.match_samples(sample_data  = sd_miss,\n",
    "                                       ancestors_ts = ts_anc_ref)\n",
    "    \n",
    "    with open(imputed_vcf_file, \"w\") as vcf:\n",
    "        ts_matched.write_vcf(vcf, contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd1f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_genotypes_using_tsinfer_without_inference(ts_anc_ref,\n",
    "                                                     ref_vcf_file,\n",
    "                                                     miss_vcf_file,\n",
    "                                                     imputed_vcf_file,\n",
    "                                                     contig_id):\n",
    "    sd_ref  = create_sample_data_from_vcf_file(ref_vcf_file)\n",
    "    sd_miss = create_sample_data_from_vcf_file(miss_vcf_file)\n",
    "    \n",
    "    ts_matched = tsinfer.match_samples(sample_data  = sd_miss,\n",
    "                                       ancestors_ts = ts_anc_ref)\n",
    "    \n",
    "    with open(imputed_vcf_file, \"w\") as vcf:\n",
    "        ts_matched.write_vcf(vcf, contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1ea4b",
   "metadata": {},
   "source": [
    "## Create data sets via simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ab9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ref   = 100\n",
    "size_query =  10\n",
    "\n",
    "ploidy_level = 2\n",
    "eff_pop_size = 10_000\n",
    "\n",
    "num_replicates = 1\n",
    "\n",
    "num_missing_sites = 1_000\n",
    "\n",
    "contig_id = 'chr20'\n",
    "\n",
    "base_dir = \"data/modern_outofafrica_equal_p1000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f814f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_map = msprime.RateMap.uniform(\n",
    "    sequence_length = 1_000_000,\n",
    "    rate = 1e-8\n",
    ")\n",
    "# chr20:1 - chr20:849,253\n",
    "#map_file = \"./hapmap/genetic_map_GRCh37_\" + contig_id + \"_reduced.txt\"\n",
    "#rate_map = msprime.RateMap.read_hapmap(\n",
    "#    fileobj = map_file\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa5b6e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the reference panel is 1000\n",
      "Size of the query is 100\n",
      "Ploidy level is 2\n",
      "Population size is 10000\n",
      "Simulating 1 ts without duplicate site positions.\n",
      "Simulation of 1 ts took 0.06 seconds.\n"
     ]
    }
   ],
   "source": [
    "sample_set = [\n",
    "    msprime.SampleSet(num_samples = size_query,\n",
    "                      time = 0,\n",
    "                      #time = 100\n",
    "                      ploidy = 2),\n",
    "    msprime.SampleSet(num_samples = size_ref,\n",
    "                      time = 0,\n",
    "                      ploidy = 2)\n",
    "]\n",
    "\n",
    "print(f\"Size of the reference panel is {size_ref}\")\n",
    "print(f\"Size of the query is {size_query}\")\n",
    "print(f\"Ploidy level is {ploidy_level}\")\n",
    "print(f\"Population size is {eff_pop_size}\")\n",
    "\n",
    "src_ts = [] # List of full simulated ts.\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print(f\"Simulating {num_replicates} ts without duplicate site positions.\")\n",
    "success = 0\n",
    "while success < num_replicates:\n",
    "    sim_ts = msprime.sim_ancestry(\n",
    "        samples = sample_set,\n",
    "        population_size = eff_pop_size,\n",
    "        ploidy = ploidy_level,\n",
    "        model = \"hudson\",\n",
    "        recombination_rate = rate_map,\n",
    "        discrete_genome = False\n",
    "    )\n",
    "    \n",
    "    sim_mts = msprime.sim_mutations(\n",
    "        sim_ts,\n",
    "        rate = 1e-8,\n",
    "        discrete_genome = False\n",
    "    )\n",
    "    \n",
    "    pos_discretized = np.round(sim_mts.tables.sites.position)\n",
    "    num_pos_total   = len(pos_discretized)\n",
    "    num_pos_unique  = len(np.unique(pos_discretized))\n",
    "    if num_pos_total != num_pos_unique:\n",
    "        continue\n",
    "        \n",
    "    sim_mts_discretized = get_ts_with_discretized_coordinates(sim_mts)\n",
    "    src_ts.append(sim_mts_discretized)\n",
    "    success += 1\n",
    "    \n",
    "toc = time.time()\n",
    "print(f\"Simulation of {num_replicates} ts took {round(toc - tic, 2)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4058b4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of (sampling and non-sampling) populations is 5.\n",
      "Number of sampling populations is 3.\n",
      "Populations in this model are: ['YRI', 'CEU', 'CHB', 'Neanderthal', 'ArchaicAFR'].\n",
      "Simulating 1 ts without duplicate site positions.\n",
      "Simulation of 1 ts took 47.35 seconds.\n"
     ]
    }
   ],
   "source": [
    "contig_id = 'chr20'\n",
    "\n",
    "species = stdpopsim.get_species(\"HomSap\")\n",
    "contig  = species.get_contig(\"chr20\")\n",
    "model   = species.get_demographic_model('OutOfAfricaArchaicAdmixture_5R19')\n",
    "\n",
    "print(f\"Number of (sampling and non-sampling) populations is {model.num_populations}.\")\n",
    "print(f\"Number of sampling populations is {model.num_sampling_populations}.\")\n",
    "print(f\"Populations in this model are: {[pop.id for pop in model.populations]}.\")\n",
    "\n",
    "samples = model.get_samples(2 * (size_query + size_ref),\n",
    "                            2 * size_ref,\n",
    "                            2 * size_ref)\n",
    "\n",
    "engine = stdpopsim.get_engine('msprime')\n",
    "\n",
    "src_ts = [] # List of full simulated ts.\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print(f\"Simulating {num_replicates} ts without duplicate site positions.\")\n",
    "success = 0\n",
    "while success < num_replicates:\n",
    "    sim_mts = engine.simulate(model,\n",
    "                              contig,\n",
    "                              samples,\n",
    "                              discrete_genome = False,\n",
    "                              sequence_length = 100)\n",
    "    \n",
    "    #pos_discretized = np.round(sim_mts.tables.sites.position * 10)\n",
    "    #num_pos_total   = len(pos_discretized)\n",
    "    #num_pos_unique  = len(np.unique(pos_discretized))\n",
    "    #if num_pos_total != num_pos_unique:\n",
    "    #    print(f\"{num_pos_total} {num_pos_unique}\")\n",
    "    #    continue\n",
    "    \n",
    "    sim_mts_discretized = get_ts_with_discretized_coordinates(sim_mts)\n",
    "    src_ts.append(sim_mts_discretized)\n",
    "    success += 1\n",
    "    \n",
    "toc = time.time()\n",
    "print(f\"Simulation of {num_replicates} ts took {round(toc - tic, 2)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12ae6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals_query = np.arange(size_query)\n",
    "samples_query     = np.arange(2 * size_query)\n",
    "\n",
    "individuals_ref   = np.arange(size_query,\n",
    "                              size_query + 3 * size_ref)\n",
    "samples_ref       = np.arange(2 * size_query,\n",
    "                              2 * (size_query + 3 * size_ref))\n",
    "\n",
    "gt_mask = mask_genotype.MissingGenotypeMask(individuals = individuals_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce9cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ts 0.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n"
     ]
    }
   ],
   "source": [
    "anc_ts = [] # List of simulated ancestor ts.\n",
    "\n",
    "for i, ts in enumerate(src_ts):\n",
    "    print(f\"Processing ts {i}.\")\n",
    "    ref_vcf_file  = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    true_vcf_file = base_dir + \"true/\" + \"true.\" + str(i) + \".vcf\"\n",
    "    miss_vcf_file = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    ts_anc_ref_file = base_dir + \"ts_anc_ref/\" + \"ts_anc_ref.\" + str(i) + \".trees\"\n",
    "    \n",
    "    sd_all = tsinfer.SampleData.from_tree_sequence(ts, use_sites_time = False)\n",
    "    \n",
    "    sd_ref   = sd_all.subset(individuals = individuals_ref)\n",
    "    sd_query = sd_all.subset(individuals = individuals_query)\n",
    "    \n",
    "    #sites_to_keep     = filter_monomorphic_sites(sd_ref, sd_query)\n",
    "    #sd_ref_filtered   =   sd_ref.subset(sites = sites_to_keep[0])\n",
    "    #sd_query_filtered = sd_query.subset(sites = sites_to_keep[1])\n",
    "    \n",
    "    # TODO: Refactor.\n",
    "    # TODO: Remove some monomorphic sites?\n",
    "    print(\"Printing ancestors ts.\")\n",
    "    sim_ts_anc_ref = make_ancestors_ts(samples = samples_ref,\n",
    "                                       ts = ts,\n",
    "                                       remove_leaves = True)\n",
    "    tmp_tables = sim_ts_anc_ref.dump_tables()\n",
    "    tmp_tables.populations.metadata_schema = tskit.MetadataSchema(schema = None)\n",
    "    sim_ts_anc_ref = tmp_tables.tree_sequence()\n",
    "    anc_ts.append(sim_ts_anc_ref)\n",
    "    sim_ts_anc_ref.dump(ts_anc_ref_file)\n",
    "    \n",
    "    print(\"Printing reference panel VCF.\")\n",
    "    print_sample_data_to_vcf(sample_data = sd_ref,\n",
    "                             individuals = individuals_ref,\n",
    "                             samples = samples_ref,\n",
    "                             mask = None,\n",
    "                             out_vcf_file = ref_vcf_file,\n",
    "                             contig_id = contig_id)\n",
    "    \n",
    "    print(\"Printing query VCF with non-missing genotypes.\")\n",
    "    print_sample_data_to_vcf(sample_data = sd_query,\n",
    "                             individuals = individuals_query,\n",
    "                             samples = samples_query,\n",
    "                             mask = None,\n",
    "                             out_vcf_file = true_vcf_file,\n",
    "                             contig_id = contig_id)\n",
    "    \n",
    "    print(\"Printing query VCF with missing genotypes.\")\n",
    "    print_sample_data_to_vcf(sample_data = sd_query,\n",
    "                             individuals = individuals_query,\n",
    "                             samples = samples_query,\n",
    "                             mask = gt_mask,\n",
    "                             out_vcf_file = miss_vcf_file,\n",
    "                             contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9786689d",
   "metadata": {},
   "source": [
    "## Impute genotypes using tsinfer WITH inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e143b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(src_ts)):\n",
    "    ref_vcf_file     = base_dir + \"ref/\" + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsinfer_with_infer/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    impute_genotypes_using_tsinfer_with_inference(ref_vcf_file = ref_vcf_file,\n",
    "                                                  miss_vcf_file = miss_vcf_file,\n",
    "                                                  imputed_vcf_file = imputed_vcf_file,\n",
    "                                                  contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c766f68",
   "metadata": {},
   "source": [
    "## Impute genotypes using tsinfer WITHOUT inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ba497c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid left coordinates",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m miss_vcf_file    \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiss/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiss.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vcf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m imputed_vcf_file \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed_tsinfer_without_infer/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vcf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mimpute_genotypes_using_tsinfer_without_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_anc_ref\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43manc_ts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mref_vcf_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mref_vcf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mmiss_vcf_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmiss_vcf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mimputed_vcf_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimputed_vcf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mcontig_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontig_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mimpute_genotypes_using_tsinfer_without_inference\u001b[0;34m(ts_anc_ref, ref_vcf_file, miss_vcf_file, imputed_vcf_file, contig_id)\u001b[0m\n\u001b[1;32m      6\u001b[0m sd_ref  \u001b[38;5;241m=\u001b[39m create_sample_data_from_vcf_file(ref_vcf_file)\n\u001b[1;32m      7\u001b[0m sd_miss \u001b[38;5;241m=\u001b[39m create_sample_data_from_vcf_file(miss_vcf_file)\n\u001b[0;32m----> 9\u001b[0m ts_matched \u001b[38;5;241m=\u001b[39m \u001b[43mtsinfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msd_miss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mancestors_ts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mts_anc_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(imputed_vcf_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m vcf:\n\u001b[1;32m     13\u001b[0m     ts_matched\u001b[38;5;241m.\u001b[39mwrite_vcf(vcf, contig_id \u001b[38;5;241m=\u001b[39m contig_id)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/tsinfer/inference.py:604\u001b[0m, in \u001b[0;36mmatch_samples\u001b[0;34m(sample_data, ancestors_ts, recombination_rate, mismatch_ratio, path_compression, simplify, indexes, force_sample_times, num_threads, recombination, mismatch, precision, stabilise_node_ordering, extended_checks, engine, progress_monitor)\u001b[0m\n\u001b[1;32m    602\u001b[0m sample_data\u001b[38;5;241m.\u001b[39m_check_finalised()\n\u001b[1;32m    603\u001b[0m progress_monitor \u001b[38;5;241m=\u001b[39m _get_progress_monitor(progress_monitor, match_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 604\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mSampleMatcher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mancestors_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecombination_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecombination_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmismatch_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmismatch_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecombination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecombination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmismatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextended_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m sample_indexes \u001b[38;5;241m=\u001b[39m check_sample_indexes(sample_data, indexes)\n\u001b[1;32m    619\u001b[0m sample_times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28mlen\u001b[39m(sample_indexes), dtype\u001b[38;5;241m=\u001b[39msample_data\u001b[38;5;241m.\u001b[39mindividuals_time\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    621\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/tsinfer/inference.py:1482\u001b[0m, in \u001b[0;36mSampleMatcher.__init__\u001b[0;34m(self, sample_data, ancestors_ts, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mancestors_ts_tables \u001b[38;5;241m=\u001b[39m ancestors_ts\u001b[38;5;241m.\u001b[39mdump_tables()\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(sample_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mancestors_ts_tables\u001b[38;5;241m.\u001b[39msites\u001b[38;5;241m.\u001b[39mposition, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1482\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_tree_sequence_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# Map from input sample indexes (IDs in the SampleData file) to the\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;66;03m# node ID in the tree sequence.\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_id_map \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/tsinfer/inference.py:1501\u001b[0m, in \u001b[0;36mSampleMatcher.restore_tree_sequence_builder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1499\u001b[0m left \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_map, edges\u001b[38;5;241m.\u001b[39mleft)\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_map[left] \u001b[38;5;241m!=\u001b[39m edges\u001b[38;5;241m.\u001b[39mleft):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid left coordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1502\u001b[0m right \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_map, edges\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_map[right] \u001b[38;5;241m!=\u001b[39m edges\u001b[38;5;241m.\u001b[39mright):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid left coordinates"
     ]
    }
   ],
   "source": [
    "for i in range(len(src_ts)):\n",
    "    ref_vcf_file     = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsinfer_without_infer/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    impute_genotypes_using_tsinfer_without_inference(ts_anc_ref = anc_ts[i],\n",
    "                                                     ref_vcf_file = ref_vcf_file,\n",
    "                                                     miss_vcf_file = miss_vcf_file,\n",
    "                                                     imputed_vcf_file = imputed_vcf_file,\n",
    "                                                     contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38e462",
   "metadata": {},
   "source": [
    "## Impute genotypes using BEAGLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff859033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.0.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.0.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.0\n",
      "\n",
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.1.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.1.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.1\n",
      "\n",
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.2.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.2.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.2\n",
      "\n",
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.3.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.3.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.3\n",
      "\n",
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.4.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.4.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.4\n",
      "\n",
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.5.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.5.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.5\n",
      "\n",
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.6.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.6.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.6\n",
      "\n",
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.7.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.7.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.7\n",
      "\n",
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.8.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.8.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.8\n",
      "\n",
      "java -jar analysis/beagle/beagle.28Jun21.220.jar ref=data/modern_panmictic_uniform_p1000/ref/ref.9.vcf gt=data/modern_panmictic_uniform_p1000/miss/miss.9.vcf out=data/modern_panmictic_uniform_p1000/imputed_beagle/imputed.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beagle_exe = \"analysis/beagle/beagle.28Jun21.220.jar\"\n",
    "map_file = \"hapmap/genetic_map_GRCh37_chr20_reduced_plink.txt\"\n",
    "\n",
    "for i in range(len(src_ts)):\n",
    "    ref_vcf_file     = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_beagle/\" + \"imputed.\" + str(i)\n",
    "    beagle_cmd = [\n",
    "        \"java\", \"-jar\", beagle_exe,\n",
    "        #\"map=\" + map_file,\n",
    "        \"ref=\" + ref_vcf_file,\n",
    "        \"gt=\"  + miss_vcf_file,\n",
    "        \"out=\" + imputed_vcf_file\n",
    "    ]\n",
    "    beagle_cmd = \" \".join(beagle_cmd)\n",
    "    print(beagle_cmd + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3f76d",
   "metadata": {},
   "source": [
    "## Get imputation accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c4025cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing imputation accuracy metrics for tsinfer WITHOUT inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::hts_open_format] Failed to open file \"data/modern_outofafrica_equal_p1000/imputed_tsinfer_without_infer/imputed.0.vcf\" : No such file or directory\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Error opening data/modern_outofafrica_equal_p1000/imputed_tsinfer_without_infer/imputed.0.vcf",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     miss_vcf_file    \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiss/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiss.\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vcf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     imputed_vcf_file \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed_tsinfer_without_infer/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vcf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_variants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_vcf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmiss_vcf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimputed_vcf_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(stats)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mcompare_variants\u001b[0;34m(true_vcf_file, miss_vcf_file, imputed_vcf_file)\u001b[0m\n\u001b[1;32m     59\u001b[0m true_vcf    \u001b[38;5;241m=\u001b[39m parse_vcf_file(true_vcf_file)\n\u001b[1;32m     60\u001b[0m miss_vcf    \u001b[38;5;241m=\u001b[39m parse_vcf_file(miss_vcf_file)\n\u001b[0;32m---> 61\u001b[0m imputed_vcf \u001b[38;5;241m=\u001b[39m \u001b[43mparse_vcf_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimputed_vcf_file\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m compare_vcf(true_vcf, miss_vcf),\\\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_vcf and miss_vcf are not comparable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Imputed VCF file must have at most the number of positions as the true/miss VCF files.\u001b[39;00m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mparse_vcf_file\u001b[0;34m(vcf_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mIf gt_types = False, then 0=HOM_REF, 1=HET, 2=UNKNOWN, the coordinates are 0-based.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mIt returns a list of dictionaries, each containing a VCF record.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m parsed_vcf \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variant \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcyvcf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVCF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvcf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mgts012\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mstrict_gt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m     10\u001b[0m     record \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m: variant\u001b[38;5;241m.\u001b[39mREF,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malt\u001b[39m\u001b[38;5;124m'\u001b[39m: variant\u001b[38;5;241m.\u001b[39mALT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m : variant\u001b[38;5;241m.\u001b[39mgenotypes\n\u001b[1;32m     17\u001b[0m     }\n\u001b[1;32m     18\u001b[0m     parsed_vcf\u001b[38;5;241m.\u001b[39mappend(record)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/cyvcf2/cyvcf2.pyx:258\u001b[0m, in \u001b[0;36mcyvcf2.cyvcf2.VCF.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/cyvcf2/cyvcf2.pyx:190\u001b[0m, in \u001b[0;36mcyvcf2.cyvcf2.HTSFile._open_htsfile\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Error opening data/modern_outofafrica_equal_p1000/imputed_tsinfer_without_infer/imputed.0.vcf"
     ]
    }
   ],
   "source": [
    "# Get imputation accuracy metrics for tsinfer without inference.\n",
    "print(\"Computing imputation accuracy metrics for tsinfer WITHOUT inference.\")\n",
    "results = []\n",
    "for i in range(len(src_ts)):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsinfer_without_infer/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    stats = compare_variants(true_vcf_file, miss_vcf_file, imputed_vcf_file)\n",
    "    results.append(stats)\n",
    "for y in results:\n",
    "    print(\",\".join([str(x) for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0caf474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing imputation accuracy metrics for tsinfer WITH inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     miss_vcf_file    \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiss/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiss.\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vcf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     imputed_vcf_file \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed_tsinfer_with_infer/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vcf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_variants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_vcf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmiss_vcf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimputed_vcf_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(stats)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mcompare_variants\u001b[0;34m(true_vcf_file, miss_vcf_file, imputed_vcf_file)\u001b[0m\n\u001b[1;32m     69\u001b[0m nbr_gt_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(imputed_vcf)):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m true_vcf[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m common_pos\\\n\u001b[0;32m---> 72\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mmiss_vcf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcommon_pos\u001b[49m\\\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m imputed_vcf[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m common_pos:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     imputed_bool \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;241m==\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m]\n\u001b[1;32m     76\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m x\n\u001b[1;32m     77\u001b[0m                     \u001b[38;5;129;01min\u001b[39;00m miss_vcf[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get imputation accuracy metrics for tsinfer with inference.\n",
    "print(\"Computing imputation accuracy metrics for tsinfer WITH inference.\")\n",
    "results = []\n",
    "for i in range(len(src_ts)):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsinfer_with_infer/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    stats = compare_variants(true_vcf_file, miss_vcf_file, imputed_vcf_file)\n",
    "    results.append(stats)\n",
    "for y in results:\n",
    "    print(\",\".join([str(x) for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46ca517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing imputation accuracy metrics for BEAGLE.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3411,3312,0.9709762532981531\n",
      "3425,3316,0.9681751824817518\n",
      "3044,2924,0.9605781865965834\n",
      "3137,3047,0.9713101689512272\n",
      "3376,3275,0.9700829383886256\n",
      "3242,3107,0.9583590376310919\n",
      "3515,3314,0.9428165007112376\n",
      "2960,2872,0.9702702702702702\n",
      "3236,3158,0.9758961681087762\n",
      "3118,3045,0.9765875561257216\n"
     ]
    }
   ],
   "source": [
    "# Get imputation accuracy metrics for BEAGLE.\n",
    "print(\"Computing imputation accuracy metrics for BEAGLE.\")\n",
    "results = []\n",
    "for i in range(len(src_ts)):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_beagle/\" + \"imputed.\" + str(i) + \".vcf.gz\"\n",
    "    stats = compare_variants(true_vcf_file, miss_vcf_file, imputed_vcf_file)\n",
    "    results.append(stats)\n",
    "for y in results:\n",
    "    print(\",\".join([str(x) for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fe0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
