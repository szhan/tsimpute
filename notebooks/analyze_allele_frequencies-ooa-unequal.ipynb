{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8028421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyvcf2 0.30.14\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cyvcf2\n",
    "\n",
    "print(f\"cyvcf2 {cyvcf2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0449fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_maf_from_vcf(vcf_file,\n",
    "                         categorize = False,\n",
    "                         verbose = False):\n",
    "    num_singletons = 0\n",
    "    \n",
    "    maf_dict = OrderedDict()\n",
    "    \n",
    "    for variant in cyvcf2.VCF(vcf_file):\n",
    "        # Assume that there are only biallelic sites.\n",
    "        num_genotypes_00 = 0\n",
    "        num_genotypes_01 = 0 # Includes genotype 10\n",
    "        num_genotypes_11 = 0\n",
    "        num_alleles_0 = 0\n",
    "        num_alleles_1 = 0\n",
    "        num_alleles_2 = 0\n",
    "        \n",
    "        for genotype in variant.genotypes:\n",
    "            # Tally up genotypes.\n",
    "            if   genotype[0] == 0 and genotype[0] == 0:\n",
    "                num_genotypes_00 += 1\n",
    "            elif genotype[0] == 1 and genotype[1] == 1:\n",
    "                num_genotypes_11 += 1\n",
    "            else:\n",
    "                num_genotypes_01 += 1 # Or 10\n",
    "                \n",
    "            # Tally up alleles in genotype.\n",
    "            if   genotype[0] == 0:\n",
    "                num_alleles_0 += 1\n",
    "            elif genotype[0] == 1:\n",
    "                num_alleles_1 += 1\n",
    "            elif genotype[0] == 2:\n",
    "                num_alleles_2 += 1\n",
    "                if verbose:\n",
    "                    print(f\"WARNING: Multi-alleic site at {variant.start} \" +\\\n",
    "                          f\"with genotype {genotype}.\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"WARNING: Allele value in {genotype}\" +\\\n",
    "                          f\"at {variant.start} is not recognized.\")\n",
    "                \n",
    "            # Tally up alleles in genotype.\n",
    "            if   genotype[1] == 0:\n",
    "                num_alleles_0 += 1\n",
    "            elif genotype[1] == 1:\n",
    "                num_alleles_1 += 1\n",
    "            elif genotype[1] == 2:\n",
    "                num_alleles_2 += 1\n",
    "                if verbose:\n",
    "                    print(f\"WARNING:\" + \" \" +\\\n",
    "                          f\"Multi-alleic site at {variant.start}\" + \" \" +\\\n",
    "                          f\"with genotype {genotype}.\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"WARNING:\" + \" \" +\\\n",
    "                          f\"Allele value in {genotype}\" + \" \" +\\\n",
    "                          f\"at {variant.start} is not recognized.\")\n",
    "                \n",
    "        #assert min(num_alleles_0, num_alleles_1) > num_alleles_2,\\\n",
    "        #    \"Allele 2 occurs at higher frequency than alleles 0 and 1.\"\n",
    "        \n",
    "        num_alleles_total = num_alleles_0 + num_alleles_1 + num_alleles_2\n",
    "        # MAF is defined as the frequency of the SECOND most common allele.\n",
    "        minor_allele = 0 if num_alleles_0 < num_alleles_1 else 1\n",
    "        maf = float(min(num_alleles_0, num_alleles_1)) / float(num_alleles_total)\n",
    "        \n",
    "        # Key: Site position\n",
    "        # Val: (MAF or MAF category, minor allele,)\n",
    "        if categorize:\n",
    "            #if maf < 0.0000002:\n",
    "            #    maf_dict[variant.start] = ('(0.00000%, 0.00002%)', minor_allele)\n",
    "            #elif maf >= 0.0000002 and maf < 0.0000005:\n",
    "            #    maf_dict[variant.start] = ('[0.00002%, 0.00005%)', minor_allele)\n",
    "            #elif maf >= 0.0000005 and maf < 0.000001:\n",
    "            #    maf_dict[variant.start] = ('[0.00005%,  0.0001%)', minor_allele)\n",
    "            #elif maf >= 0.000001 and maf < 0.000002:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0001%,  0.0002%)', minor_allele)\n",
    "            #elif maf >= 0.000002 and maf < 0.000005:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0002%,  0.0005%)', minor_allele)\n",
    "            #elif maf >= 0.000005 and maf < 0.00001:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0005%,  0.0010%)', minor_allele)\n",
    "            #elif maf >= 0.00001 and maf < 0.00002:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0010%,  0.0020%)', minor_allele)\n",
    "            #elif maf >= 0.00002 and maf < 0.00005:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0020%,  0.0050%)', minor_allele)\n",
    "            #elif maf >= 0.00005 and maf < 0.00010:\n",
    "            #    maf_dict[variant.start] = ('[ 0.0050%,  0.0100%)', minor_allele)\n",
    "            if maf < 0.00010:\n",
    "                maf_dict[variant.start] = ('( 0.0000%,  0.0100%)', minor_allele)\n",
    "            elif maf >= 0.00010 and maf < 0.00100:\n",
    "                maf_dict[variant.start] = ('[ 0.0100%,  0.1000%)', minor_allele)\n",
    "            elif maf >= 0.00100 and maf < 0.00200:\n",
    "                maf_dict[variant.start] = ('[ 0.1000%,  0.2000%)', minor_allele)\n",
    "            elif maf >= 0.00200 and maf < 0.00300:\n",
    "                maf_dict[variant.start] = ('[ 0.2000%,  0.3000%)', minor_allele)\n",
    "            elif maf >= 0.00300 and maf < 0.00400:\n",
    "                maf_dict[variant.start] = ('[ 0.3000%,  0.4000%)', minor_allele)\n",
    "            elif maf >= 0.00400 and maf < 0.00500:\n",
    "                maf_dict[variant.start] = ('[ 0.4000%,  0.5000%)', minor_allele)\n",
    "            elif maf >= 0.00500 and maf < 0.01000:\n",
    "                maf_dict[variant.start] = ('[ 0.5000%,  1.0000%)', minor_allele)\n",
    "            elif maf >= 0.01000 and maf < 0.02000:\n",
    "                maf_dict[variant.start] = ('[ 1.0000%,  2.0000%)', minor_allele)\n",
    "            elif maf >= 0.02000 and maf < 0.05000:\n",
    "                maf_dict[variant.start] = ('[ 2.0000%,  5.0000%)', minor_allele)\n",
    "            elif maf >= 0.05000 and maf < 0.10000:\n",
    "                maf_dict[variant.start] = ('[ 5.0000%, 10.0000%)', minor_allele)\n",
    "            elif maf >= 0.10000 and maf < 0.20000:\n",
    "                maf_dict[variant.start] = ('[10.0000%, 20.0000%)', minor_allele)\n",
    "            elif maf >= 0.20000 and maf < 0.30000:\n",
    "                maf_dict[variant.start] = ('[20.0000%, 30.0000%)', minor_allele)\n",
    "            elif maf >= 0.30000 and maf < 0.40000:\n",
    "                maf_dict[variant.start] = ('[30.0000%, 40.0000%)', minor_allele)\n",
    "            elif maf >= 0.40000 and maf <= 0.50000:\n",
    "                maf_dict[variant.start] = ('[40.0000%, 50.0000%]', minor_allele)\n",
    "            else:\n",
    "                print(f\"MAF value {maf} is out of recognized range.\")\n",
    "        else:\n",
    "            maf_dict[variant.start] = (maf, minor_allele)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"MAF is {round(maf, 4)}\"\\\n",
    "                  f\" at {variant.start}\"\\\n",
    "                  f\" with {variant.aaf}\"\\\n",
    "                  f\" in {maf_dict[variant.start]}\")\n",
    "        \n",
    "        if min(num_alleles_0, num_alleles_1) == 1:\n",
    "            num_singletons += 1\n",
    "            if verbose:\n",
    "                print(f\"Singleton at position {variant.start}\")\n",
    "                \n",
    "    if verbose:\n",
    "        print(f\"Number of singletons in vcf file {i} is {num_singletons}\")\n",
    "    \n",
    "    return(maf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff355954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vcf_file(vcf_file):\n",
    "    \"\"\"\n",
    "    If gt_types = False, then 0=HOM_REF, 1=HET, 2=UNKNOWN, the coordinates are 0-based.\n",
    "    It returns a list of dictionaries, each containing a VCF record.\n",
    "    \"\"\"\n",
    "    parsed_vcf = []\n",
    "    \n",
    "    for variant in cyvcf2.VCF(vcf_file,\n",
    "                              gts012 = False, # 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\n",
    "                              strict_gt = True):\n",
    "        record = {\n",
    "            'ref': variant.REF,\n",
    "            'alt': variant.ALT,\n",
    "            'ctg': variant.CHROM, # Contig id/name\n",
    "            'pos': int(variant.start),\n",
    "            'aa' : variant.INFO.get('AA'), # Ancestral allele\n",
    "            'gt' : variant.genotypes\n",
    "        }\n",
    "        \n",
    "        parsed_vcf.append(record)\n",
    "        \n",
    "    return(parsed_vcf)\n",
    "\n",
    "\n",
    "def compare_vcf(vcf_1, vcf_2):\n",
    "    assert len(vcf_1) == len(vcf_2),\\\n",
    "        \"vcf_1 and vcf_2 have different number of records.\"\n",
    "    \n",
    "    for i in range(len(vcf_1)):\n",
    "        is_valid_ref = vcf_1[i].get('ref') == vcf_2[i].get('ref')\n",
    "        #is_valid_alt = vcf_1[i].get('alt') == vcf_2[i].get('alt')\n",
    "        is_valid_ctg = vcf_1[i].get('ctg') == vcf_2[i].get('ctg')\n",
    "        is_valid_pos = vcf_1[i].get('pos') == vcf_2[i].get('pos')\n",
    "        #is_valid_aa  = vcf_1[i].get('aa' ) == vcf_2[i].get('aa' )\n",
    "        is_all_valid = np.all([is_valid_ref,\n",
    "                               #is_valid_alt,\n",
    "                               is_valid_ctg,\n",
    "                               is_valid_pos\n",
    "                               #is_valid_aa\n",
    "                              ])\n",
    "        \n",
    "        if not is_all_valid:\n",
    "            pos_1 = vcf_1[i].get('pos')\n",
    "            pos_2 = vcf_2[i].get('pos')\n",
    "            print(f\"{is_valid_ref} {is_valid_alt} {is_valid_ctg} {is_valid_pos}\")\n",
    "            print(f\"{vcf_1[i].get('alt')} {vcf_2[i].get('alt')}\")\n",
    "            print(f\"Incomparable records at {pos_1} and {pos_2}.\")\n",
    "            return(False)\n",
    "        \n",
    "    return(True)\n",
    "\n",
    "\n",
    "def get_common_positions_in_vcf(vcf_1, vcf_2):\n",
    "    pos_1 = []\n",
    "    pos_2 = []\n",
    "    for i, record in enumerate(vcf_1):\n",
    "        pos_1.append(record.get('pos'))\n",
    "    for i, record in enumerate(vcf_2):\n",
    "        pos_2.append(record.get('pos'))\n",
    "        \n",
    "    # All positions should be unique.\n",
    "    assert len(pos_1) == len(set(pos_1)),\\\n",
    "        \"The positions in vcf_1 are not all unique.\"\n",
    "    assert len(pos_2) == len(set(pos_2)),\\\n",
    "        \"The positions in vcf_2 are not all unique.\"\n",
    "    \n",
    "    common_pos = list(set.intersection(set(pos_1), set(pos_2)))\n",
    "    \n",
    "    return(common_pos)\n",
    "\n",
    "\n",
    "def compare_variants(true_vcf_file,\n",
    "                     miss_vcf_file,\n",
    "                     imputed_vcf_file,\n",
    "                     maf_dict,\n",
    "                     ploidy_level,\n",
    "                     verbose = False):\n",
    "    assert ploidy_level == 1 or ploidy_level == 2,\\\n",
    "        f\"ploidy_level {ploidy_level} is not recognized.\"\n",
    "    \n",
    "    if ploidy_level == 1:\n",
    "        MISSING_GENOTYPE_CONSTANT = [-1, False]\n",
    "    else:\n",
    "        MISSING_GENOTYPE_CONSTANT = [-1, -1, True]\n",
    "    \n",
    "    true_vcf    = parse_vcf_file(true_vcf_file)\n",
    "    miss_vcf    = parse_vcf_file(miss_vcf_file)\n",
    "    imputed_vcf = parse_vcf_file(imputed_vcf_file)\n",
    "    \n",
    "    new_true_vcf, new_miss_vcf, new_imputed_vcf = filter_non_biallelic_sites(true_vcf, miss_vcf, imputed_vcf)\n",
    "    \n",
    "    # Reencode genotype from 0|0, 0|1, 1|0, and 1|1 to 1, 2, 2, and 3, respectively.\n",
    "    reencode_map = {\n",
    "        (0, 0, True) : 1, # AA\n",
    "        (0, 1, True) : 2, # AB, treated as equal to BA\n",
    "        (1, 0, True) : 2, # BA\n",
    "        (1, 1, True) : 3, # BB\n",
    "        (0, False)   : 1, # A\n",
    "        (1, False)   : 2, # B\n",
    "    }\n",
    "    \n",
    "    # Imputed VCF file must have at most the number of positions as the true/miss VCF files.\n",
    "    nbr_gt_missing_all = 0 # Number of genotypes imputed, correctly or not.\n",
    "    nbr_gt_correct_all = 0 # Number of instances of genotypes correctly imputed.\n",
    "    \n",
    "    # Key   : MAF category\n",
    "    # Value : (number of total, number of correctly imputed, percent correctly imputed)\n",
    "    maf_categories = OrderedDict()\n",
    "    #maf_categories['(0.00000%, 0.00002%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[0.00002%, 0.00005%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[0.00005%,  0.0001%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0001%,  0.0002%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0002%,  0.0005%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0005%,  0.0010%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0010%,  0.0020%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0020%,  0.0050%)'] = [0.0, 0.0, 0.0]\n",
    "    #maf_categories['[ 0.0050%,  0.0100%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['( 0.0000%,  0.0100%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.0100%,  0.1000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.1000%,  0.2000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.2000%,  0.3000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.3000%,  0.4000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.4000%,  0.5000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 0.5000%,  1.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 1.0000%,  2.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 2.0000%,  5.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[ 5.0000%, 10.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[10.0000%, 20.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[20.0000%, 30.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[30.0000%, 40.0000%)'] = [0.0, 0.0, 0.0]\n",
    "    maf_categories['[40.0000%, 50.0000%]'] = [0.0, 0.0, 0.0]\n",
    "    \n",
    "    for i in range(len(new_imputed_vcf)):\n",
    "        position = new_imputed_vcf[i]['pos']\n",
    "        \n",
    "        if position not in maf_dict:\n",
    "            continue\n",
    "            \n",
    "        maf, minor_allele = maf_dict[position]\n",
    "        \n",
    "        missing_bool   = [x == MISSING_GENOTYPE_CONSTANT for x in new_miss_vcf[i]['gt']]\n",
    "        true_gt_oi     = [x for x, y in zip(new_true_vcf[i]['gt'],    missing_bool) if y]\n",
    "        imputed_gt_oi  = [x for x, y in zip(new_imputed_vcf[i]['gt'], missing_bool) if y]\n",
    "        \n",
    "        assert len(true_gt_oi) == len(imputed_gt_oi),\\\n",
    "            f\"true_gt_oi {len(true_gt_oi)}\" + \" and \" +\\\n",
    "            f\"imputed_gt_oi {len(imputed_gt_oi)}\" + \" \" +\\\n",
    "            f\"are not of the same length.\"\n",
    "        \n",
    "        true_gt_oi_minor    = [x\n",
    "                               for x, y\n",
    "                               in zip(true_gt_oi, imputed_gt_oi)\n",
    "                               if x == [minor_allele, False]\n",
    "                              ]\n",
    "        imputed_gt_oi_minor = [y\n",
    "                               for x, y\n",
    "                               in zip(true_gt_oi, imputed_gt_oi)\n",
    "                               if x == [minor_allele, False]\n",
    "                              ]\n",
    "        \n",
    "        nbr_gt_missing = len(imputed_gt_oi_minor)\n",
    "        if nbr_gt_missing == 0:\n",
    "            continue\n",
    "            \n",
    "        true_gt_reencoded    = [reencode_map[tuple(x)] for x in true_gt_oi_minor]\n",
    "        imputed_gt_reencoded = [reencode_map[tuple(x)] for x in imputed_gt_oi_minor]\n",
    "        \n",
    "        nbr_gt_correct       = np.count_nonzero([x == y\n",
    "                                                 for x, y\n",
    "                                                 in zip(true_gt_reencoded, imputed_gt_reencoded)])\n",
    "        \n",
    "        if verbose:\n",
    "            if nbr_gt_missing != nbr_gt_correct:\n",
    "                print(f\"{nbr_gt_missing},\\\n",
    "                        {nbr_gt_correct},\\\n",
    "                        {round(float(nbr_gt_correct) / float(nbr_gt_missing), 6)},\\\n",
    "                        {position},\\\n",
    "                        {maf[position]}\")\n",
    "                \n",
    "        maf_categories[maf][0] += nbr_gt_missing\n",
    "        maf_categories[maf][1] += nbr_gt_correct\n",
    "        \n",
    "        nbr_gt_missing_all += nbr_gt_missing # Update overall tally.\n",
    "        nbr_gt_correct_all += nbr_gt_correct # Update overall tally.\n",
    "        \n",
    "    for i, category in enumerate(maf_categories):\n",
    "        if float(maf_categories[category][0]) == 0:\n",
    "            concordance_rate = -1\n",
    "        else:\n",
    "            concordance_rate = round(maf_categories[category][1] / maf_categories[category][0], 6)\n",
    "        maf_categories[category][2] = concordance_rate\n",
    "        \n",
    "    overall_concordance_rate = float(nbr_gt_correct_all) / float(nbr_gt_missing_all)\n",
    "    \n",
    "    return((nbr_gt_missing_all, nbr_gt_correct_all, overall_concordance_rate, maf_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7613aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_non_biallelic_sites(vcf_1, vcf_2, vcf_3):\n",
    "    assert compare_vcf(vcf_1, vcf_2),\\\n",
    "        \"vcf_1 and vcf_2 are not comparable.\"\n",
    "    assert compare_vcf(vcf_2, vcf_3),\\\n",
    "        \"vcf_2 and vcf_3 are not comparable.\"\n",
    "    \n",
    "    new_vcf_1 = []\n",
    "    new_vcf_2 = []\n",
    "    new_vcf_3 = []\n",
    "    \n",
    "    for i in range(len(vcf_1)):\n",
    "        is_biallelic_1 = len(set(vcf_1[i]['alt']) - {'.'}) == 1\n",
    "        is_biallelic_2 = len(set(vcf_2[i]['alt']) - {'.'}) == 1\n",
    "        is_biallelic_3 = len(set(vcf_3[i]['alt']) - {'.'}) == 1\n",
    "        \n",
    "        if is_biallelic_1 and is_biallelic_2 and is_biallelic_3:\n",
    "            new_vcf_1.append(vcf_1[i])\n",
    "            new_vcf_2.append(vcf_2[i])\n",
    "            new_vcf_3.append(vcf_3[i])\n",
    "            \n",
    "    assert  len(new_vcf_1) == len(new_vcf_2)\\\n",
    "        and len(new_vcf_1) == len(new_vcf_3),\\\n",
    "        \"The number of site positions in \" +\\\n",
    "        \"new_vcf_1, new_vcf_2, and new_vcf_3\" +\\\n",
    "        \"are different.\"\n",
    "        \n",
    "    return(new_vcf_1, new_vcf_2, new_vcf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a3b8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fe8aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.0.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.1.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.2.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.3.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.4.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.5.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.6.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.7.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.8.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.9.vcf\n"
     ]
    }
   ],
   "source": [
    "maf_dict = []\n",
    "for i in np.arange(10):\n",
    "    vcf_file = base_dir + \"ref/ref.\" + str(i) + \".vcf\"\n",
    "    print(f\"{vcf_file}\")\n",
    "    maf_dict.append(compute_maf_from_vcf(vcf_file,\n",
    "                                         categorize = True,\n",
    "                                         verbose = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84f30b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.0.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.1.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.2.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.3.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.4.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.5.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.6.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.7.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.8.vcf\n",
      "../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_tsonly/imputed.9.vcf\n"
     ]
    }
   ],
   "source": [
    "method = \"tsonly\"\n",
    "imputed_dir = \"imputed\" + \"_\" + method + \"/\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + imputed_dir + \"imputed.\" + str(i) + \".vcf\"\n",
    "    print(f\"{imputed_vcf_file}\")\n",
    "    \n",
    "    stats = compare_variants(true_vcf_file,\n",
    "                             miss_vcf_file,\n",
    "                             imputed_vcf_file,\n",
    "                             maf_dict = maf_dict[i],\n",
    "                             ploidy_level = 1,\n",
    "                             verbose = False)\n",
    "    \n",
    "    results.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33a61ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0;tsonly;( 0.0000%,  0.0100%);86.0;76.0;0.883721\n",
      "0;tsonly;[ 0.0100%,  0.1000%);601.0;599.0;0.996672\n",
      "0;tsonly;[ 0.1000%,  0.2000%);545.0;545.0;1.0\n",
      "0;tsonly;[ 0.2000%,  0.3000%);338.0;337.0;0.997041\n",
      "0;tsonly;[ 0.3000%,  0.4000%);434.0;434.0;1.0\n",
      "0;tsonly;[ 0.4000%,  0.5000%);229.0;229.0;1.0\n",
      "0;tsonly;[ 0.5000%,  1.0000%);977.0;977.0;1.0\n",
      "0;tsonly;[ 1.0000%,  2.0000%);473.0;473.0;1.0\n",
      "0;tsonly;[ 2.0000%,  5.0000%);133.0;133.0;1.0\n",
      "0;tsonly;[ 5.0000%, 10.0000%);247.0;247.0;1.0\n",
      "0;tsonly;[10.0000%, 20.0000%);577.0;577.0;1.0\n",
      "0;tsonly;[20.0000%, 30.0000%);520.0;520.0;1.0\n",
      "0;tsonly;[30.0000%, 40.0000%);628.0;628.0;1.0\n",
      "0;tsonly;[40.0000%, 50.0000%];4203.0;4203.0;1.0\n",
      "1;tsonly;( 0.0000%,  0.0100%);102.0;94.0;0.921569\n",
      "1;tsonly;[ 0.0100%,  0.1000%);549.0;549.0;1.0\n",
      "1;tsonly;[ 0.1000%,  0.2000%);461.0;461.0;1.0\n",
      "1;tsonly;[ 0.2000%,  0.3000%);487.0;487.0;1.0\n",
      "1;tsonly;[ 0.3000%,  0.4000%);146.0;146.0;1.0\n",
      "1;tsonly;[ 0.4000%,  0.5000%);197.0;197.0;1.0\n",
      "1;tsonly;[ 0.5000%,  1.0000%);330.0;329.0;0.99697\n",
      "1;tsonly;[ 1.0000%,  2.0000%);546.0;546.0;1.0\n",
      "1;tsonly;[ 2.0000%,  5.0000%);193.0;193.0;1.0\n",
      "1;tsonly;[ 5.0000%, 10.0000%);263.0;263.0;1.0\n",
      "1;tsonly;[10.0000%, 20.0000%);678.0;678.0;1.0\n",
      "1;tsonly;[20.0000%, 30.0000%);271.0;270.0;0.99631\n",
      "1;tsonly;[30.0000%, 40.0000%);954.0;954.0;1.0\n",
      "1;tsonly;[40.0000%, 50.0000%];2855.0;2855.0;1.0\n",
      "2;tsonly;( 0.0000%,  0.0100%);102.0;97.0;0.95098\n",
      "2;tsonly;[ 0.0100%,  0.1000%);682.0;679.0;0.995601\n",
      "2;tsonly;[ 0.1000%,  0.2000%);424.0;423.0;0.997642\n",
      "2;tsonly;[ 0.2000%,  0.3000%);402.0;402.0;1.0\n",
      "2;tsonly;[ 0.3000%,  0.4000%);217.0;217.0;1.0\n",
      "2;tsonly;[ 0.4000%,  0.5000%);154.0;154.0;1.0\n",
      "2;tsonly;[ 0.5000%,  1.0000%);1031.0;1031.0;1.0\n",
      "2;tsonly;[ 1.0000%,  2.0000%);464.0;464.0;1.0\n",
      "2;tsonly;[ 2.0000%,  5.0000%);373.0;373.0;1.0\n",
      "2;tsonly;[ 5.0000%, 10.0000%);436.0;436.0;1.0\n",
      "2;tsonly;[10.0000%, 20.0000%);564.0;564.0;1.0\n",
      "2;tsonly;[20.0000%, 30.0000%);1026.0;1026.0;1.0\n",
      "2;tsonly;[30.0000%, 40.0000%);315.0;314.0;0.996825\n",
      "2;tsonly;[40.0000%, 50.0000%];2522.0;2522.0;1.0\n",
      "3;tsonly;( 0.0000%,  0.0100%);89.0;80.0;0.898876\n",
      "3;tsonly;[ 0.0100%,  0.1000%);673.0;670.0;0.995542\n",
      "3;tsonly;[ 0.1000%,  0.2000%);771.0;771.0;1.0\n",
      "3;tsonly;[ 0.2000%,  0.3000%);523.0;523.0;1.0\n",
      "3;tsonly;[ 0.3000%,  0.4000%);226.0;226.0;1.0\n",
      "3;tsonly;[ 0.4000%,  0.5000%);134.0;133.0;0.992537\n",
      "3;tsonly;[ 0.5000%,  1.0000%);216.0;216.0;1.0\n",
      "3;tsonly;[ 1.0000%,  2.0000%);49.0;49.0;1.0\n",
      "3;tsonly;[ 2.0000%,  5.0000%);233.0;233.0;1.0\n",
      "3;tsonly;[ 5.0000%, 10.0000%);194.0;194.0;1.0\n",
      "3;tsonly;[10.0000%, 20.0000%);1083.0;1083.0;1.0\n",
      "3;tsonly;[20.0000%, 30.0000%);1009.0;1009.0;1.0\n",
      "3;tsonly;[30.0000%, 40.0000%);577.0;577.0;1.0\n",
      "3;tsonly;[40.0000%, 50.0000%];2781.0;2781.0;1.0\n",
      "4;tsonly;( 0.0000%,  0.0100%);80.0;73.0;0.9125\n",
      "4;tsonly;[ 0.0100%,  0.1000%);627.0;625.0;0.99681\n",
      "4;tsonly;[ 0.1000%,  0.2000%);334.0;334.0;1.0\n",
      "4;tsonly;[ 0.2000%,  0.3000%);305.0;305.0;1.0\n",
      "4;tsonly;[ 0.3000%,  0.4000%);249.0;249.0;1.0\n",
      "4;tsonly;[ 0.4000%,  0.5000%);255.0;255.0;1.0\n",
      "4;tsonly;[ 0.5000%,  1.0000%);466.0;466.0;1.0\n",
      "4;tsonly;[ 1.0000%,  2.0000%);843.0;843.0;1.0\n",
      "4;tsonly;[ 2.0000%,  5.0000%);936.0;936.0;1.0\n",
      "4;tsonly;[ 5.0000%, 10.0000%);556.0;556.0;1.0\n",
      "4;tsonly;[10.0000%, 20.0000%);428.0;428.0;1.0\n",
      "4;tsonly;[20.0000%, 30.0000%);188.0;188.0;1.0\n",
      "4;tsonly;[30.0000%, 40.0000%);481.0;481.0;1.0\n",
      "4;tsonly;[40.0000%, 50.0000%];3251.0;3251.0;1.0\n",
      "5;tsonly;( 0.0000%,  0.0100%);81.0;78.0;0.962963\n",
      "5;tsonly;[ 0.0100%,  0.1000%);662.0;662.0;1.0\n",
      "5;tsonly;[ 0.1000%,  0.2000%);369.0;369.0;1.0\n",
      "5;tsonly;[ 0.2000%,  0.3000%);446.0;446.0;1.0\n",
      "5;tsonly;[ 0.3000%,  0.4000%);431.0;431.0;1.0\n",
      "5;tsonly;[ 0.4000%,  0.5000%);351.0;351.0;1.0\n",
      "5;tsonly;[ 0.5000%,  1.0000%);569.0;568.0;0.998243\n",
      "5;tsonly;[ 1.0000%,  2.0000%);43.0;43.0;1.0\n",
      "5;tsonly;[ 2.0000%,  5.0000%);368.0;368.0;1.0\n",
      "5;tsonly;[ 5.0000%, 10.0000%);347.0;345.0;0.994236\n",
      "5;tsonly;[10.0000%, 20.0000%);592.0;592.0;1.0\n",
      "5;tsonly;[20.0000%, 30.0000%);201.0;201.0;1.0\n",
      "5;tsonly;[30.0000%, 40.0000%);1456.0;1456.0;1.0\n",
      "5;tsonly;[40.0000%, 50.0000%];2990.0;2990.0;1.0\n",
      "6;tsonly;( 0.0000%,  0.0100%);77.0;71.0;0.922078\n",
      "6;tsonly;[ 0.0100%,  0.1000%);835.0;833.0;0.997605\n",
      "6;tsonly;[ 0.1000%,  0.2000%);430.0;430.0;1.0\n",
      "6;tsonly;[ 0.2000%,  0.3000%);478.0;478.0;1.0\n",
      "6;tsonly;[ 0.3000%,  0.4000%);301.0;301.0;1.0\n",
      "6;tsonly;[ 0.4000%,  0.5000%);195.0;195.0;1.0\n",
      "6;tsonly;[ 0.5000%,  1.0000%);378.0;378.0;1.0\n",
      "6;tsonly;[ 1.0000%,  2.0000%);221.0;220.0;0.995475\n",
      "6;tsonly;[ 2.0000%,  5.0000%);539.0;538.0;0.998145\n",
      "6;tsonly;[ 5.0000%, 10.0000%);1527.0;1527.0;1.0\n",
      "6;tsonly;[10.0000%, 20.0000%);333.0;333.0;1.0\n",
      "6;tsonly;[20.0000%, 30.0000%);150.0;150.0;1.0\n",
      "6;tsonly;[30.0000%, 40.0000%);749.0;749.0;1.0\n",
      "6;tsonly;[40.0000%, 50.0000%];2690.0;2690.0;1.0\n",
      "7;tsonly;( 0.0000%,  0.0100%);84.0;78.0;0.928571\n",
      "7;tsonly;[ 0.0100%,  0.1000%);658.0;656.0;0.99696\n",
      "7;tsonly;[ 0.1000%,  0.2000%);508.0;507.0;0.998031\n",
      "7;tsonly;[ 0.2000%,  0.3000%);172.0;172.0;1.0\n",
      "7;tsonly;[ 0.3000%,  0.4000%);10.0;10.0;1.0\n",
      "7;tsonly;[ 0.4000%,  0.5000%);66.0;66.0;1.0\n",
      "7;tsonly;[ 0.5000%,  1.0000%);298.0;297.0;0.996644\n",
      "7;tsonly;[ 1.0000%,  2.0000%);332.0;332.0;1.0\n",
      "7;tsonly;[ 2.0000%,  5.0000%);649.0;649.0;1.0\n",
      "7;tsonly;[ 5.0000%, 10.0000%);640.0;640.0;1.0\n",
      "7;tsonly;[10.0000%, 20.0000%);412.0;412.0;1.0\n",
      "7;tsonly;[20.0000%, 30.0000%);888.0;888.0;1.0\n",
      "7;tsonly;[30.0000%, 40.0000%);307.0;307.0;1.0\n",
      "7;tsonly;[40.0000%, 50.0000%];2650.0;2650.0;1.0\n",
      "8;tsonly;( 0.0000%,  0.0100%);87.0;81.0;0.931034\n",
      "8;tsonly;[ 0.0100%,  0.1000%);592.0;590.0;0.996622\n",
      "8;tsonly;[ 0.1000%,  0.2000%);344.0;344.0;1.0\n",
      "8;tsonly;[ 0.2000%,  0.3000%);489.0;489.0;1.0\n",
      "8;tsonly;[ 0.3000%,  0.4000%);555.0;555.0;1.0\n",
      "8;tsonly;[ 0.4000%,  0.5000%);69.0;69.0;1.0\n",
      "8;tsonly;[ 0.5000%,  1.0000%);499.0;499.0;1.0\n",
      "8;tsonly;[ 1.0000%,  2.0000%);276.0;276.0;1.0\n",
      "8;tsonly;[ 2.0000%,  5.0000%);85.0;85.0;1.0\n",
      "8;tsonly;[ 5.0000%, 10.0000%);414.0;414.0;1.0\n",
      "8;tsonly;[10.0000%, 20.0000%);383.0;383.0;1.0\n",
      "8;tsonly;[20.0000%, 30.0000%);1065.0;1065.0;1.0\n",
      "8;tsonly;[30.0000%, 40.0000%);532.0;532.0;1.0\n",
      "8;tsonly;[40.0000%, 50.0000%];2370.0;2370.0;1.0\n",
      "9;tsonly;( 0.0000%,  0.0100%);87.0;80.0;0.91954\n",
      "9;tsonly;[ 0.0100%,  0.1000%);686.0;676.0;0.985423\n",
      "9;tsonly;[ 0.1000%,  0.2000%);432.0;431.0;0.997685\n",
      "9;tsonly;[ 0.2000%,  0.3000%);285.0;285.0;1.0\n",
      "9;tsonly;[ 0.3000%,  0.4000%);246.0;246.0;1.0\n",
      "9;tsonly;[ 0.4000%,  0.5000%);96.0;96.0;1.0\n",
      "9;tsonly;[ 0.5000%,  1.0000%);908.0;907.0;0.998899\n",
      "9;tsonly;[ 1.0000%,  2.0000%);753.0;753.0;1.0\n",
      "9;tsonly;[ 2.0000%,  5.0000%);486.0;486.0;1.0\n",
      "9;tsonly;[ 5.0000%, 10.0000%);210.0;210.0;1.0\n",
      "9;tsonly;[10.0000%, 20.0000%);148.0;147.0;0.993243\n",
      "9;tsonly;[20.0000%, 30.0000%);221.0;221.0;1.0\n",
      "9;tsonly;[30.0000%, 40.0000%);166.0;166.0;1.0\n",
      "9;tsonly;[40.0000%, 50.0000%];3225.0;3225.0;1.0\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(\"\\n\".join([';'.join([str(i), method, k, str(v[0]), str(v[1]), str(v[2])])\n",
    "                     for k, v\n",
    "                     in result[3].items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72737b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
