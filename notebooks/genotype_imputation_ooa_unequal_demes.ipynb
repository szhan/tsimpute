{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1c464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tskit 0.4.1\n",
      "tsinfer 0.2.3.dev9+gc8568d5\n",
      "msprime 1.1.1\n",
      "stdpopsim 0.1.2\n",
      "cyvcf2 0.30.14\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "sys.path.append(\"../modules/\")\n",
    "import mask_genotype\n",
    "import parse_vcf\n",
    "\n",
    "import demes\n",
    "import tsinfer\n",
    "from tsinfer import make_ancestors_ts\n",
    "import tskit\n",
    "import msprime\n",
    "import stdpopsim\n",
    "import cyvcf2\n",
    "\n",
    "print(f\"tskit {tskit.__version__}\")\n",
    "print(f\"tsinfer {tsinfer.__version__}\")\n",
    "print(f\"msprime {msprime.__version__}\")\n",
    "print(f\"stdpopsim {stdpopsim.__version__}\")\n",
    "print(f\"cyvcf2 {cyvcf2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64d1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_data_to_vcf(sample_data,\n",
    "                             individuals,\n",
    "                             samples,\n",
    "                             ploidy_level,\n",
    "                             mask,\n",
    "                             out_vcf_file,\n",
    "                             contig_id,\n",
    "                             sequence_length_max = 1e12):\n",
    "    \"\"\"\n",
    "    Fields:\n",
    "    CHROM contig_id\n",
    "    POS row index in genotype_matrix\n",
    "    ID .\n",
    "    REF ancestral allele\n",
    "    ALT derived allele(s)\n",
    "    QUAL .\n",
    "    FILTER PASS\n",
    "    INFO\n",
    "    FORMAT GT\n",
    "    individual 0\n",
    "    individual 1\n",
    "    ...\n",
    "    individual n - 1; n = number of individuals\n",
    "    \"\"\"\n",
    "    CHROM = contig_id\n",
    "    ID = '.'\n",
    "    QUAL = '.'\n",
    "    FILTER = 'PASS'\n",
    "    FORMAT = 'GT'\n",
    "    \n",
    "    assert ploidy_level == 1 or ploidy_level == 2,\\\n",
    "        f\"Specified ploidy_level {ploidy_level} is not recognized.\"\n",
    "    \n",
    "    assert ploidy_level * len(individuals) == len(samples),\\\n",
    "        f\"Some individuals may not have the same ploidy level of {ploidy_level}.\"\n",
    "    \n",
    "    # Assume that both sample and individual ids are ordered the same way.\n",
    "    #individual_id_map = np.repeat(individuals, 2)\n",
    "    \n",
    "    header  = \"##fileformat=VCFv4.2\\n\"\\\n",
    "            + \"##source=tskit \" + tskit.__version__ + \"\\n\"\\\n",
    "            + \"##INFO=<ID=AA,Number=1,Type=String,Description=\\\"Ancestral Allele\\\">\\n\"\\\n",
    "            + \"##FORMAT=<ID=GT,Number=1,Type=String,Description=\\\"Genotype\\\">\\n\"\n",
    "    header += \"##contig=<ID=\" + contig_id + \",\" + \"length=\" + str(int(ts.sequence_length)) + \">\\n\"\n",
    "    header += \"\\t\".join(['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT']\\\n",
    "                        + [\"s\" + str(x) for x in individuals])\n",
    "    \n",
    "    with open(out_vcf_file, \"w\") as vcf:\n",
    "        vcf.write(header + \"\\n\")\n",
    "        for i, variant in enumerate(ts.variants()):\n",
    "            site_id = variant.site.id\n",
    "            POS = int(np.round(variant.site.position))\n",
    "            if POS > sequence_length_max:\n",
    "                break\n",
    "            # Since the tree sequence was produced using simulation,\n",
    "            #    there's no reference sequence other than the ancestral sequence.\n",
    "            REF = variant.site.ancestral_state\n",
    "            alt_alleles = list(set(variant.alleles) - {REF})\n",
    "            AA = variant.site.ancestral_state\n",
    "            ALT = \",\".join(alt_alleles) if len(alt_alleles) > 0 else \".\"\n",
    "            INFO = \"AA\" + \"=\" + AA\n",
    "            record = [str(x)\n",
    "                      for x\n",
    "                      in [CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, FORMAT]]\n",
    "            \n",
    "            for j in individuals:\n",
    "                #sample_ids = [samples[x]\n",
    "                #              for x\n",
    "                #              in np.where(individual_id_map == j)[0].tolist()]\n",
    "                #genotype = \"|\".join([str(variant.genotypes[k])\n",
    "                #                     for k\n",
    "                #                     in sample_ids])\n",
    "                if ploidy_level == 1:\n",
    "                    genotype = str(variant.genotypes[j])\n",
    "                else:\n",
    "                    genotype = str(variant.genotypes[2 * j]) + \"|\" + str(variant.genotypes[2 * j + 1])\n",
    "                    \n",
    "                if mask is not None and mask.query_position(individual = j, position = POS) == True:\n",
    "                    if ploidy_level == 1:\n",
    "                        genotype = '.'\n",
    "                    else:\n",
    "                        genotype = '.|.' # Or \"./.\"\n",
    "                record += [genotype]\n",
    "                \n",
    "            vcf.write(\"\\t\".join(record) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa396407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sourced and modified from:\n",
    "# https://tsinfer.readthedocs.io/en/latest/tutorial.html#data-example\n",
    "def get_chromosome_length(vcf):\n",
    "    assert len(vcf.seqlens) == 1\n",
    "    return vcf.seqlens[0]\n",
    "\n",
    "\n",
    "def add_populations(vcf,\n",
    "                    samples):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    pop_ids = [sample_name[0] for sample_name in vcf.samples]\n",
    "    pop_codes = np.unique(pop_ids)\n",
    "    pop_lookup = {}\n",
    "    for p in pop_codes:\n",
    "        pop_lookup[p] = samples.add_population(metadata = {\"name\" : p})\n",
    "    return [pop_lookup[pop_id] for pop_id in pop_ids]\n",
    "\n",
    "\n",
    "def add_individuals(vcf,\n",
    "                    samples,\n",
    "                    ploidy_level,\n",
    "                    populations):\n",
    "    for name, population in zip(vcf.samples, populations):\n",
    "        samples.add_individual(ploidy = ploidy_level,\n",
    "                               metadata = {\"name\": name},\n",
    "                               population = population)\n",
    "\n",
    "\n",
    "def add_sites(vcf,\n",
    "              samples,\n",
    "              ploidy_level,\n",
    "              warn_monomorphic_sites = False):\n",
    "    \"\"\"\n",
    "    Read the sites in the VCF and add them to the samples object,\n",
    "    reordering the alleles to put the ancestral allele first,\n",
    "    if it is available.\n",
    "    \"\"\"\n",
    "    assert ploidy_level == 1 or ploidy_level == 2,\\\n",
    "        f\"ploidy_level {ploidy_level} is not recognized.\"\n",
    "    \n",
    "    pos = 0\n",
    "    for variant in vcf:\n",
    "        # Check for duplicate site positions.\n",
    "        if pos == variant.POS:\n",
    "            raise ValueError(\"Duplicate positions for variant at position\", pos)\n",
    "        else:\n",
    "            pos = variant.POS\n",
    "        # Check that the genotypes are phased.\n",
    "        #if any([not phased for _, _, phased in variant.genotypes]):\n",
    "        #    raise ValueError(\"Unphased genotypes for variant at position\", pos)\n",
    "        alleles = [variant.REF] + variant.ALT # Exactly as in the input VCF file.\n",
    "        if warn_monomorphic_sites:\n",
    "            if len(set(alleles) - {'.'}) == 1:\n",
    "                print(f\"Monomorphic site at {pos}\")\n",
    "        ancestral = variant.INFO.get(\"AA\", variant.REF) # Dangerous action!!!\n",
    "        # Ancestral state must be first in the allele list.\n",
    "        ordered_alleles = [ancestral] + list(set(alleles) - {ancestral})\n",
    "        # Create an index mapping from the input VCF to tsinfer input.\n",
    "        allele_index = {\n",
    "            old_index: ordered_alleles.index(allele)\n",
    "            for old_index, allele in enumerate(alleles)\n",
    "        }\n",
    "        # When genotype is missing...\n",
    "        if variant.num_unknown > 0:\n",
    "            allele_index[-1] = tskit.MISSING_DATA\n",
    "            ordered_alleles += [None]\n",
    "        # Map original allele indexes to their indexes in the new alleles list.\n",
    "        genotypes = [\n",
    "            allele_index[old_index]\n",
    "            for row in variant.genotypes # cyvcf2 uses -1 to indicate missing data.\n",
    "            for old_index in row[0:ploidy_level] # Each is a 3-tuple (allele 1, allele 2, is phased?).\n",
    "        ]\n",
    "        samples.add_site(pos,\n",
    "                         genotypes = genotypes,\n",
    "                         alleles = ordered_alleles)\n",
    "\n",
    "\n",
    "def create_sample_data_from_vcf_file(vcf_file):\n",
    "    vcf = cyvcf2.VCF(vcf_file,\n",
    "                     gts012 = False, # 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\n",
    "                     strict_gt = True)\n",
    "    with tsinfer.SampleData(\n",
    "        sequence_length = get_chromosome_length(vcf)\n",
    "    ) as samples:\n",
    "        populations = add_populations(vcf, samples)\n",
    "        add_individuals(vcf, samples, ploidy_level, populations)\n",
    "        add_sites(vcf, samples, ploidy_level)\n",
    "    return(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0e8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vcf_file(vcf_file):\n",
    "    \"\"\"\n",
    "    If gt_types = False, then 0=HOM_REF, 1=HET, 2=UNKNOWN, the coordinates are 0-based.\n",
    "    It returns a list of dictionaries, each containing a VCF record.\n",
    "    \"\"\"\n",
    "    parsed_vcf = []\n",
    "    for variant in cyvcf2.VCF(vcf_file,\n",
    "                              gts012 = False, # 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\n",
    "                              strict_gt = True):\n",
    "        record = {\n",
    "            'ref': variant.REF,\n",
    "            'alt': variant.ALT,\n",
    "            'ctg': variant.CHROM, # Contig id/name\n",
    "            'pos': int(variant.start),\n",
    "            'aa' : variant.INFO.get('AA'), # Ancestral allele\n",
    "            'gt' : variant.genotypes\n",
    "        }\n",
    "        parsed_vcf.append(record)\n",
    "    return(parsed_vcf)\n",
    "\n",
    "\n",
    "def compare_vcf(vcf_1, vcf_2):\n",
    "    assert len(vcf_1) == len(vcf_2)\n",
    "    for i in range(len(vcf_1)):\n",
    "        is_valid_ref = vcf_1[i].get('ref') == vcf_2[i].get('ref')\n",
    "        is_valid_alt = vcf_1[i].get('alt') == vcf_2[i].get('alt')\n",
    "        is_valid_ctg = vcf_1[i].get('ctg') == vcf_2[i].get('ctg')\n",
    "        is_valid_pos = vcf_1[i].get('pos') == vcf_2[i].get('pos')\n",
    "        is_valid_aa  = vcf_1[i].get('aa' ) == vcf_2[i].get('aa' )\n",
    "        is_all_valid = np.all([is_valid_ref,\n",
    "                               is_valid_alt,\n",
    "                               is_valid_ctg,\n",
    "                               is_valid_pos,\n",
    "                               is_valid_aa])\n",
    "        if not is_all_valid:\n",
    "            return(False)\n",
    "    return(True)\n",
    "\n",
    "\n",
    "def get_common_positions_in_vcf(vcf_1, vcf_2):\n",
    "    pos_1 = []\n",
    "    pos_2 = []\n",
    "    for i, record in enumerate(vcf_1):\n",
    "        pos_1.append(record.get('pos'))\n",
    "    for i, record in enumerate(vcf_2):\n",
    "        pos_2.append(record.get('pos'))\n",
    "    # All positions should be unique.\n",
    "    assert len(pos_1) == len(set(pos_1)),\\\n",
    "        \"The positions in vcf_1 are not all unique.\"\n",
    "    assert len(pos_2) == len(set(pos_2)),\\\n",
    "        \"The positions in vcf_2 are not all unique.\"\n",
    "    common_pos = list(set.intersection(set(pos_1), set(pos_2)))\n",
    "    return(common_pos)\n",
    "\n",
    "\n",
    "def compare_variants(true_vcf_file,\n",
    "                     miss_vcf_file,\n",
    "                     imputed_vcf_file,\n",
    "                     ploidy_level,\n",
    "                     verbose = False):\n",
    "    true_vcf    = parse_vcf_file(true_vcf_file)\n",
    "    miss_vcf    = parse_vcf_file(miss_vcf_file)\n",
    "    imputed_vcf = parse_vcf_file(imputed_vcf_file)\n",
    "    \n",
    "    assert compare_vcf(true_vcf, miss_vcf),\\\n",
    "        \"true_vcf and miss_vcf are not comparable.\"\n",
    "    \n",
    "    # If diploid, then assume phased.\n",
    "    MISSING_GENOTYPE_CONSTANT = [-1, -1, True] if ploidy_level == 2 else [-1, False]\n",
    "    \n",
    "    # Imputed VCF file must have at most the number of positions as the true/miss VCF files.\n",
    "    common_pos = get_common_positions_in_vcf(miss_vcf, imputed_vcf)\n",
    "    \n",
    "    # Number of genotypes imputed, correctly or not.\n",
    "    nbr_gt_total = 0\n",
    "    # Number of instances of genotypes correctly imputed.\n",
    "    nbr_gt_correct = 0\n",
    "    nbr_gt_0 = 0\n",
    "    nbr_gt_1 = 0\n",
    "    \n",
    "    for i in range(len(imputed_vcf)):\n",
    "        if        true_vcf[i]['pos'] not in common_pos\\\n",
    "            or    miss_vcf[i]['pos'] not in common_pos\\\n",
    "            or imputed_vcf[i]['pos'] not in common_pos:\n",
    "            continue\n",
    "            \n",
    "        imputed_bool = [x == MISSING_GENOTYPE_CONSTANT\n",
    "                        for x\n",
    "                        in miss_vcf[i]['gt']\n",
    "                       ]\n",
    "        true_gt_oi = [x\n",
    "                      for x, y\n",
    "                      in zip(true_vcf[i]['gt'], imputed_bool) if y\n",
    "                     ]\n",
    "        miss_gt_oi = [x\n",
    "                      for x, y\n",
    "                      in zip(miss_vcf[i]['gt'], imputed_bool) if y\n",
    "                     ]\n",
    "        imputed_gt_oi = [x\n",
    "                         for x, y\n",
    "                         in zip(imputed_vcf[i]['gt'], imputed_bool) if y\n",
    "                        ]\n",
    "        \n",
    "        nbr_gt_0 += np.sum([x == [0, False]\n",
    "                            for x, y\n",
    "                            in zip(true_vcf[i]['gt'], imputed_bool) if y])\n",
    "        nbr_gt_1 += np.sum([x == [1, False]\n",
    "                            for x, y\n",
    "                            in zip(true_vcf[i]['gt'], imputed_bool) if y])\n",
    "        \n",
    "        nbr_gt_total   += len(true_gt_oi)\n",
    "        nbr_gt_correct += np.count_nonzero([x == y\n",
    "                                            for x, y\n",
    "                                            in zip(true_gt_oi, imputed_gt_oi)\n",
    "                                           ])\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Position {true_vcf[i]['pos']}\")\n",
    "            print(f\"Boolean array to indicate which genotypes are missing.\")\n",
    "            print(imputed_bool)\n",
    "            print(f\"True genotypes\")\n",
    "            print(true_gt_oi)\n",
    "            print(f\"Missing genotypes\")\n",
    "            print(miss_gt_oi)\n",
    "            print(f\"Imputed genotypes\")\n",
    "            print(imputed_gt_oi)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f\"Number of missing genotypes 0: {nbr_gt_0}\")\n",
    "        print(f\"Number of missing genotypes 1: {nbr_gt_1}\")\n",
    "            \n",
    "    concordance_rate = float(nbr_gt_correct) / float(nbr_gt_total)\n",
    "    \n",
    "    return((nbr_gt_total, nbr_gt_correct, concordance_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a68edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_biallelic_sites(sample_data_1,\n",
    "                         sample_data_2,\n",
    "                         verbose = False):\n",
    "    variants_1 = sample_data_1.variants()\n",
    "    variants_2 = sample_data_2.variants()\n",
    "    \n",
    "    # Keep only biallelic sites\n",
    "    sites_1 = []\n",
    "    sites_2 = []\n",
    "    \n",
    "    for var_1, var_2 in zip(variants_1, variants_2):\n",
    "        assert var_1.site.position == var_2.site.position\n",
    "        \n",
    "        alleles_1 = set(var_1.alleles) - {None}\n",
    "        alleles_2 = set(var_2.alleles) - {None}\n",
    "        \n",
    "        if len(alleles_1) == 2\\\n",
    "            and len(alleles_2) == 2\\\n",
    "            and alleles_1 == alleles_2:\n",
    "            sites_1.append(var_1.site.id)\n",
    "            sites_2.append(var_2.site.id)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"SD1: {var_1.site.position} {alleles_1}\" + \" \"+\\\n",
    "                      f\"SD2: {var_2.site.position} {alleles_2}\")\n",
    "                \n",
    "    assert len(sites_1) == len(sites_2),\\\n",
    "        \"The number of site positions in sites_1 and sites_2 are different.\"\n",
    "    \n",
    "    return(sites_1, sites_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23154dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_with_discretized_coordinates(ts):\n",
    "    ts_tables = ts.dump_tables()\n",
    "    ts_tables.sites.position = np.round(ts_tables.sites.position)\n",
    "    ts_tables.deduplicate_sites()\n",
    "    ts_tables.sort()\n",
    "    ts_tables.build_index()\n",
    "    ts_tables.compute_mutation_times()\n",
    "    ts_discretized = ts_tables.tree_sequence()\n",
    "    return(ts_discretized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8994b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_genotypes_using_tsinfer(ref_vcf_file,\n",
    "                                   miss_vcf_file,\n",
    "                                   imputed_vcf_file,\n",
    "                                   contig_id):\n",
    "    sd_ref  = create_sample_data_from_vcf_file(ref_vcf_file)\n",
    "    sd_miss = create_sample_data_from_vcf_file(miss_vcf_file)\n",
    "    ad_ref     = tsinfer.generate_ancestors(sample_data = sd_ref)\n",
    "    # This step is to infer a tree sequence from the sample data.\n",
    "    ts_anc_ref = tsinfer.match_ancestors(sample_data   = sd_ref,\n",
    "                                         ancestor_data = ad_ref)\n",
    "    ts_matched = tsinfer.match_samples(sample_data  = sd_miss,\n",
    "                                       ancestors_ts = ts_anc_ref)\n",
    "    with open(imputed_vcf_file, \"w\") as vcf:\n",
    "        ts_matched.write_vcf(vcf, contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd1f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_genotypes_using_ts_only(ref_vcf_file,\n",
    "                                   miss_vcf_file,\n",
    "                                   imputed_vcf_file,\n",
    "                                   ts_anc_ref,\n",
    "                                   contig_id):\n",
    "    sd_ref  = create_sample_data_from_vcf_file(ref_vcf_file)\n",
    "    sd_miss = create_sample_data_from_vcf_file(miss_vcf_file)\n",
    "    ts_matched = tsinfer.match_samples(sample_data  = sd_miss,\n",
    "                                       ancestors_ts = ts_anc_ref)\n",
    "    with open(imputed_vcf_file, \"w\") as vcf:\n",
    "        ts_matched.write_vcf(vcf, contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1ea4b",
   "metadata": {},
   "source": [
    "## Create data sets via simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ab9ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of reference panel    : 100000\n",
      "Number of samples from YRI : 2500\n",
      "Number of samples from CEU : 95000\n",
      "Number of samples from CHB : 2500\n"
     ]
    }
   ],
   "source": [
    "size_query =   1_000\n",
    "\n",
    "size_yri   =   2_500\n",
    "size_ceu   =  95_000\n",
    "size_chb   =   2_500\n",
    "size_ref   = size_yri + size_ceu + size_chb\n",
    "\n",
    "print(f\"Size of reference panel    : {size_ref}\")\n",
    "print(f\"Number of samples from YRI : {size_yri}\")\n",
    "print(f\"Number of samples from CEU : {size_ceu}\")\n",
    "print(f\"Number of samples from CHB : {size_chb}\")\n",
    "\n",
    "num_replicates = 10\n",
    "\n",
    "num_missing_sites = 10_000\n",
    "\n",
    "contig_id = '1'\n",
    "ploidy_level = 1\n",
    "sequence_length = 1_000_000\n",
    "\n",
    "base_dir = \"../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f814f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_map = msprime.RateMap.uniform(\n",
    "    sequence_length = sequence_length,\n",
    "    rate = 1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c01a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = \"../demes/gutenkunst_ooa_2009.yaml\"\n",
    "ooa_graph = demes.load(yaml_file)\n",
    "demography_model = msprime.Demography.from_demes(ooa_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4058b4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating 10 ts without duplicate site positions.\n",
      "Simulation of 10 ts took 11.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "sample_set = [\n",
    "    msprime.SampleSet(num_samples = size_yri + size_query,\n",
    "                      population = \"YRI\", # id = 3\n",
    "                      ploidy = ploidy_level),\n",
    "    msprime.SampleSet(num_samples = size_ceu,\n",
    "                      population = \"CEU\", # id = 4\n",
    "                      ploidy = ploidy_level),\n",
    "    msprime.SampleSet(num_samples = size_chb,\n",
    "                      population = \"CHB\", # id = 5\n",
    "                      ploidy = ploidy_level)\n",
    "]\n",
    "\n",
    "src_ts = [] # List of full simulated ts.\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "print(f\"Simulating {num_replicates} ts without duplicate site positions.\")\n",
    "success = 0\n",
    "\n",
    "while success < num_replicates:\n",
    "    sim_ts = msprime.sim_ancestry(\n",
    "        samples = sample_set,\n",
    "        demography = demography_model,\n",
    "        ploidy = ploidy_level,\n",
    "        model = \"hudson\",\n",
    "        recombination_rate = rate_map,\n",
    "        discrete_genome = True\n",
    "    )\n",
    "    \n",
    "    sim_mts = msprime.sim_mutations(\n",
    "        sim_ts,\n",
    "        rate = 1e-8,\n",
    "        discrete_genome = True\n",
    "    )\n",
    "    \n",
    "    src_ts.append(sim_mts)\n",
    "    success += 1\n",
    "    \n",
    "toc = time.time()\n",
    "print(f\"Simulation of {num_replicates} ts took {round(toc - tic, 2)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a12ae6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reference samples : 100000\n",
      "Number of study     samples : 1000\n"
     ]
    }
   ],
   "source": [
    "# Impute into YRI samples.\n",
    "ts = src_ts[0]\n",
    "\n",
    "individuals_query = ts.samples(population = 3)[:size_query]\n",
    "samples_query     = individuals_query # When haploid\n",
    "\n",
    "individuals_ref   = np.concatenate([ts.samples(population = 3)[size_query:],\n",
    "                                    ts.samples(population = 4),\n",
    "                                    ts.samples(population = 5)])\n",
    "samples_ref       = individuals_ref   # When haploid\n",
    "\n",
    "gt_mask = mask_genotype.MissingGenotypeMask(individuals        = individuals_query,\n",
    "                                            sequence_length    = sequence_length,\n",
    "                                            proportion_missing = 0.05)\n",
    "\n",
    "print(f\"Number of reference samples : {len(individuals_ref)}\")\n",
    "print(f\"Number of study     samples : {len(individuals_query)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fce9cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ts 0.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 1.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 2.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 3.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 4.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 5.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 6.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 7.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 8.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n",
      "Processing ts 9.\n",
      "Printing ancestors ts.\n",
      "Printing reference panel VCF.\n",
      "Printing query VCF with non-missing genotypes.\n",
      "Printing query VCF with missing genotypes.\n"
     ]
    }
   ],
   "source": [
    "anc_ts = [] # List of simulated ancestor ts.\n",
    "\n",
    "for i, ts in enumerate(src_ts):\n",
    "    print(f\"Processing ts {i}.\")\n",
    "    ref_vcf_file  = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    true_vcf_file = base_dir + \"true/\" + \"true.\" + str(i) + \".vcf\"\n",
    "    miss_vcf_file = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    ts_anc_ref_file = base_dir + \"ts_anc_ref/\" + \"ts_anc_ref.\" + str(i) + \".trees\"\n",
    "    \n",
    "    sd_all = tsinfer.SampleData.from_tree_sequence(ts, use_sites_time = False)\n",
    "    \n",
    "    sd_ref   = sd_all.subset(individuals = individuals_ref)\n",
    "    sd_query = sd_all.subset(individuals = individuals_query)\n",
    "    \n",
    "    sites_to_keep     = find_biallelic_sites(sd_ref, sd_query)\n",
    "    sd_ref_filtered   =   sd_ref.subset(sites = sites_to_keep[0])\n",
    "    sd_query_filtered = sd_query.subset(sites = sites_to_keep[1])\n",
    "    \n",
    "    # TODO: Refactor.\n",
    "    print(\"Printing ancestors ts.\")\n",
    "    sim_ts_anc_ref = make_ancestors_ts(samples = samples_ref,\n",
    "                                       ts = ts,\n",
    "                                       remove_leaves = True)\n",
    "    tmp_tables = sim_ts_anc_ref.dump_tables()\n",
    "    tmp_tables.populations.metadata_schema = tskit.MetadataSchema(schema = None)\n",
    "    sim_ts_anc_ref = tmp_tables.tree_sequence()\n",
    "    anc_ts.append(sim_ts_anc_ref)\n",
    "    sim_ts_anc_ref.dump(ts_anc_ref_file)\n",
    "    \n",
    "    print(\"Printing reference panel VCF.\")\n",
    "    print_sample_data_to_vcf(sample_data = sd_ref_filtered,\n",
    "                             individuals = individuals_ref,\n",
    "                             samples = samples_ref,\n",
    "                             ploidy_level = ploidy_level,\n",
    "                             mask = None,\n",
    "                             out_vcf_file = ref_vcf_file,\n",
    "                             contig_id = contig_id,\n",
    "                             sequence_length_max = 1e24)\n",
    "    \n",
    "    print(\"Printing query VCF with non-missing genotypes.\")\n",
    "    print_sample_data_to_vcf(sample_data = sd_query_filtered,\n",
    "                             individuals = individuals_query,\n",
    "                             samples = samples_query,\n",
    "                             ploidy_level = ploidy_level,\n",
    "                             mask = None,\n",
    "                             out_vcf_file = true_vcf_file,\n",
    "                             contig_id = contig_id,\n",
    "                             sequence_length_max = 1e24)\n",
    "    \n",
    "    print(\"Printing query VCF with missing genotypes.\")\n",
    "    print_sample_data_to_vcf(sample_data = sd_query_filtered,\n",
    "                             individuals = individuals_query,\n",
    "                             samples = samples_query,\n",
    "                             ploidy_level = ploidy_level,\n",
    "                             mask = gt_mask,\n",
    "                             out_vcf_file = miss_vcf_file,\n",
    "                             contig_id = contig_id,\n",
    "                             sequence_length_max = 1e24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da1bc5",
   "metadata": {},
   "source": [
    "## Perform genotype imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f2d72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing imputation using ts only.\n",
      "Imputing VCF 0\n",
      "Imputing VCF 1\n",
      "Imputing VCF 2\n",
      "Imputing VCF 3\n",
      "Imputing VCF 4\n",
      "Imputing VCF 5\n",
      "Imputing VCF 6\n",
      "Imputing VCF 7\n",
      "Imputing VCF 8\n",
      "Imputing VCF 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Doing imputation using ts only.\")\n",
    "\n",
    "for i in np.arange(len(src_ts)):\n",
    "    print(f\"Imputing VCF {i}\")\n",
    "    ref_vcf_file     = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsonly/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    impute_genotypes_using_ts_only(ref_vcf_file = ref_vcf_file,\n",
    "                                   miss_vcf_file = miss_vcf_file,\n",
    "                                   imputed_vcf_file = imputed_vcf_file,\n",
    "                                   ts_anc_ref = anc_ts[i],\n",
    "                                   contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e143b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing imputation using tsinfer.\n",
      "Imputing VCF 0\n",
      "Imputing VCF 1\n",
      "Imputing VCF 2\n",
      "Imputing VCF 3\n",
      "Imputing VCF 4\n",
      "Imputing VCF 5\n",
      "Imputing VCF 6\n",
      "Imputing VCF 7\n",
      "Imputing VCF 8\n",
      "Imputing VCF 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Doing imputation using tsinfer.\")\n",
    "\n",
    "for i in np.arange(len(src_ts)):\n",
    "    print(f\"Imputing VCF {i}\")\n",
    "    ref_vcf_file     = base_dir + \"ref/\" + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsinfer/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    impute_genotypes_using_tsinfer(ref_vcf_file = ref_vcf_file,\n",
    "                                   miss_vcf_file = miss_vcf_file,\n",
    "                                   imputed_vcf_file = imputed_vcf_file,\n",
    "                                   contig_id = contig_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff859033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing imputation using BEAGLE.\n",
      "Imputing VCF 0\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.0.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.0.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.0\n",
      "\n",
      "Imputing VCF 1\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.1.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.1.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.1\n",
      "\n",
      "Imputing VCF 2\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.2.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.2.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.2\n",
      "\n",
      "Imputing VCF 3\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.3.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.3.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.3\n",
      "\n",
      "Imputing VCF 4\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.4.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.4.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.4\n",
      "\n",
      "Imputing VCF 5\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.5.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.5.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.5\n",
      "\n",
      "Imputing VCF 6\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.6.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.6.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.6\n",
      "\n",
      "Imputing VCF 7\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.7.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.7.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.7\n",
      "\n",
      "Imputing VCF 8\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.8.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.8.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.8\n",
      "\n",
      "Imputing VCF 9\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/ref/ref.9.vcf gt=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/miss/miss.9.vcf out=../data/modern_ooa_unequal_900505_haploid_miss05_yri_demes_yri/imputed_beagle/imputed.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Doing imputation using BEAGLE.\")\n",
    "\n",
    "beagle_exe = \"../analysis/beagle/beagle.28Jun21.220.jar\"\n",
    "\n",
    "for i in np.arange(len(src_ts)):\n",
    "    print(f\"Imputing VCF {i}\")\n",
    "    ref_vcf_file     = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_beagle/\" + \"imputed.\" + str(i)\n",
    "    beagle_cmd = [\n",
    "        \"java\", \"-jar\", beagle_exe,\n",
    "        \"ref=\" + ref_vcf_file,\n",
    "        \"gt=\"  + miss_vcf_file,\n",
    "        \"out=\" + imputed_vcf_file\n",
    "    ]\n",
    "    beagle_cmd = \" \".join(beagle_cmd)\n",
    "    print(beagle_cmd + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3f76d",
   "metadata": {},
   "source": [
    "## Get imputation accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c4025cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing imputation accuracy metrics for ts only.\n",
      "376732,376697,0.9999070957603814\n",
      "370184,370162,0.9999405700948717\n",
      "375151,375121,0.9999200322003673\n",
      "369503,369478,0.9999323415506776\n",
      "367133,367113,0.999945523829239\n",
      "363183,363166,0.9999531916416793\n",
      "377197,377172,0.9999337216361742\n",
      "367301,367276,0.9999319359326547\n",
      "369965,369947,0.9999513467490168\n",
      "373975,373942,0.9999117588074069\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing imputation accuracy metrics for ts only.\")\n",
    "results = []\n",
    "\n",
    "for i in np.arange(len(src_ts)):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsonly/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    stats = compare_variants(true_vcf_file,\n",
    "                             miss_vcf_file,\n",
    "                             imputed_vcf_file,\n",
    "                             ploidy_level = 1)\n",
    "    results.append(stats)\n",
    "    \n",
    "for y in results:\n",
    "    print(\",\".join([str(x) for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0caf474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing imputation accuracy metrics for tsinfer.\n",
      "376732,376644,0.9997664121975304\n",
      "370184,370088,0.9997406695048948\n",
      "375151,375044,0.9997147815146434\n",
      "369503,369411,0.9997510169064933\n",
      "367133,367020,0.9996922096352003\n",
      "363183,363107,0.9997907391039779\n",
      "377197,377112,0.9997746535629923\n",
      "367301,367209,0.9997495242321692\n",
      "369965,369879,0.9997675455786358\n",
      "373975,373887,0.9997646901530851\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing imputation accuracy metrics for tsinfer.\")\n",
    "results = []\n",
    "\n",
    "for i in np.arange(len(src_ts)):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsinfer/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    stats = compare_variants(true_vcf_file,\n",
    "                             miss_vcf_file,\n",
    "                             imputed_vcf_file,\n",
    "                             ploidy_level = 1)\n",
    "    results.append(stats)\n",
    "    \n",
    "for y in results:\n",
    "    print(\",\".join([str(x) for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46ca517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing imputation accuracy metrics for BEAGLE.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376732,376655,0.9997956106728391\n",
      "370184,370126,0.9998433211592073\n",
      "375151,375093,0.9998453955873768\n",
      "369503,369441,0.9998322070456803\n",
      "367133,367075,0.9998420191047931\n",
      "363183,363117,0.9998182734324018\n",
      "377197,377140,0.9998488853304772\n",
      "367301,367234,0.9998175882995146\n",
      "369965,369923,0.9998864757477058\n",
      "373975,373914,0.9998368874924795\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing imputation accuracy metrics for BEAGLE.\")\n",
    "results = []\n",
    "\n",
    "for i in np.arange(len(src_ts)):\n",
    "    true_vcf_file    = base_dir + \"true/\" + \"true.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\"  + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_beagle/\" + \"imputed.\" + str(i) + \".vcf.gz\"\n",
    "    stats = compare_variants(true_vcf_file = true_vcf_file,\n",
    "                             miss_vcf_file = miss_vcf_file,\n",
    "                             imputed_vcf_file = imputed_vcf_file,\n",
    "                             ploidy_level = 1)\n",
    "    results.append(stats)\n",
    "    \n",
    "for y in results:\n",
    "    print(\",\".join([str(x) for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e6d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
