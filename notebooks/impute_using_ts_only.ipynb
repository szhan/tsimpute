{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde3e9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msprime 1.1.1\n",
      "tskit 0.5.2.dev0\n",
      "tsinfer 0.2.4.dev27+gd61ae2f\n",
      "datetime 26/07/2022 09:44:49\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import click\n",
    "import gzip\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import msprime\n",
    "import tskit\n",
    "import tsinfer\n",
    "from tsinfer import make_ancestors_ts\n",
    "\n",
    "print(f\"msprime {msprime.__version__}\")\n",
    "print(f\"tskit {tskit.__version__}\")\n",
    "print(f\"tsinfer {tsinfer.__version__}\")\n",
    "\n",
    "start_datetime = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(f\"datetime {start_datetime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5e4bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions\n",
    "def count_sites_by_type(\n",
    "    ts_or_sd\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Iterate through the variants of a TreeSequence or SampleData object,\n",
    "    and count the number of mono-, bi-, tri-, and quad-allelic sites.\n",
    "    \n",
    "    :param TreeSequence/SampleData ts_or_sd:\n",
    "    :return None:\n",
    "    \"\"\"\n",
    "    assert isinstance(ts_or_sd, (tskit.TreeSequence, tsinfer.SampleData))\n",
    "    \n",
    "    sites_mono = 0\n",
    "    sites_bi = 0\n",
    "    sites_bi_singleton = 0\n",
    "    sites_tri = 0\n",
    "    sites_quad = 0\n",
    "    \n",
    "    for v in ts_or_sd.variants():\n",
    "        num_alleles = len(set(v.alleles) - {None})\n",
    "        if num_alleles == 1:\n",
    "            sites_mono += 1\n",
    "        elif num_alleles == 2:\n",
    "            sites_bi += 1\n",
    "            if np.sum(v.genotypes) == 1:\n",
    "                sites_bi_singleton += 1\n",
    "        elif num_alleles == 3:\n",
    "            sites_tri += 1\n",
    "        else:\n",
    "            sites_quad += 1\n",
    "    \n",
    "    sites_total = sites_mono + sites_bi + sites_tri + sites_quad\n",
    "    \n",
    "    print(f\"\\tsites mono : {sites_mono}\")\n",
    "    print(f\"\\tsites bi   : {sites_bi} ({sites_bi_singleton} singletons)\")\n",
    "    print(f\"\\tsites tri  : {sites_tri}\")\n",
    "    print(f\"\\tsites quad : {sites_quad}\")\n",
    "    print(f\"\\tsites total: {sites_total}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def check_site_positions_ts_issubset_sd(\n",
    "    tree_sequence,\n",
    "    sample_data\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Check whether the site positions in `TreeSequence` are a subset of\n",
    "    the site positions in `SampleData`.\n",
    "    \n",
    "    :param TreeSequence tree_sequence:\n",
    "    :param SampleData sample_data:\n",
    "    :return bool:\n",
    "    \"\"\"\n",
    "    ts_site_positions = np.empty(tree_sequence.num_sites)\n",
    "    sd_site_positions = np.empty(sample_data.num_sites)\n",
    "    \n",
    "    i = 0\n",
    "    for v in tree_sequence.variants():\n",
    "        ts_site_positions[i] = v.site.position\n",
    "        i += 1\n",
    "        \n",
    "    j = 0\n",
    "    for v in sample_data.variants():\n",
    "        sd_site_positions[j] = v.site.position\n",
    "        j += 1\n",
    "        \n",
    "    assert i == tree_sequence.num_sites\n",
    "    assert j == sample_data.num_sites\n",
    "    \n",
    "    if set(ts_site_positions).issubset(set(sd_site_positions)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def compare_sites_sd_and_ts(\n",
    "    sample_data,\n",
    "    tree_sequence,\n",
    "    is_common,\n",
    "    check_matching_ancestral_state=True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    If `is_common` is set to True, then get the ids and positions of the sites\n",
    "    found in `sample_data` AND in `tree_sequence`.\n",
    "    \n",
    "    if `is_common` is set to False, then get the ids and positions of the sites\n",
    "    found in `sample_data` but NOT in `tree_sequence`.\n",
    "    \n",
    "    :param TreeSequence tree_sequence:\n",
    "    :param SampleData sample_data:\n",
    "    :param is_common bool:\n",
    "    :param check_matching_ancestral_state bool: (default=True)\n",
    "    :return tuple(np.array, np.array):\n",
    "    \"\"\"\n",
    "    ts_site_positions = np.empty(tree_sequence.num_sites)\n",
    "    \n",
    "    i = 0\n",
    "    for v in tree_sequence.variants():\n",
    "        ts_site_positions[i] = v.site.position\n",
    "        i += 1\n",
    "        \n",
    "    assert i == tree_sequence.num_sites\n",
    "    \n",
    "    sd_site_ids = []\n",
    "    sd_site_positions = []\n",
    "    for sd_v in sample_data.variants():\n",
    "        if is_common:\n",
    "            if sd_v.site.position in ts_site_positions:\n",
    "                sd_site_ids.append(sd_v.site.id)\n",
    "                sd_site_positions.append(sd_v.site.position)\n",
    "                if check_matching_ancestral_state:\n",
    "                    ts_site = tree_sequence.site(position=sd_v.site.position)\n",
    "                    assert sd_v.site.ancestral_state == ts_site.ancestral_state, \\\n",
    "                        f\"Ancestral states at {sd_v.site.position} not the same, \" + \\\n",
    "                        f\"{sd_v.site.ancestral_state} vs. {ts_site.ancestral_state}.\"\n",
    "        else:\n",
    "            if sd_v.site.position not in ts_site_positions:\n",
    "                sd_site_ids.append(sd_v.site.id)\n",
    "                sd_site_positions.append(sd_v.site.position)\n",
    "    \n",
    "    return(\n",
    "        (\n",
    "            np.array(sd_site_ids),\n",
    "            np.array(sd_site_positions),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def make_compatible_sample_data(\n",
    "    sample_data,\n",
    "    ancestors_ts\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Make an editable copy of a `sample_data` object, and edit it so that:\n",
    "    (1) the derived alleles in `sample_data` not in `ancestors_ts` are marked as MISSING;\n",
    "    (2) the allele list in `new_sample_data` corresponds to the allele list in `ancestors_ts`.\n",
    "    \n",
    "    N.B. Two `SampleData` attributes `sites_alleles` and `sites_genotypes`,\n",
    "    which are not explained in the tsinfer API doc, are used to facilitate the editing.\n",
    "    \n",
    "    :param SampleData sample_data:\n",
    "    :param TreeSequence ancestors_ts:\n",
    "    :return SampleData:\n",
    "    \"\"\"\n",
    "    new_sample_data = sample_data.copy()\n",
    "    \n",
    "    # Iterate through the sites in `ancestors_ts` using one generator,\n",
    "    # while iterating through the sites in `sample_data` using another generator,\n",
    "    # letting the latter generator catch up.\n",
    "    sd_variants = sample_data.variants()\n",
    "    sd_v = next(sd_variants)\n",
    "    for ts_site in ancestors_ts.sites():\n",
    "        while sd_v.site.position != ts_site.position:\n",
    "            # Sites in `samples_data` but not in `ancestors_ts` are not imputed.\n",
    "            # Also, leave them as is in the `sample_data`, but keep track of them.\n",
    "            sd_v = next(sd_variants)\n",
    "            \n",
    "        sd_site_id = sd_v.site.id # Site id in `sample_data`\n",
    "        \n",
    "        # CHECK that all the sites in `ancestors_ts` are biallelic.\n",
    "        assert len(ts_site.alleles) == 2\n",
    "        \n",
    "        # Get the derived allele in `ancestors_ts` in nucleotide space\n",
    "        ts_ancestral_allele = ts_site.ancestral_state\n",
    "        ts_derived_allele = ts_site.alleles - {ts_ancestral_allele}\n",
    "        assert len(ts_derived_allele) == 1 # CHECK\n",
    "        ts_derived_allele = tuple(ts_derived_allele)[0]\n",
    "        \n",
    "        # CHECK that the ancestral allele should be the same\n",
    "        # in both `ancestors_ts` and `sample_data`.\n",
    "        assert ts_ancestral_allele == sd_v.alleles[0]\n",
    "        \n",
    "        if ts_derived_allele not in sd_v.alleles:\n",
    "            # Case 1:\n",
    "            # If the derived alleles in the `sample_data` are not in `ancestors_ts`,\n",
    "            # then mark them as missing.\n",
    "            #\n",
    "            # The site in `sample_data` may be mono-, bi-, or multiallelic.\n",
    "            #\n",
    "            # We cannot determine whether the extra derived alleles in `sample_data`\n",
    "            # are derived from 0 or 1 in `ancestors_ts` anyway.\n",
    "            new_sample_data.sites_genotypes[sd_site_id] = np.where(\n",
    "                sd_v.genotypes != 0, # Keep if ancestral\n",
    "                tskit.MISSING_DATA, # Otherwise, flag as missing\n",
    "                0,\n",
    "            )\n",
    "            print(f\"Site {sd_site_id} has no matching derived alleles in the query samples.\")\n",
    "            # Update allele list\n",
    "            new_sample_data.sites_alleles[sd_site_id] = [ts_ancestral_allele]\n",
    "        else:\n",
    "            # The allele lists in `ancestors_ts` and `sample_data` may be different.\n",
    "            ts_derived_allele_index = sd_v.alleles.index(ts_derived_allele)\n",
    "            \n",
    "            if ts_derived_allele_index == 1:\n",
    "                # Case 2:\n",
    "                # Both the ancestral and derived alleles correspond exactly.\n",
    "                if len(sd_v.alleles) == 2:\n",
    "                    continue\n",
    "                # Case 3:\n",
    "                # The derived allele in `ancestors_ts` is indexed as 1 in `sample_data`,\n",
    "                # so mark alleles >= 2 as missing.\n",
    "                new_sample_data.sites_genotypes[sd_site_id] = np.where(\n",
    "                    sd_v.genotypes > 1, # 0 and 1 should be kept \"as is\"\n",
    "                    tskit.MISSING_DATA, # Otherwise, flag as missing\n",
    "                    sd_v.genotypes,\n",
    "                )\n",
    "                print(f\"Site {sd_site_id} has extra derived allele(s) in the query samples (set as missing).\")\n",
    "            else:\n",
    "                # Case 4:\n",
    "                #   The derived allele in `ancestors_ts` is NOT indexed as 1 in `sample_data`,\n",
    "                #   so the alleles in `sample_data` needs to be reordered,\n",
    "                #   such that the 1-indexed allele is also indexed as 1 in `ancestors_ts`.\n",
    "                new_sample_data.sites_genotypes[sd_site_id] = np.where(\n",
    "                    sd_v.genotypes == 0,\n",
    "                    0, # Leave ancestral allele \"as is\"\n",
    "                    np.where(\n",
    "                        sd_v.genotypes == ts_derived_allele_index,\n",
    "                        1, # Change it to 1 so that it corresponds to `ancestors_ts`\n",
    "                        tskit.MISSING_DATA, # Otherwise, mark as missing\n",
    "                    ),\n",
    "                )\n",
    "                print(f\"Site {sd_site_id} has the target derived allele at a different index.\")\n",
    "            # Update allele list\n",
    "            new_sample_data.sites_alleles[sd_site_id] = [ts_ancestral_allele, ts_derived_allele]\n",
    "            \n",
    "    new_sample_data.finalise()\n",
    "    \n",
    "    return(new_sample_data)\n",
    "\n",
    "\n",
    "def pick_masked_sites_random(\n",
    "    site_ids,\n",
    "    prop_masked_sites\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Draw N sites from `sites_ids` at random, where N is the number of sites to mask\n",
    "    based on a specified proportion of masked sites `prop_masked_sites`.\n",
    "    \n",
    "    TODO: Specify random seed.\n",
    "    \n",
    "    :param np.array site_ids:\n",
    "    :param float prop_masked_sites: float between 0 and 1\n",
    "    :return np.array: list of site ids\n",
    "    \"\"\"\n",
    "    assert prop_masked_sites >= 0\n",
    "    assert prop_masked_sites <= 1\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    num_masked_sites = int(np.floor(len(site_ids) * prop_masked_sites))\n",
    "    \n",
    "    masked_site_ids = np.sort(\n",
    "        rng.choice(\n",
    "            site_ids,\n",
    "            num_masked_sites,\n",
    "            replace=False,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return(masked_site_ids)\n",
    "\n",
    "\n",
    "def mask_sites_in_sample_data(\n",
    "    sample_data,\n",
    "    masked_sites=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create and return a `SampleData` object from an existing `SampleData` object,\n",
    "    which contains masked sites as listed in `masked_sites` (site ids).\n",
    "    \n",
    "    :param SampleData sample_data:\n",
    "    :param np.array masked_sites: list of site ids (NOT positions)\n",
    "    :return SampleData:\n",
    "    \"\"\"\n",
    "    new_sample_data = sample_data.copy()\n",
    "    \n",
    "    for v in sample_data.variants():\n",
    "        if v.site.id in masked_sites:\n",
    "            new_sample_data.sites_genotypes[v.site.id] = np.full_like(v.genotypes, tskit.MISSING_DATA)\n",
    "    \n",
    "    new_sample_data.finalise()\n",
    "    \n",
    "    return(new_sample_data)\n",
    "\n",
    "\n",
    "def compute_iqs(\n",
    "    genotypes_true,\n",
    "    genotypes_imputed\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculate the Imputation Quality Score between `genotypes_true` and `genotypes_imputed`.\n",
    "    1. A value of 1 indicates perfect imputation;\n",
    "    2. A value of 0 indicates that observed agreement rate is equal to chance agreement rate; and\n",
    "    3. A negative value indicates that the method imputes poorly than by chance.\n",
    "    \n",
    "    This specific formula is used to compute the IQS of imputed genotypes\n",
    "    at biallelic sites in haploid genomes.\n",
    "    \"\"\"\n",
    "    assert len(genotypes_true) == len(genotypes_imputed)\n",
    "    assert set(genotypes_true) == set([0, 1]), \\\n",
    "        f\"Non-binary states in true genotypes {set(genotypes_true)}.\"\n",
    "    assert set(genotypes_imputed) == set([0, 1]), \\\n",
    "        f\"Non-binary states in imputed genotypes {set(genotypes_imputed)}.\"\n",
    "    \n",
    "    # Allele 0 imputed correctly\n",
    "    n00 = np.sum([y == 0 for x, y in zip(genotypes_imputed, genotypes_true) if x == 0])\n",
    "    # Allele 1 imputed correctly\n",
    "    n11 = np.sum([y == 1 for x, y in zip(genotypes_imputed, genotypes_true) if x == 1])\n",
    "    # Allele 1 imputed wrongly\n",
    "    n01 = np.sum([y == 1 for x, y in zip(genotypes_imputed, genotypes_true) if x == 0])\n",
    "    # Allele 1 imputed wrongly\n",
    "    n10 = np.sum([y == 0 for x, y in zip(genotypes_imputed, genotypes_true) if x == 1])\n",
    "    \n",
    "    # Marginal counts\n",
    "    n0_ = n00 + n01\n",
    "    n1_ = n10 + n11\n",
    "    n_0 = n00 + n10\n",
    "    n_1 = n01 + n11\n",
    "    \n",
    "    # Total genotypes imputed\n",
    "    n__ = n00 + n10 + n01 + n11\n",
    "    \n",
    "    # Observed overall concordance\n",
    "    Po = float(n00 + n11) / float(n__)\n",
    "    \n",
    "    # Chance agreement\n",
    "    Pc = float(n0_ * n_0 + n1_ * n_1) / float(n__ * n__)\n",
    "    \n",
    "    assert Po >= 0 and Po <= 1\n",
    "    assert Pc >= 0 and Pc <= 1\n",
    "    \n",
    "    iqs = (Po - Pc) / (1 - Pc)\n",
    "    \n",
    "    return(iqs)\n",
    "\n",
    "\n",
    "def run_pipeline(\n",
    "    replicate_index,\n",
    "    sampling_time_query,\n",
    "    prop_missing_sites,\n",
    "    do_test_run,\n",
    "    ):\n",
    "    ### Set simulation parameters\n",
    "    contig_id = '1'\n",
    "    ploidy_level = 1\n",
    "\n",
    "    if do_test_run:\n",
    "        # For testing\n",
    "        size_ref = 50\n",
    "        size_query = 50\n",
    "        eff_pop_size = 10_000\n",
    "        mutation_rate = 1e-7\n",
    "        recombination_rate = 1e-7\n",
    "        sequence_length = 10_000\n",
    "    else:\n",
    "        # For simulations\n",
    "        size_ref = 1e4\n",
    "        size_query = 1e3\n",
    "        eff_pop_size = 10_000\n",
    "        mutation_rate = 1e-8\n",
    "        recombination_rate = 1e-8\n",
    "        sequence_length = 1_000_000\n",
    "\n",
    "\n",
    "    ### Simulate genealogy and genetic variation\n",
    "    # Uniform recombination rate\n",
    "    recomb_rate_map = msprime.RateMap.uniform(\n",
    "        sequence_length=sequence_length,\n",
    "        rate=recombination_rate,\n",
    "    )\n",
    "\n",
    "    # Uniform mutation rate\n",
    "    mut_rate_map = msprime.RateMap.uniform(\n",
    "        sequence_length=sequence_length,\n",
    "        rate=mutation_rate,\n",
    "    )\n",
    "\n",
    "    sample_set = [\n",
    "        # Reference genomes\n",
    "        msprime.SampleSet(num_samples=size_ref,\n",
    "                        time=0,\n",
    "                        ploidy=ploidy_level),\n",
    "        # Query genomes\n",
    "        msprime.SampleSet(num_samples=size_query,\n",
    "                        time=sampling_time_query,\n",
    "                        ploidy=ploidy_level),\n",
    "    ]\n",
    "\n",
    "    # A simulated tree sequence does not contain any monoallelic sites,\n",
    "    # but there may be multiallelic sites.\n",
    "    ts_full = msprime.sim_mutations(\n",
    "        msprime.sim_ancestry(\n",
    "            samples=sample_set,\n",
    "            population_size=eff_pop_size,\n",
    "            model=\"hudson\",\n",
    "            recombination_rate=recomb_rate_map,\n",
    "            discrete_genome=True,\n",
    "        ),\n",
    "        rate=mut_rate_map,\n",
    "        discrete_genome=True,\n",
    "    )\n",
    "\n",
    "    # Remove populations\n",
    "    tables = ts_full.dump_tables()\n",
    "    tables.populations.clear()\n",
    "    tables.nodes.population = np.full_like(tables.nodes.population, tskit.NULL)\n",
    "    ts_full = tables.tree_sequence()\n",
    "\n",
    "    print(\"TS full\")\n",
    "    count_sites_by_type(ts_full)\n",
    "\n",
    "    # The first `size_ref` individuals or `ploidy_level` * `size_ref` samples are the reference panel.\n",
    "    # The remaining individuals and samples are the query/target to impute into.\n",
    "    individuals_ref = np.arange(size_ref, dtype=int)\n",
    "    samples_ref = np.arange(ploidy_level * size_ref, dtype=int)\n",
    "\n",
    "    individuals_query = np.arange(size_ref, size_ref + size_query, dtype=int)\n",
    "    samples_query = np.arange(ploidy_level * size_ref, ploidy_level * (size_ref + size_query), dtype=int)\n",
    "\n",
    "\n",
    "    ### Create an ancestor ts from the reference genomes\n",
    "    # Remove all the branches leading to the query genomes\n",
    "    ts_ref = ts_full.simplify(samples_ref, filter_sites=False)\n",
    "\n",
    "    print(f\"TS ref has {ts_ref.num_samples} sample genomes ({ts_ref.sequence_length} bp)\")\n",
    "    print(f\"TS ref has {ts_ref.num_sites} sites and {ts_ref.num_trees} trees\")\n",
    "    print(\"TS ref\")\n",
    "    count_sites_by_type(ts_ref)\n",
    "\n",
    "    # Multiallelic sites are automatically removed when generating an ancestor ts.\n",
    "    # Sites which are biallelic in the full sample set but monoallelic in the ref. sample set are removed.\n",
    "    # So, only biallelic sites are retained in the ancestor ts.\n",
    "    ts_anc = make_ancestors_ts(ts=ts_ref, remove_leaves=True)\n",
    "\n",
    "    print(f\"TS anc has {ts_anc.num_samples} sample genomes ({ts_anc.sequence_length} bp)\")\n",
    "    print(f\"TS anc has {ts_anc.num_sites} sites and {ts_anc.num_trees} trees\")\n",
    "    print(\"TS anc\")\n",
    "    count_sites_by_type(ts_anc)\n",
    "\n",
    "\n",
    "    ### Create a SampleData object holding the query genomes \n",
    "    sd_full = tsinfer.SampleData.from_tree_sequence(ts_full)\n",
    "    sd_query = sd_full.subset(individuals_query)\n",
    "\n",
    "    print(f\"SD query has {sd_query.num_samples} sample genomes ({sd_query.sequence_length} bp)\")\n",
    "    print(f\"SD query has {sd_query.num_sites} sites\")\n",
    "    print(\"SD query\")\n",
    "    count_sites_by_type(sd_query)\n",
    "\n",
    "    assert check_site_positions_ts_issubset_sd(ts_anc, sd_query)\n",
    "\n",
    "    sd_query_true = make_compatible_sample_data(\n",
    "        sample_data=sd_query,\n",
    "        ancestors_ts=ts_anc,\n",
    "    )\n",
    "\n",
    "\n",
    "    ### Create a SampleData object with masked sites\n",
    "    # Identify sites in both `sd_query` and `ts_anc`.\n",
    "    # This is a superset of the sites in `sd_query` to be masked and imputed.\n",
    "    shared_site_ids, shared_site_positions = compare_sites_sd_and_ts(sd_query_true, ts_anc, is_common=True)\n",
    "    print(f\"Shared sites: {len(shared_site_ids)}\")\n",
    "\n",
    "    # Identify sites in `sd_query` but not in `ts_anc`, which are not to be imputed.\n",
    "    exclude_site_ids, exclude_site_positions = compare_sites_sd_and_ts(sd_query_true, ts_anc, is_common=False)\n",
    "    print(f\"Exclude sites: {len(exclude_site_ids)}\")\n",
    "\n",
    "    assert len(set(shared_site_ids).intersection(set(exclude_site_ids))) == 0\n",
    "    assert len(set(shared_site_positions).intersection(set(exclude_site_positions))) == 0\n",
    "\n",
    "    # Select sites in `sd_query` to mask and impute.\n",
    "    # This is a subset of 'shared_site_ids'\n",
    "    masked_site_ids = pick_masked_sites_random(\n",
    "        site_ids=shared_site_ids,\n",
    "        prop_masked_sites=prop_missing_sites,\n",
    "    )\n",
    "    masked_site_positions = [s.position for s in sd_query_true.sites(ids=masked_site_ids)]\n",
    "    print(f\"Masked sites: {len(masked_site_ids)}\")\n",
    "\n",
    "    assert set(masked_site_ids).issubset(set(shared_site_ids))\n",
    "    assert set(masked_site_positions).issubset(set(shared_site_positions))\n",
    "\n",
    "    sd_query_masked = mask_sites_in_sample_data(sd_query_true, masked_sites=masked_site_ids)\n",
    "    \n",
    "    \n",
    "    ### Impute the query genomes\n",
    "    ts_imputed = tsinfer.match_samples(sample_data=sd_query_masked, ancestors_ts=ts_anc)\n",
    "\n",
    "\n",
    "    ### Evaluate imputation performance\n",
    "    ts_ref_site_positions = [s.position for s in ts_ref.sites()]\n",
    "    sd_query_true_site_positions = [s.position for s in sd_query_true.sites()]\n",
    "    sd_query_masked_site_positions = [s.position for s in sd_query_masked.sites()]\n",
    "    ts_imputed_site_positions = [s.position for s in ts_imputed.sites()]\n",
    "\n",
    "    assert len(ts_ref_site_positions) == len(sd_query_true_site_positions)\n",
    "    assert len(ts_ref_site_positions) == len(sd_query_masked_site_positions)\n",
    "    assert len(ts_ref_site_positions) == len(ts_imputed_site_positions)\n",
    "    \n",
    "    assert set(ts_ref_site_positions) == set(sd_query_true_site_positions)\n",
    "    assert set(ts_ref_site_positions) == set(sd_query_masked_site_positions)\n",
    "    assert set(ts_ref_site_positions) == set(ts_imputed_site_positions)\n",
    "\n",
    "    results = None\n",
    "    for v_ref, v_query_true, v_query_masked, v_query_imputed in zip(\n",
    "        ts_ref.variants(), # Reference genomes from which to get the minor allele and MAF\n",
    "        sd_query_true.variants(), # Query genomes before site masking\n",
    "        sd_query_masked.variants(), # Query genomes with masked sites\n",
    "        ts_imputed.variants() # Query genomes with masked sites imputed\n",
    "    ):\n",
    "        if v_query_imputed.site.position in masked_site_positions:\n",
    "            # CHECK that ancestral states are identical.\n",
    "            assert v_ref.alleles[0] == sd_query_true.sites_alleles[v_query_true.site.id][0]\n",
    "            assert v_ref.alleles[0] == sd_query_masked.sites_alleles[v_query_masked.site.id][0]\n",
    "            assert v_ref.alleles[0] == v_query_imputed.alleles[0]\n",
    "            \n",
    "            # TODO:\n",
    "            #   Why doesn't `v.num_alleles` always reflect the number of genotypes\n",
    "            #   after simplifying?\n",
    "            if len(set(v_ref.genotypes)) == 1:\n",
    "                # Monoallelic sites in `ts_ref` are not imputed\n",
    "                # TODO: Revisit\n",
    "                continue\n",
    "                \n",
    "            assert v_ref.num_alleles == 2\n",
    "            #assert v_query_true.num_alleles == 2\n",
    "            assert set(v_query_masked.genotypes) == set([-1])\n",
    "            assert v_query_imputed.num_alleles == 2\n",
    "            \n",
    "            # Note: A minor allele in `ts_ref` may be a major allele in `sd_query`\n",
    "            freqs_ref = v_ref.frequencies()\n",
    "            af_0 = freqs_ref[v_ref.alleles[0]]\n",
    "            af_1 = freqs_ref[v_ref.alleles[1]]\n",
    "            \n",
    "            # Get MAF from `ts_ref`\n",
    "            # Definition of a minor allele: < 0.50\n",
    "            if af_1 < af_0:\n",
    "                minor_allele_index = 1\n",
    "                maf = af_1\n",
    "            else:\n",
    "                minor_allele_index = 0\n",
    "                maf = af_0\n",
    "            \n",
    "            assert not np.any(v_query_imputed.genotypes == -1)\n",
    "            \n",
    "            return((v_query_true.genotypes, v_query_imputed.genotypes,))\n",
    "            \n",
    "            # Assess imputation performance\n",
    "            total_concordance = np.sum(v_query_true.genotypes == v_query_imputed.genotypes) / len(v_query_true.genotypes)\n",
    "            iqs = compute_iqs(genotypes_true=v_query_true.genotypes, genotypes_imputed=v_query_imputed.genotypes)\n",
    "            \n",
    "            # line.shape = (1, 4)\n",
    "            line = np.array([ [v_ref.site.position, maf, total_concordance, iqs], ])\n",
    "            if results is None:\n",
    "                results = line\n",
    "            else:\n",
    "                results = np.append(results, line, axis=0)\n",
    "\n",
    "    end_datetime = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "    ### Write results\n",
    "    out_results_file = \"sim\" + \"_\" + str(replicate_index) + \".csv\"\n",
    "\n",
    "    header_text = \"\\n\".join(\n",
    "        [\n",
    "            \"#\" + \"start_timestamp\" + \"=\" + f\"{start_datetime}\",\n",
    "            \"#\" + \"end_timestamp\" + \"=\" + f\"{end_datetime}\",\n",
    "            \"#\" + \"msprime\" + \"=\" + f\"{msprime.__version__}\",\n",
    "            \"#\" + \"tskit\" + \"=\" + f\"{tskit.__version__}\",\n",
    "            \"#\" + \"tsinfer\" + \"=\" + f\"{tsinfer.__version__}\",\n",
    "            \"#\" + \"replicate\" + \"=\" + f\"{replicate_index}\",\n",
    "            \"#\" + \"size_ref\" + \"=\" + f\"{size_ref}\",\n",
    "            \"#\" + \"size_query\" + \"=\" + f\"{size_query}\",\n",
    "            \"#\" + \"eff_pop_size\" + \"=\" + f\"{eff_pop_size}\",\n",
    "            \"#\" + \"mutation_rate\" + \"=\" + f\"{mutation_rate}\",\n",
    "            \"#\" + \"recombination_rate\" + \"=\" + f\"{recombination_rate}\",\n",
    "            \"#\" + \"contig_id\" + \"=\" + f\"{contig_id}\",\n",
    "            \"#\" + \"ploidy_level\" + \"=\" + f\"{ploidy_level}\",\n",
    "            \"#\" + \"sequence_length\" + \"=\" + f\"{sequence_length}\",\n",
    "            \"#\" + \"sampling_time_query\" + \"=\" + f\"{sampling_time_query}\",\n",
    "            \"#\" + \"prop_missing_sites\" + \"=\" + f\"{prop_missing_sites}\",\n",
    "        ]\n",
    "    ) + \"\\n\"\n",
    "\n",
    "    header_text += \",\".join(\n",
    "        [\n",
    "            \"position\",\n",
    "            \"maf\",\n",
    "            \"total_concordance\",\n",
    "            \"iqs\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    np.savetxt(\n",
    "        out_results_file,\n",
    "        results,\n",
    "        fmt='%.10f',\n",
    "        delimiter=\",\",\n",
    "        newline=\"\\n\",\n",
    "        comments=\"\",\n",
    "        header=header_text,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bba28f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS full\n",
      "\tsites mono : 0\n",
      "\tsites bi   : 4397 (700 singletons)\n",
      "\tsites tri  : 4\n",
      "\tsites quad : 0\n",
      "\tsites total: 4401\n",
      "TS ref has 10000 sample genomes (1000000.0 bp)\n",
      "TS ref has 4401 sites and 3717 trees\n",
      "TS ref\n",
      "\tsites mono : 513\n",
      "\tsites bi   : 3885 (423 singletons)\n",
      "\tsites tri  : 3\n",
      "\tsites quad : 0\n",
      "\tsites total: 4401\n",
      "TS anc has 12875 sample genomes (1000000.0 bp)\n",
      "TS anc has 3460 sites and 1800 trees\n",
      "TS anc\n",
      "\tsites mono : 0\n",
      "\tsites bi   : 3460 (0 singletons)\n",
      "\tsites tri  : 0\n",
      "\tsites quad : 0\n",
      "\tsites total: 3460\n",
      "SD query has 1000 sample genomes (1000000.0 bp)\n",
      "SD query has 4401 sites\n",
      "SD query\n",
      "\tsites mono : 0\n",
      "\tsites bi   : 4397 (416 singletons)\n",
      "\tsites tri  : 4\n",
      "\tsites quad : 0\n",
      "\tsites total: 4401\n",
      "Shared sites: 3460\n",
      "Exclude sites: 941\n",
      "Masked sites: 2768\n"
     ]
    }
   ],
   "source": [
    "gt_true, gt_imputed = run_pipeline(\n",
    "    replicate_index=0,\n",
    "    sampling_time_query=100,\n",
    "    prop_missing_sites=0.80,\n",
    "    do_test_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89b100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
