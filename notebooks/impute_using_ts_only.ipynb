{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfccae17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msprime 1.1.1\n",
      "tskit 0.5.2.dev0\n",
      "tsinfer 0.2.3\n",
      "datetime 25/07/2022 12:34:45\n"
     ]
    }
   ],
   "source": [
    "import click\n",
    "import gzip\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import msprime\n",
    "import tskit\n",
    "import tsinfer\n",
    "from tsinfer import make_ancestors_ts\n",
    "\n",
    "print(f\"msprime {msprime.__version__}\")\n",
    "print(f\"tskit {tskit.__version__}\")\n",
    "print(f\"tsinfer {tsinfer.__version__}\")\n",
    "\n",
    "start_datetime = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(f\"datetime {start_datetime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c0a99",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5f8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sites_by_type(\n",
    "    ts_or_sd\n",
    "):\n",
    "    \"\"\"\n",
    "    Iterate through the variants of a TreeSequence or SampleData object,\n",
    "    and count the number of mono-, bi-, tri-, and quad-allelic sites.\n",
    "    \n",
    "    :param TreeSequence/SampleData ts_or_sd:\n",
    "    :return None:\n",
    "    \"\"\"\n",
    "    assert isinstance(ts_or_sd, (tskit.TreeSequence, tsinfer.SampleData))\n",
    "    \n",
    "    sites_mono = 0\n",
    "    sites_bi = 0\n",
    "    sites_bi_singleton = 0\n",
    "    sites_tri = 0\n",
    "    sites_quad = 0\n",
    "    \n",
    "    for v in ts_or_sd.variants():\n",
    "        num_alleles = len(set(v.alleles) - {None})\n",
    "        if num_alleles == 1:\n",
    "            sites_mono += 1\n",
    "        elif num_alleles == 2:\n",
    "            sites_bi += 1\n",
    "            if np.sum(v.genotypes) == 1:\n",
    "                sites_bi_singleton += 1\n",
    "        elif num_alleles == 3:\n",
    "            sites_tri += 1\n",
    "        else:\n",
    "            sites_quad += 1\n",
    "    \n",
    "    sites_total = sites_mono + sites_bi + sites_tri + sites_quad\n",
    "    \n",
    "    print(f\"\\tsites mono : {sites_mono}\")\n",
    "    print(f\"\\tsites bi   : {sites_bi} ({sites_bi_singleton} singletons)\")\n",
    "    print(f\"\\tsites tri  : {sites_tri}\")\n",
    "    print(f\"\\tsites quad : {sites_quad}\")\n",
    "    print(f\"\\tsites total: {sites_total}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4443280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_site_positions_ts_issubset_sd(\n",
    "    tree_sequence,\n",
    "    sample_data\n",
    "):\n",
    "    \"\"\"\n",
    "    Check whether the site positions in `TreeSequence` are a subset of\n",
    "    the site positions in `SampleData`.\n",
    "    \n",
    "    :param TreeSequence tree_sequence:\n",
    "    :param SampleData sample_data:\n",
    "    :return bool:\n",
    "    \"\"\"\n",
    "    ts_site_positions = np.empty(tree_sequence.num_sites)\n",
    "    sd_site_positions = np.empty(sample_data.num_sites)\n",
    "    \n",
    "    i = 0\n",
    "    for v in tree_sequence.variants():\n",
    "        ts_site_positions[i] = v.site.position\n",
    "        i += 1\n",
    "        \n",
    "    j = 0\n",
    "    for v in sample_data.variants():\n",
    "        sd_site_positions[j] = v.site.position\n",
    "        j += 1\n",
    "        \n",
    "    assert i == tree_sequence.num_sites\n",
    "    assert j == sample_data.num_sites\n",
    "    \n",
    "    if set(ts_site_positions).issubset(set(sd_site_positions)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837db948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sites_sd_and_ts(\n",
    "    sample_data,\n",
    "    tree_sequence,\n",
    "    is_common,\n",
    "    check_matching_ancestral_state=True\n",
    "):\n",
    "    \"\"\"\n",
    "    If `is_common` is set to True, then get the ids and positions of the sites\n",
    "    found in `sample_data` AND in `tree_sequence`.\n",
    "    \n",
    "    if `is_common` is set to False, then get the ids and positions of the sites\n",
    "    found in `sample_data` but NOT in `tree_sequence`.\n",
    "    \n",
    "    :param TreeSequence tree_sequence:\n",
    "    :param SampleData sample_data:\n",
    "    :param is_common bool:\n",
    "    :param check_matching_ancestral_state bool: (default=True)\n",
    "    :return tuple(np.array, np.array):\n",
    "    \"\"\"\n",
    "    ts_site_positions = np.empty(tree_sequence.num_sites)\n",
    "    \n",
    "    i = 0\n",
    "    for v in tree_sequence.variants():\n",
    "        ts_site_positions[i] = v.site.position\n",
    "        i += 1\n",
    "        \n",
    "    assert i == tree_sequence.num_sites\n",
    "    \n",
    "    sd_site_ids = []\n",
    "    sd_site_positions = []\n",
    "    for sd_v in sample_data.variants():\n",
    "        if is_common:\n",
    "            if sd_v.site.position in ts_site_positions:\n",
    "                sd_site_ids.append(sd_v.site.id)\n",
    "                sd_site_positions.append(sd_v.site.position)\n",
    "                if check_matching_ancestral_state:\n",
    "                    ts_site = tree_sequence.site(position=sd_v.site.position)\n",
    "                    assert sd_v.site.ancestral_state == ts_site.ancestral_state, \\\n",
    "                        f\"Ancestral states at {sd_v.site.position} not the same, \" + \\\n",
    "                        f\"{sd_v.site.ancestral_state} vs. {ts_site.ancestral_state}.\"\n",
    "        else:\n",
    "            if sd_v.site.position not in ts_site_positions:\n",
    "                sd_site_ids.append(sd_v.site.id)\n",
    "                sd_site_positions.append(sd_v.site.position)\n",
    "    \n",
    "    return(\n",
    "        (\n",
    "            np.array(sd_site_ids),\n",
    "            np.array(sd_site_positions),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33040e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_compatible_sample_data(\n",
    "    sample_data,\n",
    "    ancestors_ts\n",
    "):\n",
    "    \"\"\"\n",
    "    Make an editable copy of a `sample_data` object, and edit it so that:\n",
    "    (1) the derived alleles in `sample_data` not in `ancestors_ts` are marked as MISSING;\n",
    "    (2) the allele list in `new_sample_data` corresponds to the allele list in `ancestors_ts`.\n",
    "    \n",
    "    N.B. Two `SampleData` attributes `sites_alleles` and `sites_genotypes`,\n",
    "    which are not explained in the tsinfer API doc, are used to facilitate the editing.\n",
    "    \n",
    "    :param SampleData sample_data:\n",
    "    :param TreeSequence ancestors_ts:\n",
    "    :return SampleData:\n",
    "    \"\"\"\n",
    "    new_sample_data = sample_data.copy()\n",
    "    \n",
    "    # Iterate through the sites in `ancestors_ts` using one generator,\n",
    "    # while iterating through the sites in `sample_data` using another generator,\n",
    "    # letting the latter generator catch up.\n",
    "    sd_variants = sample_data.variants()\n",
    "    sd_v = next(sd_variants)\n",
    "    for ts_site in ancestors_ts.sites():\n",
    "        while sd_v.site.position != ts_site.position:\n",
    "            # Sites in `samples_data` but not in `ancestors_ts` are not imputed.\n",
    "            # Also, leave them as is in the `sample_data`, but keep track of them.\n",
    "            sd_v = next(sd_variants)\n",
    "            \n",
    "        sd_site_id = sd_v.site.id # Site id in `sample_data`\n",
    "        \n",
    "        # CHECK that all the sites in `ancestors_ts` are biallelic.\n",
    "        assert len(ts_site.alleles) == 2\n",
    "        \n",
    "        # Get the derived allele in `ancestors_ts` in nucleotide space\n",
    "        ts_ancestral_allele = ts_site.ancestral_state\n",
    "        ts_derived_allele = ts_site.alleles - {ts_ancestral_allele}\n",
    "        assert len(ts_derived_allele) == 1 # CHECK\n",
    "        ts_derived_allele = tuple(ts_derived_allele)[0]\n",
    "        \n",
    "        # CHECK that the ancestral allele should be the same\n",
    "        # in both `ancestors_ts` and `sample_data`.\n",
    "        assert ts_ancestral_allele == sd_v.alleles[0]\n",
    "        \n",
    "        if ts_derived_allele not in sd_v.alleles:\n",
    "            # Case 1:\n",
    "            # If the derived alleles in the `sample_data` are not in `ancestors_ts`,\n",
    "            # then mark them as missing.\n",
    "            #\n",
    "            # The site in `sample_data` may be mono-, bi-, or multiallelic.\n",
    "            #\n",
    "            # We cannot determine whether the extra derived alleles in `sample_data`\n",
    "            # are derived from 0 or 1 in `ancestors_ts` anyway.\n",
    "            new_sample_data.sites_genotypes[sd_site_id] = np.where(\n",
    "                sd_v.genotypes != 0, # Keep if ancestral\n",
    "                tskit.MISSING_DATA, # Otherwise, flag as missing\n",
    "                0,\n",
    "            )\n",
    "            print(f\"Site {sd_site_id} has no matching derived alleles in the query samples.\")\n",
    "            # Update allele list\n",
    "            new_sample_data.sites_alleles[sd_site_id] = [ts_ancestral_allele]\n",
    "        else:\n",
    "            # The allele lists in `ancestors_ts` and `sample_data` may be different.\n",
    "            ts_derived_allele_index = sd_v.alleles.index(ts_derived_allele)\n",
    "            \n",
    "            if ts_derived_allele_index == 1:\n",
    "                # Case 2:\n",
    "                # Both the ancestral and derived alleles correspond exactly.\n",
    "                if len(sd_v.alleles) == 2:\n",
    "                    continue\n",
    "                # Case 3:\n",
    "                # The derived allele in `ancestors_ts` is indexed as 1 in `sample_data`,\n",
    "                # so mark alleles >= 2 as missing.\n",
    "                new_sample_data.sites_genotypes[sd_site_id] = np.where(\n",
    "                    sd_v.genotypes > 1, # 0 and 1 should be kept \"as is\"\n",
    "                    tskit.MISSING_DATA, # Otherwise, flag as missing\n",
    "                    sd_v.genotypes,\n",
    "                )\n",
    "                print(f\"Site {sd_site_id} has extra derived allele(s) in the query samples (set as missing).\")\n",
    "            else:\n",
    "                # Case 4:\n",
    "                #   The derived allele in `ancestors_ts` is NOT indexed as 1 in `sample_data`,\n",
    "                #   so the alleles in `sample_data` needs to be reordered,\n",
    "                #   such that the 1-indexed allele is also indexed as 1 in `ancestors_ts`.\n",
    "                new_sample_data.sites_genotypes[sd_site_id] = np.where(\n",
    "                    sd_v.genotypes == 0,\n",
    "                    0, # Leave ancestral allele \"as is\"\n",
    "                    np.where(\n",
    "                        sd_v.genotypes == ts_derived_allele_index,\n",
    "                        1, # Change it to 1 so that it corresponds to `ancestors_ts`\n",
    "                        tskit.MISSING_DATA, # Otherwise, mark as missing\n",
    "                    ),\n",
    "                )\n",
    "                print(f\"Site {sd_site_id} has the target derived allele at a different index.\")\n",
    "            # Update allele list\n",
    "            new_sample_data.sites_alleles[sd_site_id] = [ts_ancestral_allele, ts_derived_allele]\n",
    "            \n",
    "    new_sample_data.finalise()\n",
    "    \n",
    "    return(new_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b8da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_masked_sites_random(\n",
    "    site_ids,\n",
    "    prop_masked_sites\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw N sites from `sites_ids` at random, where N is the number of sites to mask\n",
    "    based on a specified proportion of masked sites `prop_masked_sites`.\n",
    "    \n",
    "    TODO: Specify random seed.\n",
    "    \n",
    "    :param np.array site_ids:\n",
    "    :param float prop_masked_sites: float between 0 and 1\n",
    "    :return np.array: list of site ids\n",
    "    \"\"\"\n",
    "    assert prop_masked_sites >= 0\n",
    "    assert prop_masked_sites <= 1\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    num_masked_sites = int(np.floor(len(site_ids) * prop_masked_sites))\n",
    "    \n",
    "    masked_site_ids = np.sort(\n",
    "        rng.choice(\n",
    "            site_ids,\n",
    "            num_masked_sites,\n",
    "            replace=False,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return(masked_site_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06fe9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sites_in_sample_data(\n",
    "    sample_data,\n",
    "    masked_sites=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create and return a `SampleData` object from an existing `SampleData` object,\n",
    "    which contains masked sites as listed in `masked_sites` (site ids).\n",
    "    \n",
    "    :param SampleData sample_data:\n",
    "    :param np.array masked_sites: list of site ids (NOT positions)\n",
    "    :return SampleData:\n",
    "    \"\"\"\n",
    "    new_sample_data = sample_data.copy()\n",
    "    \n",
    "    for v in sample_data.variants():\n",
    "        if v.site.id in masked_sites:\n",
    "            new_sample_data.sites_genotypes[v.site.id] = np.full_like(v.genotypes, tskit.MISSING_DATA)\n",
    "    \n",
    "    new_sample_data.finalise()\n",
    "    \n",
    "    return(new_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa815a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iqs(\n",
    "    genotypes_true,\n",
    "    genotypes_imputed\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate the Imputation Quality Score between `genotypes_true` and `genotypes_imputed`.\n",
    "    1. A value of 1 indicates perfect imputation;\n",
    "    2. A value of 0 indicates that observed agreement rate is equal to chance agreement rate; and\n",
    "    3. A negative value indicates that the method imputes poorly than by chance.\n",
    "    \n",
    "    This specific formula is used to compute the IQS of imputed genotypes\n",
    "    at biallelic sites in haploid genomes.\n",
    "    \"\"\"\n",
    "    assert len(genotypes_true) == len(genotypes_imputed)\n",
    "    assert set(genotypes_true) == set([0, 1]), \\\n",
    "        f\"Non-binary states in true genotypes {set(genotypes_true)}.\"\n",
    "    assert set(genotypes_imputed) == set([0, 1]), \\\n",
    "        f\"Non-binary states in imputed genotypes {set(genotypes_imputed)}.\"\n",
    "    \n",
    "    # Allele 0 imputed correctly\n",
    "    n00 = np.sum([y == 0 for x, y in zip(genotypes_imputed, genotypes_true) if x == 0])\n",
    "    # Allele 1 imputed correctly\n",
    "    n11 = np.sum([y == 1 for x, y in zip(genotypes_imputed, genotypes_true) if x == 1])\n",
    "    # Allele 1 imputed wrongly\n",
    "    n01 = np.sum([y == 1 for x, y in zip(genotypes_imputed, genotypes_true) if x == 0])\n",
    "    # Allele 1 imputed wrongly\n",
    "    n10 = np.sum([y == 0 for x, y in zip(genotypes_imputed, genotypes_true) if x == 1])\n",
    "    \n",
    "    # Marginal counts\n",
    "    n0_ = n00 + n01\n",
    "    n1_ = n10 + n11\n",
    "    n_0 = n00 + n10\n",
    "    n_1 = n01 + n11\n",
    "    \n",
    "    # Total genotypes imputed\n",
    "    n__ = n00 + n10 + n01 + n11\n",
    "    \n",
    "    # Observed overall concordance\n",
    "    Po = float(n00 + n11) / float(n__)\n",
    "    \n",
    "    # Chance agreement\n",
    "    Pc = float(n0_ * n_0 + n1_ * n_1) / float(n__ * n__)\n",
    "    \n",
    "    assert Po >= 0 and Po <= 1\n",
    "    assert Pc >= 0 and Pc <= 1\n",
    "    \n",
    "    iqs = (Po - Pc) / (1 - Pc)\n",
    "    \n",
    "    return(iqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d141a7",
   "metadata": {},
   "source": [
    "### Set simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd9bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate_index = 0\n",
    "sampling_time_query = 100\n",
    "prop_missing_sites = 0.80\n",
    "\n",
    "contig_id = '1'\n",
    "ploidy_level = 1\n",
    "\n",
    "# For simulations\n",
    "# size_ref   = 1e4\n",
    "# size_query = 1e3\n",
    "# eff_pop_size = 10_000\n",
    "# mutation_rate = 1e-8\n",
    "# recombination_rate = 1e-8\n",
    "# sequence_length = 1_000_000\n",
    "\n",
    "# For testing\n",
    "size_ref   = 50\n",
    "size_query = 50\n",
    "eff_pop_size = 10_000\n",
    "mutation_rate = 1e-6\n",
    "recombination_rate = 1e-7\n",
    "sequence_length = 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebba5b8",
   "metadata": {},
   "source": [
    "### Simulate genealogy and genetic variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab44e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS full\n",
      "\tsites mono : 0\n",
      "\tsites bi   : 1820 (365 singletons)\n",
      "\tsites tri  : 135\n",
      "\tsites quad : 1\n",
      "\tsites total: 1956\n"
     ]
    }
   ],
   "source": [
    "# Uniform recombination rate\n",
    "recomb_rate_map = msprime.RateMap.uniform(\n",
    "    sequence_length=sequence_length,\n",
    "    rate=recombination_rate,\n",
    ")\n",
    "\n",
    "# Uniform mutation rate\n",
    "mut_rate_map = msprime.RateMap.uniform(\n",
    "    sequence_length=sequence_length,\n",
    "    rate=mutation_rate,\n",
    ")\n",
    "\n",
    "sample_set = [\n",
    "    # Reference genomes\n",
    "    msprime.SampleSet(num_samples=size_ref,\n",
    "                      time=0,\n",
    "                      ploidy=ploidy_level),\n",
    "    # Query genomes\n",
    "    msprime.SampleSet(num_samples=size_query,\n",
    "                      time=sampling_time_query,\n",
    "                      ploidy=ploidy_level),\n",
    "]\n",
    "\n",
    "# A simulated tree sequence does not contain any monoallelic sites,\n",
    "# but there may be multiallelic sites.\n",
    "ts_full = msprime.sim_mutations(\n",
    "    msprime.sim_ancestry(\n",
    "        samples=sample_set,\n",
    "        population_size=eff_pop_size,\n",
    "        model=\"hudson\",\n",
    "        recombination_rate=recomb_rate_map,\n",
    "        discrete_genome=True,\n",
    "    ),\n",
    "    rate=mut_rate_map,\n",
    "    discrete_genome=True,\n",
    ")\n",
    "\n",
    "# Remove populations\n",
    "tables = ts_full.dump_tables()\n",
    "tables.populations.clear()\n",
    "tables.nodes.population = np.full_like(tables.nodes.population, tskit.NULL)\n",
    "ts_full = tables.tree_sequence()\n",
    "\n",
    "print(\"TS full\")\n",
    "count_sites_by_type(ts_full)\n",
    "\n",
    "# The first `size_ref` individuals or `ploidy_level` * `size_ref` samples are the reference panel.\n",
    "# The remaining individuals and samples are the query/target to impute into.\n",
    "individuals_ref = np.arange(size_ref, dtype=int)\n",
    "samples_ref = np.arange(ploidy_level * size_ref, dtype=int)\n",
    "\n",
    "individuals_query = np.arange(size_ref, size_ref + size_query, dtype=int)\n",
    "samples_query = np.arange(ploidy_level * size_ref, ploidy_level * (size_ref + size_query), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f070b0",
   "metadata": {},
   "source": [
    "### Create an ancestor ts from the reference genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a50b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS ref has 50 sample genomes (10000.0 bp)\n",
      "TS ref has 1956 sites and 152 trees\n",
      "TS ref\n",
      "\tsites mono : 292\n",
      "\tsites bi   : 1567 (352 singletons)\n",
      "\tsites tri  : 96\n",
      "\tsites quad : 1\n",
      "\tsites total: 1956\n",
      "TS anc has 161 sample genomes (10000.0 bp)\n",
      "TS anc has 1174 sites and 138 trees\n",
      "TS anc\n",
      "\tsites mono : 0\n",
      "\tsites bi   : 1174 (0 singletons)\n",
      "\tsites tri  : 0\n",
      "\tsites quad : 0\n",
      "\tsites total: 1174\n"
     ]
    }
   ],
   "source": [
    "# Remove all the branches leading to the query genomes\n",
    "ts_ref = ts_full.simplify(samples_ref, filter_sites=False)\n",
    "\n",
    "print(f\"TS ref has {ts_ref.num_samples} sample genomes ({ts_ref.sequence_length} bp)\")\n",
    "print(f\"TS ref has {ts_ref.num_sites} sites and {ts_ref.num_trees} trees\")\n",
    "print(\"TS ref\")\n",
    "count_sites_by_type(ts_ref)\n",
    "\n",
    "# Multiallelic sites are automatically removed when generating an ancestor ts.\n",
    "# Sites which are biallelic in the full sample set but monoallelic in the ref. sample set are removed.\n",
    "# So, only biallelic sites are retained in the ancestor ts.\n",
    "ts_anc = make_ancestors_ts(ts=ts_ref, remove_leaves=True, samples=None)\n",
    "\n",
    "print(f\"TS anc has {ts_anc.num_samples} sample genomes ({ts_anc.sequence_length} bp)\")\n",
    "print(f\"TS anc has {ts_anc.num_sites} sites and {ts_anc.num_trees} trees\")\n",
    "print(\"TS anc\")\n",
    "count_sites_by_type(ts_anc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198e49f",
   "metadata": {},
   "source": [
    "### Create a SampleData object holding the query genomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1551a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SD query has 50 sample genomes (10000.0 bp)\n",
      "SD query has 1956 sites\n",
      "SD query\n",
      "\tsites mono : 0\n",
      "\tsites bi   : 1820 (346 singletons)\n",
      "\tsites tri  : 135\n",
      "\tsites quad : 1\n",
      "\tsites total: 1956\n",
      "Site 37 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 89 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 356 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 367 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 408 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 445 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 715 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 778 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 786 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 823 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 929 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 954 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 957 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 986 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 993 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1233 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1270 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1302 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1316 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1340 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1354 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1449 has the target derived allele at a different index.\n",
      "Site 1525 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1526 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1534 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1564 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1705 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1738 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1762 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1790 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1794 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1883 has extra derived allele(s) in the query samples (set as missing).\n",
      "Site 1899 has extra derived allele(s) in the query samples (set as missing).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szhan/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/zarr/storage.py:434: FutureWarning: missing object_codec for object array; this will raise a ValueError in version 3.0\n",
      "  warnings.warn('missing object_codec for object array; this will raise a '\n"
     ]
    }
   ],
   "source": [
    "sd_full = tsinfer.SampleData.from_tree_sequence(ts_full)\n",
    "sd_query = sd_full.subset(individuals_query)\n",
    "\n",
    "print(f\"SD query has {sd_query.num_samples} sample genomes ({sd_query.sequence_length} bp)\")\n",
    "print(f\"SD query has {sd_query.num_sites} sites\")\n",
    "print(\"SD query\")\n",
    "count_sites_by_type(sd_query)\n",
    "\n",
    "assert check_site_positions_ts_issubset_sd(ts_anc, sd_query)\n",
    "\n",
    "new_sd_query = make_compatible_sample_data(\n",
    "    sample_data=sd_query,\n",
    "    ancestors_ts=ts_anc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b286eed",
   "metadata": {},
   "source": [
    "### Create a SampleData object with masked sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c84771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared sites: 1174\n",
      "Exclude sites: 782\n",
      "Masked sites: 939\n"
     ]
    }
   ],
   "source": [
    "# Identify sites in both `sd_query` and `ts_anc`.\n",
    "# This is a superset of the sites in `sd_query` to be masked and imputed.\n",
    "shared_site_ids, shared_site_positions = compare_sites_sd_and_ts(sd_query, ts_anc, is_common=True)\n",
    "print(f\"Shared sites: {len(shared_site_ids)}\")\n",
    "\n",
    "# Identify sites in `sd_query` but not in `ts_anc`, which are not to be imputed.\n",
    "exclude_site_ids, exclude_site_positions = compare_sites_sd_and_ts(sd_query, ts_anc, is_common=False)\n",
    "print(f\"Exclude sites: {len(exclude_site_ids)}\")\n",
    "\n",
    "assert len(set(shared_site_ids).intersection(set(exclude_site_ids))) == 0\n",
    "assert len(set(shared_site_positions).intersection(set(exclude_site_positions))) == 0\n",
    "\n",
    "# Select sites in `sd_query` to mask and impute.\n",
    "# This is a subset of 'shared_site_ids'\n",
    "masked_site_ids = pick_masked_sites_random(\n",
    "    site_ids=shared_site_ids,\n",
    "    prop_masked_sites=prop_missing_sites,\n",
    ")\n",
    "masked_site_positions = [site.position for site in sd_query.sites(ids=masked_site_ids)]\n",
    "print(f\"Masked sites: {len(masked_site_ids)}\")\n",
    "\n",
    "assert set(masked_site_ids).issubset(set(shared_site_ids))\n",
    "assert set(masked_site_positions).issubset(set(shared_site_positions))\n",
    "\n",
    "sd_query_masked = mask_sites_in_sample_data(\n",
    "    new_sd_query,\n",
    "    masked_sites=masked_site_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de37c9c",
   "metadata": {},
   "source": [
    "### Impute the query genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "126d79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_imp = tsinfer.match_samples(\n",
    "    sample_data=sd_query_masked,\n",
    "    ancestors_ts=ts_anc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56f72c",
   "metadata": {},
   "source": [
    "### Evaluate imputation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1b9db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_ref_site_pos = [s.position for s in ts_ref.sites()]\n",
    "ts_imp_site_pos = [s.position for s in ts_imp.sites()]\n",
    "\n",
    "assert len(set(ts_ref_site_pos).intersection(set(ts_imp_site_pos))) == len(ts_ref_site_pos)\n",
    "\n",
    "results = None\n",
    "for v_ref, v_imp in zip(ts_ref.variants(), ts_imp.variants()):\n",
    "    if v_imp.site.position in masked_site_positions:\n",
    "        assert v_ref.alleles[0] == v_imp.alleles[0]\n",
    "        # TODO:\n",
    "        #   Why doesn't `v.num_alleles` always reflect the number of genotypes\n",
    "        #   after simplifying?\n",
    "        if len(set(v_ref.genotypes)) == 1 or len(set(v_imp.genotypes)) == 1:\n",
    "            # Monoallelic sites in `ts_ref` or `sd_query` are not imputed\n",
    "            continue\n",
    "        assert v_ref.num_alleles == 2\n",
    "        assert v_imp.num_alleles == 2\n",
    "        \n",
    "        freqs_ref = v_ref.frequencies()\n",
    "        freqs_imp = v_imp.frequencies()\n",
    "        \n",
    "        # Note: A minor allele in `ts_ref` may be a major allele in `sd_query`\n",
    "        af_0 = freqs_ref[v_ref.alleles[0]]\n",
    "        af_1 = freqs_ref[v_ref.alleles[1]]\n",
    "        \n",
    "        # Get MAF from `ts_ref`\n",
    "        if af_1 < af_0:\n",
    "            minor_allele_index = 1\n",
    "            maf = af_1\n",
    "        assert not np.any(v_imp.genotypes == -1)\n",
    "        \n",
    "        # Assess imputation performance\n",
    "        total_concordance = np.sum(v_ref.genotypes == v_imp.genotypes) / len(v_ref.genotypes)\n",
    "        iqs = compute_iqs(genotypes_true=v_ref.genotypes, genotypes_imputed=v_imp.genotypes)\n",
    "        \n",
    "        # line.shape = (1, 4)\n",
    "        line = np.array([ [v_ref.site.position, maf, total_concordance, iqs], ])\n",
    "        if results is None:\n",
    "            results = line\n",
    "        else:\n",
    "            results = np.append(results, line, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad95042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_datetime = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc3d01",
   "metadata": {},
   "source": [
    "### Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef838056",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_results_file = \"sim\" + \"_\" + str(replicate_index) + \".csv\"\n",
    "\n",
    "header_text = \"\\n\".join(\n",
    "    [\n",
    "        \"#\" + \"start_timestamp\" + \"=\" + f\"{start_datetime}\",\n",
    "        \"#\" + \"end_timestamp\" + \"=\" + f\"{end_datetime}\",\n",
    "        \"#\" + \"msprime\" + \"=\" + f\"{msprime.__version__}\",\n",
    "        \"#\" + \"tskit\" + \"=\" + f\"{tskit.__version__}\",\n",
    "        \"#\" + \"tsinfer\" + \"=\" + f\"{tsinfer.__version__}\",\n",
    "        \"#\" + \"replicate\" + \"=\" + f\"{replicate_index}\",\n",
    "        \"#\" + \"size_ref\" + \"=\" + f\"{size_ref}\",\n",
    "        \"#\" + \"size_query\" + \"=\" + f\"{size_query}\",\n",
    "        \"#\" + \"eff_pop_size\" + \"=\" + f\"{eff_pop_size}\",\n",
    "        \"#\" + \"mutation_rate\" + \"=\" + f\"{mutation_rate}\",\n",
    "        \"#\" + \"recombination_rate\" + \"=\" + f\"{recombination_rate}\",\n",
    "        \"#\" + \"contig_id\" + \"=\" + f\"{contig_id}\",\n",
    "        \"#\" + \"ploidy_level\" + \"=\" + f\"{ploidy_level}\",\n",
    "        \"#\" + \"sequence_length\" + \"=\" + f\"{sequence_length}\",\n",
    "        \"#\" + \"sampling_time_query\" + \"=\" + f\"{sampling_time_query}\",\n",
    "        \"#\" + \"prop_missing_sites\" + \"=\" + f\"{prop_missing_sites}\",\n",
    "    ]\n",
    ") + \"\\n\"\n",
    "\n",
    "header_text += \",\".join(\n",
    "    [\n",
    "        \"position\",\n",
    "        \"maf\",\n",
    "        \"total_concordance\",\n",
    "        \"iqs\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "np.savetxt(\n",
    "    out_results_file,\n",
    "    results,\n",
    "    fmt='%.10f',\n",
    "    delimiter=\",\",\n",
    "    newline=\"\\n\",\n",
    "    comments=\"\",\n",
    "    header=header_text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba94238b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
