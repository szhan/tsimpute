{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfccae17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tskit 0.5.0\n",
      "tsinfer 0.2.3\n",
      "msprime 1.1.1\n",
      "demes 0.2.1\n",
      "cyvcf2 0.30.14\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import msprime\n",
    "import tskit\n",
    "import tsinfer\n",
    "from tsinfer import make_ancestors_ts\n",
    "\n",
    "import cyvcf2\n",
    "import demes\n",
    "import demesdraw\n",
    "\n",
    "print(f\"tskit {tskit.__version__}\")\n",
    "print(f\"tsinfer {tsinfer.__version__}\")\n",
    "print(f\"msprime {msprime.__version__}\")\n",
    "print(f\"demes {demes.__version__}\")\n",
    "print(f\"cyvcf2 {cyvcf2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d141a7",
   "metadata": {},
   "source": [
    "### Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd9bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate_index = 0\n",
    "\n",
    "sampling_time_query = 100\n",
    "\n",
    "proportion_missing_sites = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee82bff",
   "metadata": {},
   "source": [
    "### Simulate genealogy and genetic variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfdd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ref   = 1e4\n",
    "size_query = 1e3\n",
    "\n",
    "eff_pop_size = 10_000\n",
    "mutation_rate = 1e-8\n",
    "recombination_rate = 1e-8\n",
    "\n",
    "contig_id = '1'\n",
    "ploidy_level = 1 # Haploid genomes\n",
    "sequence_length = 1_000_000 # 1 Mbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab44e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform recombination rate\n",
    "recomb_rate_map = msprime.RateMap.uniform(\n",
    "    sequence_length=sequence_length,\n",
    "    rate=recombination_rate,\n",
    ")\n",
    "\n",
    "# Uniform mutation rate\n",
    "mut_rate_map = msprime.RateMap.uniform(\n",
    "    sequence_length=sequence_length,\n",
    "    rate=mutation_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa1ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_set = [\n",
    "    # Reference panel\n",
    "    msprime.SampleSet(num_samples=size_ref,\n",
    "                      time=0,\n",
    "                      ploidy=ploidy_level),\n",
    "    # Query genomes\n",
    "    msprime.SampleSet(num_samples=size_query,\n",
    "                      time=sampling_time_query,\n",
    "                      ploidy=ploidy_level),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ebc2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simulated tree sequence does not contain any monoallelic sites,\n",
    "# but there may be multiallelic sites.\n",
    "ts_full = msprime.sim_mutations(\n",
    "    msprime.sim_ancestry(\n",
    "        samples=sample_set,\n",
    "        population_size=eff_pop_size,\n",
    "        model=\"hudson\",\n",
    "        recombination_rate=recomb_rate_map,\n",
    "        discrete_genome=True,\n",
    "    ),\n",
    "    rate=mut_rate_map,\n",
    "    discrete_genome=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376e22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals_ref = np.arange(size_ref, dtype=int)\n",
    "individual_names_ref = [\"ref_\" + str(i) for i in individuals_ref]\n",
    "samples_ref = np.arange(ploidy_level * size_ref, dtype=int)\n",
    "\n",
    "individuals_query = np.arange(size_ref, size_ref + size_query, dtype=int)\n",
    "individual_names_query = [\"query_\" + str(i) for i in individuals_query]\n",
    "samples_query = np.arange(ploidy_level * size_ref, ploidy_level * (size_ref + size_query), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f070b0",
   "metadata": {},
   "source": [
    "### Match query genomes to an ancestor tree sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a50b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4378 10000\n",
      "4378 1000\n"
     ]
    }
   ],
   "source": [
    "ts_ref = ts_full.simplify(samples_ref, filter_sites=False)\n",
    "ts_query = ts_full.simplify(samples_query, filter_sites=False)\n",
    "\n",
    "print(f\"{ts_ref.num_sites} {ts_ref.num_samples}\")\n",
    "print(f\"{ts_query.num_sites} {ts_query.num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1551a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4378 11000\n",
      "4378 10000\n",
      "4378 1000\n"
     ]
    }
   ],
   "source": [
    "# Multiallelic sites are included.\n",
    "sd_full = tsinfer.SampleData.from_tree_sequence(ts_full)\n",
    "\n",
    "sd_ref = sd_full.subset(individuals_ref)\n",
    "sd_query = sd_full.subset(individuals_query) # Used for matching\n",
    "\n",
    "print(f\"{sd_full.num_sites} {sd_full.num_samples}\")\n",
    "print(f\"{sd_ref.num_sites} {sd_ref.num_samples}\")\n",
    "print(f\"{sd_query.num_sites} {sd_query.num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f23ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multiallelic_sites(sample_data):\n",
    "    \"\"\"\n",
    "    Create a new SampleData object based on an existing SampleData object,\n",
    "    but excluding multi-allelic sites. Return the new SampleData object.\n",
    "    \"\"\"\n",
    "    multi_sites = []\n",
    "    with tsinfer.SampleData(sample_data.sequence_length) as sample_data_new:\n",
    "        for variant in sample_data.variants():\n",
    "            if len(set(variant.alleles) - {None}) <= 2:\n",
    "                sample_data_new.add_site(\n",
    "                    position=variant.site.position,\n",
    "                    genotypes=variant.genotypes,\n",
    "                    alleles=variant.alleles,\n",
    "                )\n",
    "            else:\n",
    "                multi_sites.append(variant.site.position)\n",
    "    print(f\"INFO: Removed {len(multi_sites)} multiallelic sites.\")\n",
    "    print(multi_sites)\n",
    "    return(sample_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e70ad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Removed 5 multiallelic sites.\n",
      "[128626.0, 161878.0, 599097.0, 617293.0, 675876.0]\n",
      "INFO: Removed 5 multiallelic sites.\n",
      "[128626.0, 161878.0, 599097.0, 617293.0, 675876.0]\n",
      "4373 10000\n",
      "4373 1000\n"
     ]
    }
   ],
   "source": [
    "sd_ref_filtered = remove_multiallelic_sites(sd_ref)\n",
    "sd_query_filtered = remove_multiallelic_sites(sd_query)\n",
    "\n",
    "print(f\"{sd_ref_filtered.num_sites} {sd_ref_filtered.num_samples}\")\n",
    "print(f\"{sd_query_filtered.num_sites} {sd_query_filtered.num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a92786fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiallelic sites are automatically removed when generating an ancestor tree sequence.\n",
    "ts_anc = make_ancestors_ts(ts=ts_ref, remove_leaves=True, samples=None)\n",
    "\n",
    "# # Identify sites unique to ts_anc but not in sd_query\n",
    "# sites_ts_anc = set(ts_anc.tables.sites.position)\n",
    "# sites_sd_query = set(sd_query_filtered.sites_position[:])\n",
    "# site_positions_to_remove = list(sites_ts_anc.difference(sites_sd_query))\n",
    "# print(site_positions_to_remove)\n",
    "# site_ids_to_remove = [ts_anc.site(position=p).id for p in site_positions_to_remove]\n",
    "\n",
    "# tmp_tables = ts_anc.dump_tables()\n",
    "# tmp_tables.delete_sites(site_ids_to_remove) # Remove sites unique to ts_anc\n",
    "# print(f\"Deleting {len(site_ids_to_remove)} sites.\")\n",
    "# tmp_tables.individuals.clear()\n",
    "# tmp_tables.populations.metadata_schema = tskit.MetadataSchema(schema=None)\n",
    "\n",
    "# ts_anc = tmp_tables.tree_sequence() # Used for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3b7556c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot currently match with > 2 alleles.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ts_matched \u001b[38;5;241m=\u001b[39m \u001b[43mtsinfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msd_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mancestors_ts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_anc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/tsinfer/inference.py:604\u001b[0m, in \u001b[0;36mmatch_samples\u001b[0;34m(sample_data, ancestors_ts, recombination_rate, mismatch_ratio, path_compression, simplify, indexes, force_sample_times, num_threads, recombination, mismatch, precision, stabilise_node_ordering, extended_checks, engine, progress_monitor)\u001b[0m\n\u001b[1;32m    602\u001b[0m sample_data\u001b[38;5;241m.\u001b[39m_check_finalised()\n\u001b[1;32m    603\u001b[0m progress_monitor \u001b[38;5;241m=\u001b[39m _get_progress_monitor(progress_monitor, match_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 604\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mSampleMatcher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mancestors_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecombination_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecombination_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmismatch_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmismatch_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecombination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecombination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmismatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextended_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m sample_indexes \u001b[38;5;241m=\u001b[39m check_sample_indexes(sample_data, indexes)\n\u001b[1;32m    619\u001b[0m sample_times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28mlen\u001b[39m(sample_indexes), dtype\u001b[38;5;241m=\u001b[39msample_data\u001b[38;5;241m.\u001b[39mindividuals_time\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    621\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/tsinfer/inference.py:1481\u001b[0m, in \u001b[0;36mSampleMatcher.__init__\u001b[0;34m(self, sample_data, ancestors_ts, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_data, ancestors_ts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mancestors_ts_tables \u001b[38;5;241m=\u001b[39m ancestors_ts\u001b[38;5;241m.\u001b[39mdump_tables()\n\u001b[0;32m-> 1481\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mancestors_ts_tables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msites\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1482\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_tree_sequence_builder()\n\u001b[1;32m   1483\u001b[0m     \u001b[38;5;66;03m# Map from input sample indexes (IDs in the SampleData file) to the\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m     \u001b[38;5;66;03m# node ID in the tree sequence.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/tsinfer/inference.py:1118\u001b[0m, in \u001b[0;36mMatcher.__init__\u001b[0;34m(self, sample_data, inference_site_position, num_threads, path_compression, recombination_rate, mismatch_ratio, recombination, mismatch, precision, extended_checks, engine, progress_monitor)\u001b[0m\n\u001b[1;32m   1116\u001b[0m max_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(num_alleles \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m-> 1118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot currently match with > 2 alleles.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_sequence_builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_sequence_builder_class(\n\u001b[1;32m   1120\u001b[0m     num_alleles\u001b[38;5;241m=\u001b[39mnum_alleles, max_nodes\u001b[38;5;241m=\u001b[39mmax_nodes, max_edges\u001b[38;5;241m=\u001b[39mmax_edges\n\u001b[1;32m   1121\u001b[0m )\n\u001b[1;32m   1122\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllocated tree sequence builder with max_nodes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_nodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot currently match with > 2 alleles."
     ]
    }
   ],
   "source": [
    "#ts_matched = tsinfer.match_samples(sample_data=sd_query_filtered, ancestors_ts=ts_anc)\n",
    "ts_matched = tsinfer.match_samples(sample_data=sd_query, ancestors_ts=ts_anc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33b6f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variant in ts_anc.variants():\n",
    "    if len(set(variant.alleles) - {None}) != 2:\n",
    "        print(variant.alleles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b286eed",
   "metadata": {},
   "source": [
    "### Impute into query genomes from the ancestor tree sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd35e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sites(sample_data, proportion_missing_sites):\n",
    "    \"\"\"\n",
    "    Draw N sites stored in a SampleData object at random\n",
    "    by site id, where N is the number of sites to mask\n",
    "    based on a specified proportion of missing sites.\n",
    "    \n",
    "    Return a boolean array of size sample_data.num_sites,\n",
    "    where True indicates that the site is masked.\n",
    "    \n",
    "    TODO: Specify random seed.\n",
    "    \"\"\"\n",
    "    assert proportion_missing_sites >= 0 and proportion_missing_sites <= 1, \\\n",
    "        \"Proportion of missing sites must be between 0 and 1.\"\n",
    "    \n",
    "    num_masked_sites = int(np.floor(sample_data.num_sites * proportion_missing_sites))\n",
    "    \n",
    "    masked_site_ids = np.sort(\n",
    "        np.random.default_rng().integers(\n",
    "            low=0,\n",
    "            high=sample_data.num_sites,\n",
    "            size=num_masked_sites,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    masked_site_bool = np.zeros(sample_data.num_sites, dtype=bool)\n",
    "    masked_site_bool[masked_site_ids] = True\n",
    "    \n",
    "    return(masked_site_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66192602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sites_in_sample_data(sample_data, sites_to_mask=None):\n",
    "    \"\"\"\n",
    "    Create a SampleData object from an existing SampleData object,\n",
    "    while masking specified sites listed in sites_to_mask (site ids).\n",
    "    \"\"\"\n",
    "    if sites_to_mask is None:\n",
    "        # By default, no site is masked\n",
    "        sites_to_mask = np.zeros(sample_data.num_sites, dtype=bool)\n",
    "    \n",
    "    num_variants = 0 # Check the number of sites and number of variants are identical\n",
    "    with tsinfer.SampleData(sample_data.sequence_length) as sample_data_new:\n",
    "        for i, variant in enumerate(sample_data.variants()):\n",
    "            num_variants += 1\n",
    "            if sites_to_mask[i]:\n",
    "                genotypes = np.repeat(tskit.MISSING_DATA, len(variant.genotypes))\n",
    "            else:\n",
    "                genotypes = variant.genotypes\n",
    "            sample_data_new.add_site(\n",
    "                position=variant.site.position,\n",
    "                genotypes=genotypes,\n",
    "                alleles=variant.alleles, # Keep the same\n",
    "            )\n",
    "    \n",
    "    assert sample_data.num_sites == num_variants,\\\n",
    "        \"Number of sites is not equal to the number of variants.\"\n",
    "    \n",
    "    return(sample_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f4619fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_site_bool = sample_sites(sd_query, proportion_missing_sites)\n",
    "sd_query_masked = mask_sites_in_sample_data(sd_query, sites_to_mask=masked_site_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "126d79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_imputed = tsinfer.match_samples(\n",
    "    sample_data=sd_query_masked,\n",
    "    ancestors_ts=ts_anc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc3d01",
   "metadata": {},
   "source": [
    "### Write VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e56cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SD full    : 3284\n",
      "SD query   : 3284\n",
      "TS ref     : 3284\n",
      "TS query   : 3284\n",
      "TS anc     : 2781\n",
      "TS imputed : 3284\n"
     ]
    }
   ],
   "source": [
    "print(f\"SD full    : {sd_full.num_sites}\")\n",
    "print(f\"SD query   : {sd_query.num_sites}\")\n",
    "print(f\"TS ref     : {ts_ref.num_sites}\")\n",
    "print(f\"TS query   : {ts_query.num_sites}\")\n",
    "print(f\"TS anc     : {ts_anc.num_sites}\")\n",
    "print(f\"TS imputed : {ts_imputed.num_sites}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdbea55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vcf_file = \".\".join([\"ref\", str(replicate_index), \"vcf\", \"gz\"])\n",
    "query_true_vcf_file = \".\".join([\"query_true\", str(replicate_index), \"vcf\", \"gz\"])\n",
    "query_miss_vcf_file = \".\".join([\"query_miss\", str(replicate_index), \"vcf\", \"gz\"])\n",
    "imputed_vcf_file = \".\".join([\"imputed\", str(replicate_index), \"vcf\", \"gz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbaec761",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(ref_vcf_file, \"wt\") as f:\n",
    "    ts_ref.write_vcf(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb9c6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(query_true_vcf_file, \"wt\") as f:\n",
    "    ts_query.write_vcf(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cdc54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mask(variant):\n",
    "    num_samples = len(variant.genotypes)\n",
    "    if masked_site_bool[variant.site.id]:\n",
    "        sample_mask = np.ones(num_samples, dtype=bool)\n",
    "    else:\n",
    "        sample_mask = np.zeros(num_samples, dtype=bool)\n",
    "    return sample_mask\n",
    "\n",
    "\n",
    "with gzip.open(query_miss_vcf_file, \"wt\") as f:\n",
    "    ts_query.write_vcf(f, sample_mask=sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef838056",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(imputed_vcf_file, \"wt\") as f:\n",
    "    ts_imputed.write_vcf(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1213d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
