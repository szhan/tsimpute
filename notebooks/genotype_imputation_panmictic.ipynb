{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f1c464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tskit 0.5.0\n",
      "tsinfer 0.2.3\n",
      "msprime 1.1.1\n",
      "demes 0.2.1\n",
      "cyvcf2 0.30.14\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tskit\n",
    "from tsinfer import make_ancestors_ts\n",
    "import tsinfer\n",
    "import msprime\n",
    "\n",
    "import demes\n",
    "import demesdraw\n",
    "import cyvcf2\n",
    "\n",
    "print(f\"tskit {tskit.__version__}\")\n",
    "print(f\"tsinfer {tsinfer.__version__}\")\n",
    "print(f\"msprime {msprime.__version__}\")\n",
    "print(f\"demes {demes.__version__}\")\n",
    "print(f\"cyvcf2 {cyvcf2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa396407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sourced and modified from:\n",
    "# https://tsinfer.readthedocs.io/en/latest/tutorial.html#data-example\n",
    "def get_chromosome_length(vcf):\n",
    "    assert len(vcf.seqlens) == 1\n",
    "    return vcf.seqlens[0]\n",
    "\n",
    "\n",
    "def add_populations(vcf,\n",
    "                    samples):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    pop_ids = [sample_name[0] for sample_name in vcf.samples]\n",
    "    pop_codes = np.unique(pop_ids)\n",
    "    pop_lookup = {}\n",
    "    for p in pop_codes:\n",
    "        pop_lookup[p] = samples.add_population(metadata = {\"name\" : p})\n",
    "    return [pop_lookup[pop_id] for pop_id in pop_ids]\n",
    "\n",
    "\n",
    "def add_individuals(vcf,\n",
    "                    samples,\n",
    "                    ploidy_level,\n",
    "                    populations):\n",
    "    for name, population in zip(vcf.samples, populations):\n",
    "        samples.add_individual(ploidy = ploidy_level,\n",
    "                               metadata = {\"name\": name},\n",
    "                               population = population)\n",
    "\n",
    "\n",
    "def add_sites(vcf,\n",
    "              samples,\n",
    "              ploidy_level,\n",
    "              warn_monomorphic_sites = False):\n",
    "    \"\"\"\n",
    "    Read the sites in the VCF and add them to the samples object,\n",
    "    reordering the alleles to put the ancestral allele first,\n",
    "    if it is available.\n",
    "    \"\"\"\n",
    "    assert ploidy_level == 1 or ploidy_level == 2,\\\n",
    "        f\"ploidy_level {ploidy_level} is not recognized.\"\n",
    "    \n",
    "    pos = 0\n",
    "    for variant in vcf:\n",
    "        # Check for duplicate site positions.\n",
    "        if pos == variant.POS:\n",
    "            raise ValueError(\"Duplicate positions for variant at position\", pos)\n",
    "        else:\n",
    "            pos = variant.POS\n",
    "        # Check that the genotypes are phased.\n",
    "        #if any([not phased for _, _, phased in variant.genotypes]):\n",
    "        #    raise ValueError(\"Unphased genotypes for variant at position\", pos)\n",
    "        alleles = [variant.REF] + variant.ALT # Exactly as in the input VCF file.\n",
    "        if warn_monomorphic_sites:\n",
    "            if len(set(alleles) - {'.'}) == 1:\n",
    "                print(f\"Monomorphic site at {pos}\")\n",
    "        ancestral = variant.INFO.get(\"AA\", variant.REF) # Dangerous action!!!\n",
    "        # Ancestral state must be first in the allele list.\n",
    "        ordered_alleles = [ancestral] + list(set(alleles) - {ancestral})\n",
    "        # Create an index mapping from the input VCF to tsinfer input.\n",
    "        allele_index = {\n",
    "            old_index: ordered_alleles.index(allele)\n",
    "            for old_index, allele in enumerate(alleles)\n",
    "        }\n",
    "        # When genotype is missing...\n",
    "        if variant.num_unknown > 0:\n",
    "            allele_index[-1] = tskit.MISSING_DATA\n",
    "            ordered_alleles += [None]\n",
    "        # Map original allele indexes to their indexes in the new alleles list.\n",
    "        genotypes = [\n",
    "            allele_index[old_index]\n",
    "            for row in variant.genotypes # cyvcf2 uses -1 to indicate missing data.\n",
    "            for old_index in row[0:ploidy_level] # Each is a 3-tuple (allele 1, allele 2, is phased?).\n",
    "        ]\n",
    "        samples.add_site(pos,\n",
    "                         genotypes = genotypes,\n",
    "                         alleles = ordered_alleles)\n",
    "\n",
    "\n",
    "def create_sample_data_from_vcf_file(vcf_file):\n",
    "    vcf = cyvcf2.VCF(vcf_file,\n",
    "                     gts012 = False, # 0=HOM_REF, 1=HET, 2=UNKNOWN, 3=HOM_ALT\n",
    "                     strict_gt = True)\n",
    "    with tsinfer.SampleData(\n",
    "        sequence_length = get_chromosome_length(vcf)\n",
    "    ) as samples:\n",
    "        populations = add_populations(vcf, samples)\n",
    "        add_individuals(vcf, samples, ploidy_level, populations)\n",
    "        add_sites(vcf, samples, ploidy_level)\n",
    "    return(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a68edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_biallelic_sites(sample_data_1, sample_data_2):\n",
    "    variants_1 = sample_data_1.variants()\n",
    "    variants_2 = sample_data_2.variants()\n",
    "    # Keep only biallelic sites\n",
    "    sites_1 = []\n",
    "    sites_2 = []\n",
    "    for var_1, var_2 in zip(variants_1, variants_2):\n",
    "        assert var_1.site.position == var_2.site.position\n",
    "        alleles_1 = set(var_1.alleles) - {None}\n",
    "        alleles_2 = set(var_2.alleles) - {None}\n",
    "        if len(alleles_1) == 2\\\n",
    "            and len(alleles_2) == 2\\\n",
    "            and alleles_1 == alleles_2:\n",
    "            sites_1.append(var_1.site.id)\n",
    "            sites_2.append(var_2.site.id)\n",
    "    assert len(sites_1) == len(sites_2),\\\n",
    "        \"The number of site positions in sites_1 and sites_2 are different.\"\n",
    "    return(sites_1, sites_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23154dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_with_discretized_coordinates(ts):\n",
    "    ts_tables = ts.dump_tables()\n",
    "    ts_tables.sites.position = np.round(ts_tables.sites.position)\n",
    "    ts_tables.deduplicate_sites()\n",
    "    ts_tables.sort()\n",
    "    ts_tables.build_index()\n",
    "    ts_tables.compute_mutation_times()\n",
    "    ts_discretized = ts_tables.tree_sequence()\n",
    "    return(ts_discretized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a07aa7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_site_mask(ts, missing):\n",
    "    assert missing >=0 and missing <= 1,\\\n",
    "        \"Proportion of missing sites is not between 0 and 1.\"\n",
    "    site_mask = np.random.random(ts.num_sites) < missing\n",
    "    return(site_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "739d7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_into_ancestor_tree_sequence(ts, samples):\n",
    "    \"\"\"\n",
    "    Remove the tips (or the sample nodes at time 0) from a tree sequence,\n",
    "    and return an ancestor tree sequence.\n",
    "    \n",
    "    Presently, there is an extra step to remove the metadata from the\n",
    "    ancestor tree sequence.\n",
    "    \"\"\"\n",
    "    ts_tipless = make_ancestors_ts(samples = samples,\n",
    "                                   ts = ts,\n",
    "                                   remove_leaves = True)\n",
    "    tmp_tables = ts_tipless.dump_tables()\n",
    "    tmp_tables.populations.metadata_schema = tskit.MetadataSchema(schema = None)\n",
    "    ts_new = tmp_tables.tree_sequence()\n",
    "    return(ts_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8994b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_genotypes_using_tsinfer(ref_vcf_file,\n",
    "                                   miss_vcf_file,\n",
    "                                   imputed_vcf_file,\n",
    "                                   contig_id):\n",
    "    sd_ref  = create_sample_data_from_vcf_file(ref_vcf_file)\n",
    "    sd_miss = create_sample_data_from_vcf_file(miss_vcf_file)\n",
    "    ad_ref     = tsinfer.generate_ancestors(sample_data = sd_ref)\n",
    "    # This step is to infer a tree sequence from the sample data.\n",
    "    ts_anc_ref = tsinfer.match_ancestors(sample_data   = sd_ref,\n",
    "                                         ancestor_data = ad_ref)\n",
    "    ts_matched = tsinfer.match_samples(sample_data  = sd_miss,\n",
    "                                       ancestors_ts = ts_anc_ref)\n",
    "    with open(imputed_vcf_file, \"w\") as vcf:\n",
    "        ts_matched.write_vcf(vcf, contig_id=contig_id)\n",
    "    return(ts_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bd1f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_genotypes_using_ts_only(ref_vcf_file,\n",
    "                                   miss_vcf_file,\n",
    "                                   imputed_vcf_file,\n",
    "                                   imputed_ts_file,\n",
    "                                   ts_anc_ref,\n",
    "                                   contig_id):\n",
    "    sd_ref = create_sample_data_from_vcf_file(ref_vcf_file)\n",
    "    sd_miss = create_sample_data_from_vcf_file(miss_vcf_file)\n",
    "    \n",
    "    # Clean ts_anc_ref\n",
    "    tmp_tables = ts_anc_ref.dump_tables()\n",
    "    #tmp_tables.individuals.clear()\n",
    "    ts_anc_ref = tmp_tables.tree_sequence()\n",
    "    \n",
    "    ts_fixed = tsinfer.match_samples(sample_data=sd_miss,\n",
    "                                     ancestors_ts=ts_anc_ref)\n",
    "    with gzip.open(imputed_vcf_file, \"wt\") as f:\n",
    "        ts_fixed.write_vcf(f, contig_id=contig_id)\n",
    "    ts_fixed.dump(imputed_ts_file)\n",
    "    \n",
    "    return(ts_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1ea4b",
   "metadata": {},
   "source": [
    "## Create data sets via simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80ab9ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the reference panel is 1000\n",
      "Size of the query is 100\n",
      "Ploidy level is 1\n",
      "Population size is 10000\n",
      "Sampling time query : 100\n",
      "Base directory : ../data/ancient_panmictic_haploid_miss80_time1e2/\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"../data/ancient_panmictic_haploid_miss80_time1e2/\"\n",
    "\n",
    "sampling_time_query = 100\n",
    "\n",
    "num_replicates = 10\n",
    "\n",
    "size_query = 100\n",
    "size_ref   = 1_000\n",
    "\n",
    "eff_pop_size = 10_000\n",
    "mutation_rate = 1e-8\n",
    "recombination_rate = 1e-8\n",
    "\n",
    "proportion_missing_sites = 0.80\n",
    "\n",
    "contig_id = '1'\n",
    "ploidy_level = 1\n",
    "sequence_length = 1_0000_000 # 10 Mbp\n",
    "\n",
    "print(f\"Size of the reference panel is {size_ref}\")\n",
    "print(f\"Size of the query is {size_query}\")\n",
    "print(f\"Ploidy level is {ploidy_level}\")\n",
    "print(f\"Population size is {eff_pop_size}\")\n",
    "print(f\"Sampling time query : {sampling_time_query}\")\n",
    "print(f\"Base directory : {base_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f814f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_map = msprime.RateMap.uniform(\n",
    "    sequence_length = sequence_length,\n",
    "    rate = recombination_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "920dc741",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_set = [\n",
    "    msprime.SampleSet(num_samples = size_query,\n",
    "                      time = sampling_time_query,\n",
    "                      ploidy = ploidy_level),\n",
    "    msprime.SampleSet(num_samples = size_ref,\n",
    "                      time = 0,\n",
    "                      ploidy = ploidy_level)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be904e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_ts = [] # List of full ts.\n",
    "anc_ts = [] # List of ancestor ts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa5b6e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating 10 tree sequences.\n",
      "Simulation of 10 ts took 5.41 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Simulating {num_replicates} tree sequences.\")\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "for i in np.arange(num_replicates):\n",
    "    sim_ts = msprime.sim_mutations(\n",
    "        msprime.sim_ancestry(\n",
    "            samples = sample_set,\n",
    "            population_size = eff_pop_size,\n",
    "            model = \"hudson\",\n",
    "            recombination_rate = rate_map,\n",
    "            discrete_genome = True\n",
    "        ),\n",
    "        rate = mutation_rate,\n",
    "        discrete_genome = True\n",
    "    )\n",
    "    src_ts.append(sim_ts)\n",
    "    \n",
    "toc = time.time()\n",
    "print(f\"Simulation of {num_replicates} ts took {round(toc - tic, 2)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a12ae6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals_query = np.arange(size_query, dtype = int)\n",
    "individual_names_query = [\"query_\" + str(i) for i in individuals_query]\n",
    "samples_query = np.arange(ploidy_level * size_query, dtype=int)\n",
    "\n",
    "individuals_ref = np.arange(size_query, size_query + size_ref, dtype=int)\n",
    "individual_names_ref = [\"ref_\" + str(i) for i in individuals_ref]\n",
    "samples_ref = np.arange(ploidy_level * size_query, ploidy_level * (size_query + size_ref), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fce9cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ts 0.\n",
      "\tGetting ancestors ts...\n",
      "\tPrinting reference VCF...\n",
      "\tPrinting query VCF with non-missing genotypes...\n",
      "\tPrinting query VCF with missing genotypes...\n",
      "Took 15.67206883430481 seconds to process ts 0.\n"
     ]
    }
   ],
   "source": [
    "for i, ts in enumerate(src_ts[:1]):\n",
    "    print(f\"Processing ts {i}.\")\n",
    "    tic = time.time()\n",
    "    \n",
    "    ref_vcf_file = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf.gz\"\n",
    "    true_vcf_file = base_dir + \"true/\" + \"true.\" + str(i) + \".vcf.gz\"\n",
    "    miss_vcf_file = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf.gz\"\n",
    "    \n",
    "    ts_full_ref_file = base_dir + \"ref/\" + \"ts_full_ref.\" + str(i) + \".trees\"\n",
    "    ts_anc_ref_file = base_dir + \"ts_anc_ref/\" + \"ts_anc_ref.\" + str(i) + \".trees\"\n",
    "    \n",
    "    print(\"\\tGetting ancestors ts...\")\n",
    "    ts_anc_ref = convert_into_ancestor_tree_sequence(ts, samples=samples_ref)\n",
    "    anc_ts.append(ts_anc_ref)\n",
    "    \n",
    "    ts.dump(ts_full_ref_file)\n",
    "    ts_anc_ref.dump(ts_anc_ref_file)\n",
    "    \n",
    "    site_mask = get_random_site_mask(ts, missing=proportion_missing_sites)\n",
    "    \n",
    "    print(\"\\tPrinting reference VCF...\")\n",
    "    with gzip.open(ref_vcf_file, \"wt\") as f:\n",
    "        ts.write_vcf(f, individuals=individuals_ref)\n",
    "    print(\"\\tPrinting query VCF with non-missing genotypes...\")\n",
    "    with gzip.open(true_vcf_file, \"wt\") as f:\n",
    "        ts.write_vcf(f, individuals=individuals_query)\n",
    "    print(\"\\tPrinting query VCF with missing genotypes...\")\n",
    "    with gzip.open(miss_vcf_file, \"wt\") as f:\n",
    "        ts.write_vcf(f,\n",
    "                     individuals=individuals_query,\n",
    "                     site_mask=site_mask)\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(f\"Took {toc - tic} seconds to process ts {i}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da1bc5",
   "metadata": {},
   "source": [
    "## Perform genotype imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f2d72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing imputation using ts only.\n",
      "Imputing VCF 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6274 is out of bounds for axis 0 with size 6274",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m imputed_vcf_file \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed_tsonly/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vcf.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m ts_imputed_file  \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed_tsonly/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.trees\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m ts_imputed       \u001b[38;5;241m=\u001b[39m \u001b[43mimpute_genotypes_using_ts_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_vcf_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mref_vcf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mmiss_vcf_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmiss_vcf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mimputed_vcf_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimputed_vcf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mimputed_ts_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mts_imputed_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mts_anc_ref\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43manc_ts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mcontig_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontig_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m toc \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTook \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoc \u001b[38;5;241m-\u001b[39m tic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds to process ts \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mimpute_genotypes_using_ts_only\u001b[0;34m(ref_vcf_file, miss_vcf_file, imputed_vcf_file, imputed_ts_file, ts_anc_ref, contig_id)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#tmp_tables.individuals.clear()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m ts_anc_ref \u001b[38;5;241m=\u001b[39m tmp_tables\u001b[38;5;241m.\u001b[39mtree_sequence()\n\u001b[0;32m---> 15\u001b[0m ts_fixed \u001b[38;5;241m=\u001b[39m \u001b[43mtsinfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msd_miss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mancestors_ts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mts_anc_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(imputed_vcf_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m     ts_fixed\u001b[38;5;241m.\u001b[39mwrite_vcf(f, contig_id\u001b[38;5;241m=\u001b[39mcontig_id)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/tsinfer/inference.py:604\u001b[0m, in \u001b[0;36mmatch_samples\u001b[0;34m(sample_data, ancestors_ts, recombination_rate, mismatch_ratio, path_compression, simplify, indexes, force_sample_times, num_threads, recombination, mismatch, precision, stabilise_node_ordering, extended_checks, engine, progress_monitor)\u001b[0m\n\u001b[1;32m    602\u001b[0m sample_data\u001b[38;5;241m.\u001b[39m_check_finalised()\n\u001b[1;32m    603\u001b[0m progress_monitor \u001b[38;5;241m=\u001b[39m _get_progress_monitor(progress_monitor, match_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 604\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mSampleMatcher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mancestors_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecombination_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecombination_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmismatch_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmismatch_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecombination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecombination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmismatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextended_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m sample_indexes \u001b[38;5;241m=\u001b[39m check_sample_indexes(sample_data, indexes)\n\u001b[1;32m    619\u001b[0m sample_times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28mlen\u001b[39m(sample_indexes), dtype\u001b[38;5;241m=\u001b[39msample_data\u001b[38;5;241m.\u001b[39mindividuals_time\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    621\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/tsinfer/inference.py:1481\u001b[0m, in \u001b[0;36mSampleMatcher.__init__\u001b[0;34m(self, sample_data, ancestors_ts, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_data, ancestors_ts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mancestors_ts_tables \u001b[38;5;241m=\u001b[39m ancestors_ts\u001b[38;5;241m.\u001b[39mdump_tables()\n\u001b[0;32m-> 1481\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mancestors_ts_tables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msites\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1482\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_tree_sequence_builder()\n\u001b[1;32m   1483\u001b[0m     \u001b[38;5;66;03m# Map from input sample indexes (IDs in the SampleData file) to the\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m     \u001b[38;5;66;03m# node ID in the tree sequence.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tskit-play/lib/python3.8/site-packages/tsinfer/inference.py:1032\u001b[0m, in \u001b[0;36mMatcher.__init__\u001b[0;34m(self, sample_data, inference_site_position, num_threads, path_compression, recombination_rate, mismatch_ratio, recombination, mismatch, precision, extended_checks, engine, progress_monitor)\u001b[0m\n\u001b[1;32m   1030\u001b[0m all_sites \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_data\u001b[38;5;241m.\u001b[39msites_position[:]\n\u001b[1;32m   1031\u001b[0m index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(all_sites, inference_site_position)\n\u001b[0;32m-> 1032\u001b[0m num_alleles \u001b[38;5;241m=\u001b[39m \u001b[43msample_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_alleles\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(all_sites[index] \u001b[38;5;241m==\u001b[39m inference_site_position):\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSite positions for inference must be a subset of those in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1036\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe sample data file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1037\u001b[0m     )\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6274 is out of bounds for axis 0 with size 6274"
     ]
    }
   ],
   "source": [
    "print(\"Doing imputation using ts only.\")\n",
    "\n",
    "for i in np.arange(len(src_ts[:1])):\n",
    "    print(f\"Imputing VCF {i}\")\n",
    "    tic = time.time()\n",
    "    \n",
    "    ref_vcf_file     = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf.gz\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf.gz\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsonly/\" + \"imputed.\" + str(i) + \".vcf.gz\"\n",
    "    ts_imputed_file  = base_dir + \"imputed_tsonly/\" + \"imputed.\" + str(i) + \".trees\"\n",
    "    ts_imputed       = impute_genotypes_using_ts_only(ref_vcf_file = ref_vcf_file,\n",
    "                                                      miss_vcf_file = miss_vcf_file,\n",
    "                                                      imputed_vcf_file = imputed_vcf_file,\n",
    "                                                      imputed_ts_file = ts_imputed_file,\n",
    "                                                      ts_anc_ref = anc_ts[i],\n",
    "                                                      contig_id = contig_id)\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(f\"Took {toc - tic} seconds to process ts {i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e143b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing imputation using tsinfer.\n",
      "Imputing VCF 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Doing imputation using tsinfer.\")\n",
    "\n",
    "for i in np.arange(len(src_ts[:1])):\n",
    "    print(f\"Imputing VCF {i}\")\n",
    "    tic = time.time()\n",
    "    \n",
    "    ref_vcf_file     = base_dir + \"ref/\" + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_tsinfer/\" + \"imputed.\" + str(i) + \".vcf\"\n",
    "    ts_imputed_file  = base_dir + \"imputed_tsinfer/\" + \"imputed.\" + str(i) + \".trees\"\n",
    "    ts_imputed       = impute_genotypes_using_tsinfer(ref_vcf_file = ref_vcf_file,\n",
    "                                                      miss_vcf_file = miss_vcf_file,\n",
    "                                                      imputed_vcf_file = imputed_vcf_file,\n",
    "                                                      contig_id = contig_id)\n",
    "    ts_imputed.dump(ts_imputed_file)\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(f\"Took {toc - tic} seconds to process ts {i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff859033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing imputation using BEAGLE.\n",
      "java -jar ../analysis/beagle/beagle.28Jun21.220.jar ref=../data/ancient_panmictic_haploid_miss80/ref/ref.0.vcf gt=../data/ancient_panmictic_haploid_miss80/miss/miss.0.vcf out=../data/ancient_panmictic_haploid_miss80/imputed_beagle/imputed.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Doing imputation using BEAGLE.\")\n",
    "\n",
    "beagle_exe = \"../analysis/beagle/beagle.28Jun21.220.jar\"\n",
    "\n",
    "#for i in np.arange(len(src_ts)):\n",
    "for i in [0]:\n",
    "    ref_vcf_file     = base_dir + \"ref/\"  + \"ref.\"  + str(i) + \".vcf\"\n",
    "    miss_vcf_file    = base_dir + \"miss/\" + \"miss.\" + str(i) + \".vcf\"\n",
    "    imputed_vcf_file = base_dir + \"imputed_beagle/\" + \"imputed.\" + str(i)\n",
    "    beagle_cmd = [\n",
    "        \"java\", \"-jar\", beagle_exe,\n",
    "        \"ref=\" + ref_vcf_file,\n",
    "        \"gt=\"  + miss_vcf_file,\n",
    "        \"out=\" + imputed_vcf_file\n",
    "    ]\n",
    "    beagle_cmd = \" \".join(beagle_cmd)\n",
    "    print(beagle_cmd + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
